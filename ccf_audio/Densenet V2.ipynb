{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:16:12.239318Z",
     "start_time": "2020-12-06T08:16:12.230695Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:16:12.473353Z",
     "start_time": "2020-12-06T08:16:12.462804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:16:12.661510Z",
     "start_time": "2020-12-06T08:16:12.649809Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "GLOBAL_SEED = 42\n",
    "setup_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:16:12.855381Z",
     "start_time": "2020-12-06T08:16:12.846225Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = '/root/cfl/b/Audio/data/train'\n",
    "test_path = '/root/cfl/b/Audio/data/test'\n",
    "feat_path = '/root/cfl/b/Audio/features'\n",
    "res_path = '/root/cfl/b/Audio/res'\n",
    "model_save = '/root/cfl/b/Audio/model_save'\n",
    "tensorboard_path = '/root/cfl/b/Audio/tb_run'\n",
    "if not os.path.exists(model_save):\n",
    "    os.makedirs(model_save)\n",
    "if not os.path.exists(res_path):\n",
    "    os.makedirs(res_path)\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取特征保存为图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:16:13.716027Z",
     "start_time": "2020-12-06T08:16:13.710570Z"
    }
   },
   "outputs": [],
   "source": [
    "SR = 65535\n",
    "NUM_CLASSES = 30\n",
    "LABELS = os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T07:45:30.396293Z",
     "start_time": "2020-12-06T07:45:30.376749Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop_or_pad(y, length):\n",
    "    if len(y) < length:\n",
    "        y = np.concatenate([y, np.zeros(length - len(y))])\n",
    "    elif len(y) > length:\n",
    "        y = y[: length]\n",
    "    return y\n",
    "\n",
    "def preprocess_train(train_path):\n",
    "    x, y = [], []\n",
    "    for i, label in enumerate(LABELS):\n",
    "        label_dir = os.path.join(train_path, label)\n",
    "        for wav_file in tqdm(os.listdir(label_dir)):\n",
    "            wav_path = os.path.join(train_path, label, wav_file)\n",
    "            wav, sr = lb.load(wav_path, sr=SR)\n",
    "            wav = crop_or_pad(wav, 1*SR)\n",
    "            x.append(wav)\n",
    "            y.append(i)\n",
    "\n",
    "    x, y = np.r_[x], np.r_[y]\n",
    "#     x, y = shuffle(x, y, random_state=GLOBAL_SEED)\n",
    "    return x, y.astype(np.int32)\n",
    "\n",
    "def preprocess_test(test_path):\n",
    "    x, keys = [], []\n",
    "\n",
    "    for wav_file in tqdm(os.listdir(test_path)):\n",
    "        wav_path = os.path.join(test_path, wav_file)\n",
    "        wav, sr = lb.load(wav_path, sr=SR)\n",
    "        wav = crop_or_pad(wav, 1*SR)\n",
    "        x.append(wav)\n",
    "        keys.append(wav_file)\n",
    "    x = np.r_[x] \n",
    "    return x, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T05:32:12.490174Z",
     "start_time": "2020-12-06T04:39:11.135983Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2122/2122 [02:05<00:00, 16.91it/s]\n",
      "100%|██████████| 2095/2095 [02:05<00:00, 16.71it/s]\n",
      "100%|██████████| 2109/2109 [02:17<00:00, 15.39it/s]\n",
      "100%|██████████| 2121/2121 [01:54<00:00, 18.48it/s]\n",
      "100%|██████████| 2138/2138 [01:54<00:00, 18.66it/s]\n",
      "100%|██████████| 1567/1567 [01:23<00:00, 18.76it/s]\n",
      "100%|██████████| 2123/2123 [01:53<00:00, 18.76it/s]\n",
      "100%|██████████| 2126/2126 [01:54<00:00, 18.58it/s]\n",
      "100%|██████████| 2106/2106 [01:53<00:00, 18.63it/s]\n",
      "100%|██████████| 2131/2131 [01:54<00:00, 18.67it/s]\n",
      "100%|██████████| 1562/1562 [01:23<00:00, 18.70it/s]\n",
      "100%|██████████| 1573/1573 [01:23<00:00, 18.75it/s]\n",
      "100%|██████████| 2089/2089 [01:51<00:00, 18.66it/s]\n",
      "100%|██████████| 1584/1584 [01:24<00:00, 18.66it/s]\n",
      "100%|██████████| 2119/2119 [01:53<00:00, 18.66it/s]\n",
      "100%|██████████| 2086/2086 [01:52<00:00, 18.62it/s]\n",
      "100%|██████████| 2108/2108 [01:52<00:00, 18.66it/s]\n",
      "100%|██████████| 1566/1566 [01:23<00:00, 18.74it/s]\n",
      "100%|██████████| 1540/1540 [01:22<00:00, 18.73it/s]\n",
      "100%|██████████| 2125/2125 [01:54<00:00, 18.60it/s]\n",
      "100%|██████████| 2103/2103 [01:51<00:00, 18.81it/s]\n",
      "100%|██████████| 1548/1548 [01:23<00:00, 18.64it/s]\n",
      "100%|██████████| 2121/2121 [01:53<00:00, 18.67it/s]\n",
      "100%|██████████| 1580/1580 [01:24<00:00, 18.74it/s]\n",
      "100%|██████████| 2105/2105 [01:53<00:00, 18.62it/s]\n",
      "100%|██████████| 1600/1600 [01:25<00:00, 18.71it/s]\n",
      "100%|██████████| 2121/2121 [01:53<00:00, 18.73it/s]\n",
      "100%|██████████| 1537/1537 [01:22<00:00, 18.73it/s]\n",
      "100%|██████████| 2086/2086 [01:52<00:00, 18.62it/s]\n",
      "100%|██████████| 2095/2095 [01:52<00:00, 18.68it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = preprocess_train(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T05:38:32.214844Z",
     "start_time": "2020-12-06T05:32:12.492080Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6835/6835 [06:17<00:00, 18.12it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, test_names = preprocess_test(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T05:39:32.039348Z",
     "start_time": "2020-12-06T05:38:32.216928Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savez(os.path.join(feat_path, 'data'), X_train=X_train, X_test=X_test, y=y_train, test_names=test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载特征准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:16:17.349541Z",
     "start_time": "2020-12-06T08:16:17.343094Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.load(os.path.join(feat_path, 'data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:17:01.427890Z",
     "start_time": "2020-12-06T08:16:17.678507Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y']\n",
    "test_names = data['test_names']\n",
    "labels = os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:17:01.515357Z",
     "start_time": "2020-12-06T08:17:01.429686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:17:01.817144Z",
     "start_time": "2020-12-06T08:17:01.517451Z"
    }
   },
   "outputs": [],
   "source": [
    "\"https://www.kaggle.com/gopidurgaprasad/audio-augmentation-albumentations/\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, PolarityInversion, Gain, AddGaussianSNR\n",
    "\n",
    "\n",
    "class AudioTransform(BasicTransform):\n",
    "    \"\"\"Transform for Audio task\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "    \n",
    "      \n",
    "class MelSpectrogram(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, parameters, always_apply=False, p=0.5):\n",
    "        super(MelSpectrogram, self).__init__(always_apply, p)\n",
    "\n",
    "        self.parameters = parameters\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(sound, sr=sr, **self.parameters)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "        melspec = melspec.astype(np.float32)\n",
    "\n",
    "        return melspec, sr\n",
    "    \n",
    "    \n",
    "class SpecAugment(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, num_mask=2, freq_masking=0.15, time_masking=0.20, always_apply=False, p=0.5):\n",
    "        super(SpecAugment, self).__init__(always_apply, p)\n",
    "\n",
    "        self.num_mask = num_mask\n",
    "        self.freq_masking = freq_masking\n",
    "        self.time_masking = time_masking\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "\n",
    "        spec_aug = self.spec_augment(melspec, \n",
    "                                     self.num_mask,\n",
    "                                     self.freq_masking,\n",
    "                                     self.time_masking,\n",
    "                                     melspec.min())\n",
    "        \n",
    "\n",
    "\n",
    "        return spec_aug, sr\n",
    "    \n",
    "    # Source: https://www.kaggle.com/davids1992/specaugment-quick-implementation\n",
    "    def spec_augment(self, \n",
    "                    spec: np.ndarray,\n",
    "                    num_mask=2,\n",
    "                    freq_masking=0.15,\n",
    "                    time_masking=0.20,\n",
    "                    value=0):\n",
    "        spec = spec.copy()\n",
    "        num_mask = random.randint(1, num_mask)\n",
    "        for i in range(num_mask):\n",
    "            all_freqs_num, all_frames_num  = spec.shape\n",
    "            freq_percentage = random.uniform(0.0, freq_masking)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[f0:f0 + num_freqs_to_mask, :] = value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[:, t0:t0 + num_frames_to_mask] = value\n",
    "\n",
    "        return spec\n",
    "\n",
    "    \n",
    "class SpectToImage(AudioTransform):\n",
    "\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(SpectToImage, self).__init__(always_apply, p)\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        image, sr = data\n",
    "        delta = librosa.feature.delta(image)\n",
    "        accelerate = librosa.feature.delta(image, order=2)\n",
    "        image = np.stack([image, delta, accelerate], axis=-1)\n",
    "        image = image.astype(np.float32) / 100.0\n",
    "\n",
    "        return image\n",
    "\n",
    "sound_augment = Compose([\n",
    "    PolarityInversion(p=0.2),\n",
    "    Gain(min_gain_in_db=-15, max_gain_in_db=15, p=0.3),\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.2),\n",
    "    AddGaussianSNR(p=0.2)\n",
    "#     TimeStretch(min_rate=0.8, max_rate=1.25, p=0.2)\n",
    "#     Shift(min_fraction=-0.1, max_fraction=0.1, p=0.2),\n",
    "])\n",
    "\n",
    "\n",
    "melspectrogram_parameters = {\n",
    "        \"n_mels\": 256,\n",
    "        'n_fft': 2048, \n",
    "        'hop_length': 512\n",
    "    }\n",
    "\n",
    "spec_augment = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpecAugment(p=0.2),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "to_image = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "def augment(wav):\n",
    "    data = sound_augment(samples=wav, sample_rate=SR), SR\n",
    "    image = spec_augment(data=data)['data']\n",
    "    return image.transpose(2, 1, 0)\n",
    "\n",
    "def get_image(wav):\n",
    "    data = wav, SR\n",
    "    image = to_image(data=data)['data']\n",
    "    return image.transpose(2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:17:02.028786Z",
     "start_time": "2020-12-06T08:17:01.818682Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, index, is_train=True, is_valid=False):\n",
    "        self.index = index\n",
    "        self.is_train = is_train\n",
    "        self.is_valid = is_valid\n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            if self.is_valid:\n",
    "                img = get_image(X_train[self.index[idx]])\n",
    "            else:\n",
    "                img = augment(X_train[self.index[idx]])\n",
    "            return torch.tensor(img, dtype=torch.float32), y_train[self.index[idx]]\n",
    "        else:\n",
    "            img = get_image(X_test[self.index[idx]])\n",
    "            return torch.tensor(img, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:17:02.045720Z",
     "start_time": "2020-12-06T08:17:02.030433Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN = 128\n",
    "BATCH_SIZE_VAL = 128\n",
    "BATCH_SIZE_TEST = 128\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=GLOBAL_SEED)\n",
    "data_folds = []\n",
    "valid_indexs = []    \n",
    "\n",
    "\n",
    "test_dataset = CustomDataset(np.arange(X_test.shape[0]), is_train=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, sampler=SequentialSampler(test_dataset), shuffle=False, num_workers=4)\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(X=X_train, y=y_train)):\n",
    "    valid_indexs.append(valid_index)\n",
    "    \n",
    "    train_dataset = CustomDataset(train_index, is_train=True)\n",
    "    val_dataset = CustomDataset(valid_index, is_train=True, is_valid=True)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=4)\n",
    "    valid_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, sampler=SequentialSampler(val_dataset), shuffle=False, num_workers=4)\n",
    "    data_folds.append((train_dataloader, valid_dataloader, test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:17:02.079946Z",
     "start_time": "2020-12-06T08:17:02.047325Z"
    }
   },
   "outputs": [],
   "source": [
    "from resnest.torch import resnest50\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:17:16.065422Z",
     "start_time": "2020-12-06T08:17:16.056449Z"
    }
   },
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.densenet161(pretrained=True)\n",
    "        self.model.classifier = nn.Linear(2208, 30)    \n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T08:17:17.080250Z",
     "start_time": "2020-12-06T08:17:17.048402Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader, criterion, history, n_iters):\n",
    "    model.eval()\n",
    "    costs = []\n",
    "    accs = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda().long()\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            costs.append(loss.item())\n",
    "            _, y_preds = torch.max(y_output, 1)\n",
    "            accs.append((y_preds == y).float().mean().item())\n",
    "    mean_accs = np.mean(accs)\n",
    "    mean_costs = np.mean(costs)\n",
    "    writer.add_scalar('age/validate_accuracy', mean_accs, n_iters)\n",
    "    writer.add_scalar('age/validate_loss', mean_costs, n_iters)\n",
    "    if mean_accs > history['best_acc']:  \n",
    "        history['best_acc'] = mean_accs\n",
    "        checkpoint_pth = history['best_model_path']\n",
    "        torch.save(model.state_dict(), checkpoint_pth)\n",
    "    return mean_costs, mean_accs\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, step=True):\n",
    "    model.train()\n",
    "    costs = []\n",
    "    accs = []\n",
    "    val_loss, val_acc = 0, 0\n",
    "    with tqdm(total=len(train_dataloader.dataset), desc='Epoch{}'.format(epoch)) as pbar:\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda().long()\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step:\n",
    "                scheduler.step()\n",
    "            with torch.no_grad():\n",
    "                costs.append(loss.item())\n",
    "                _, y_preds = torch.max(y_output, 1)\n",
    "                accs.append((y_preds == y).float().mean().item())\n",
    "                pbar.update(y.size(0))\n",
    "            n_iters = idx + len(train_dataloader) * (epoch-1)\n",
    "            if idx in validate_points:\n",
    "                val_loss, val_acc = validate(model, val_dataloader, criterion, history, n_iters)\n",
    "                model.train()\n",
    "            \n",
    "            writer.add_scalar('age/train_accuracy', accs[-1], n_iters)\n",
    "            writer.add_scalar('age/train_loss', costs[-1], n_iters)\n",
    "            writer.add_scalar('age/learning_rate', scheduler.get_lr()[0], n_iters)\n",
    "            pbar.set_postfix_str('loss:{:.4f}, acc:{:.4f}, val-loss:{:.4f}, val-acc:{:.4f}'.format(np.mean(costs[-10:]), np.mean(accs[-10:]), val_loss, val_acc))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "def test(oof_train_test, model, test_dataloader, val_dataloader, valid_index, weight=1):\n",
    "    model.eval()\n",
    "    y_preds = []\n",
    "    y_preds_val = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(test_dataloader):\n",
    "            X = batch\n",
    "            X= X.cuda()\n",
    "            y_output = model(X)    \n",
    "            y_preds.append(y_output.cpu())\n",
    "            \n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            X, y = batch\n",
    "            X = X.cuda()\n",
    "            y_output = model(X)\n",
    "            y_preds_val.append(y_output.cpu())\n",
    "    \n",
    "    oof_train_test[valid_index] += F.softmax(torch.cat(y_preds_val)).numpy() * weight\n",
    "    oof_train_test[57886:] += F.softmax(torch.cat(y_preds)).numpy() * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T11:42:09.100989Z",
     "start_time": "2020-12-06T08:18:03.372875Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 46308/46308 [08:02<00:00, 96.05it/s, loss:0.2494, acc:0.9248, val-loss:0.3475, val-acc:0.8942] \n",
      "Epoch2: 100%|██████████| 46308/46308 [07:55<00:00, 97.30it/s, loss:0.1829, acc:0.9444, val-loss:0.1290, val-acc:0.9616] \n",
      "Epoch3: 100%|██████████| 46308/46308 [07:58<00:00, 96.73it/s, loss:0.1444, acc:0.9630, val-loss:0.0991, val-acc:0.9705] \n",
      "Epoch4: 100%|██████████| 46308/46308 [07:59<00:00, 96.65it/s, loss:0.1124, acc:0.9722, val-loss:0.0892, val-acc:0.9734] \n",
      "Epoch5: 100%|██████████| 46308/46308 [07:48<00:00, 98.81it/s, loss:0.1071, acc:0.9689, val-loss:0.0812, val-acc:0.9763] \n",
      "Epoch1: 100%|██████████| 46309/46309 [07:56<00:00, 97.09it/s, loss:0.2573, acc:0.9220, val-loss:0.2728, val-acc:0.9170] \n",
      "Epoch2: 100%|██████████| 46309/46309 [07:58<00:00, 96.86it/s, loss:0.1932, acc:0.9446, val-loss:0.1291, val-acc:0.9606] \n",
      "Epoch3: 100%|██████████| 46309/46309 [07:57<00:00, 96.89it/s, loss:0.1054, acc:0.9722, val-loss:0.1013, val-acc:0.9703] \n",
      "Epoch4: 100%|██████████| 46309/46309 [08:00<00:00, 96.42it/s, loss:0.1201, acc:0.9650, val-loss:0.0924, val-acc:0.9735] \n",
      "Epoch5: 100%|██████████| 46309/46309 [07:57<00:00, 96.98it/s, loss:0.0886, acc:0.9724, val-loss:0.0847, val-acc:0.9751] \n",
      "Epoch1: 100%|██████████| 46309/46309 [07:55<00:00, 97.36it/s, loss:0.2576, acc:0.9261, val-loss:0.3751, val-acc:0.8891] \n",
      "Epoch2: 100%|██████████| 46309/46309 [07:59<00:00, 96.54it/s, loss:0.1429, acc:0.9587, val-loss:0.1499, val-acc:0.9567] \n",
      "Epoch3: 100%|██████████| 46309/46309 [07:58<00:00, 96.69it/s, loss:0.1419, acc:0.9605, val-loss:0.1182, val-acc:0.9657] \n",
      "Epoch4: 100%|██████████| 46309/46309 [07:59<00:00, 96.60it/s, loss:0.0763, acc:0.9783, val-loss:0.1091, val-acc:0.9704] \n",
      "Epoch5: 100%|██████████| 46309/46309 [07:59<00:00, 96.53it/s, loss:0.1003, acc:0.9715, val-loss:0.1060, val-acc:0.9710] \n",
      "Epoch1: 100%|██████████| 46309/46309 [07:57<00:00, 97.02it/s, loss:0.3253, acc:0.9065, val-loss:0.2856, val-acc:0.9159] \n",
      "Epoch2: 100%|██████████| 46309/46309 [07:54<00:00, 97.69it/s, loss:0.1818, acc:0.9468, val-loss:0.1569, val-acc:0.9539] \n",
      "Epoch3: 100%|██████████| 46309/46309 [07:55<00:00, 97.37it/s, loss:0.1194, acc:0.9629, val-loss:0.1059, val-acc:0.9706] \n",
      "Epoch4: 100%|██████████| 46309/46309 [07:56<00:00, 97.17it/s, loss:0.0959, acc:0.9693, val-loss:0.0920, val-acc:0.9730] \n",
      "Epoch5: 100%|██████████| 46309/46309 [07:56<00:00, 97.21it/s, loss:0.0930, acc:0.9761, val-loss:0.0860, val-acc:0.9762] \n",
      "Epoch1: 100%|██████████| 46309/46309 [07:57<00:00, 96.91it/s, loss:0.2837, acc:0.9143, val-loss:0.3624, val-acc:0.8880] \n",
      "Epoch2: 100%|██████████| 46309/46309 [07:53<00:00, 97.70it/s, loss:0.1588, acc:0.9510, val-loss:0.1216, val-acc:0.9662] \n",
      "Epoch3: 100%|██████████| 46309/46309 [07:47<00:00, 98.96it/s, loss:0.1329, acc:0.9548, val-loss:0.0873, val-acc:0.9760] \n",
      "Epoch4: 100%|██████████| 46309/46309 [07:51<00:00, 98.15it/s, loss:0.0963, acc:0.9718, val-loss:0.0820, val-acc:0.9771] \n",
      "Epoch5: 100%|██████████| 46309/46309 [07:50<00:00, 98.33it/s, loss:0.0871, acc:0.9730, val-loss:0.0767, val-acc:0.9790] \n"
     ]
    }
   ],
   "source": [
    "def criterion(y_output, y_true):\n",
    "    loss = nn.CrossEntropyLoss()(y_output, y_true)\n",
    "    return loss\n",
    "\n",
    "res_folds = []\n",
    "acc_folds = []\n",
    "model_name = 'densenet161_augment_0'\n",
    "for idx, (train_dataloader, val_dataloader, test_dataloader) in enumerate(data_folds):\n",
    "    oof_train_test = np.zeros((X_train.shape[0] + X_test.shape[0], 30))\n",
    "    history = {'best_acc': 0, 'best_model_path':os.path.join(model_save, '{}_checkpoint_fold_{}.pth'.format(model_name, idx))}\n",
    "    validate_points = list(np.linspace(0, len(train_dataloader)-1, 3).astype(int))[1:]\n",
    "    model = DenseNet().cuda()\n",
    "#     model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.999), lr=1e-3)\n",
    "    epochs = 5\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "#     scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-5, max_lr=2e-3, step_size_up=int(len(train_dataloader)/2), cycle_momentum=False, mode='triangular')\n",
    "#     scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, epochs=epochs, steps_per_epoch=len(train_dataloader), pct_start=0.2, anneal_strategy='linear', div_factor=30, final_div_factor=1e4)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        writer = SummaryWriter(log_dir=os.path.join(tensorboard_path, '{}_fold_{}'.format(model_name, idx)))\n",
    "        train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, step=False)\n",
    "        scheduler.step()\n",
    "        gc.collect()\n",
    "    model.load_state_dict(torch.load(history['best_model_path'], map_location= torch.device('cpu')), strict=True)\n",
    "    test(oof_train_test, model, test_dataloader, val_dataloader, valid_indexs[idx], weight=1)\n",
    "    acc_folds.append(history['best_acc'])\n",
    "    res_folds.append(oof_train_test)\n",
    "    np.save(os.path.join(res_path, \"{}_fold_{}.npy\".format(model_name, idx)), oof_train_test)\n",
    "    del model, history \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:21:12.145134Z",
     "start_time": "2020-12-06T12:21:12.137063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9762694200316628,\n",
       " 0.9750819356886895,\n",
       " 0.9709821428571429,\n",
       " 0.9762416861869476,\n",
       " 0.9791380494505495]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:21:53.406132Z",
     "start_time": "2020-12-06T12:21:53.391588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [7.85733759e-02, 4.25898797e-05, 3.19214882e-06, ...,\n",
       "         9.37322238e-06, 3.30220617e-04, 5.94436733e-06],\n",
       "        [9.99553263e-01, 2.14319229e-07, 4.09443608e-08, ...,\n",
       "         1.15420889e-07, 1.89542170e-05, 9.49692147e-09],\n",
       "        ...,\n",
       "        [1.10477504e-06, 2.02628271e-05, 1.64571829e-05, ...,\n",
       "         6.38984488e-07, 1.03654684e-05, 5.91033881e-07],\n",
       "        [1.57495541e-03, 1.76962127e-03, 4.35744151e-02, ...,\n",
       "         1.51485763e-03, 3.20568425e-03, 1.65873766e-03],\n",
       "        [6.98836402e-07, 6.13883856e-07, 2.10523172e-06, ...,\n",
       "         9.73290870e-09, 2.33207658e-07, 6.19521012e-09]]),\n",
       " array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [2.41159323e-05, 9.68836757e-05, 6.28635462e-05, ...,\n",
       "         3.10805422e-06, 2.89240816e-05, 1.17068817e-06],\n",
       "        [2.17054831e-03, 1.65374111e-03, 2.24933005e-03, ...,\n",
       "         6.13339851e-03, 1.94429886e-03, 9.36375698e-04],\n",
       "        [2.02155115e-06, 1.68478346e-06, 7.27919087e-06, ...,\n",
       "         2.12401918e-08, 1.95450411e-06, 1.55446376e-08]]),\n",
       " array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [3.88583402e-07, 6.06853973e-06, 1.62180527e-06, ...,\n",
       "         5.55674653e-08, 8.77987168e-06, 2.13328892e-08],\n",
       "        [4.96507483e-03, 8.20185174e-04, 8.72363150e-03, ...,\n",
       "         4.81339172e-03, 6.92333048e-03, 9.48251050e-04],\n",
       "        [2.45468840e-07, 3.09244996e-07, 1.79466178e-06, ...,\n",
       "         6.97192792e-09, 2.37945855e-07, 2.06274220e-09]]),\n",
       " array([[9.97874856e-01, 3.89340994e-06, 1.81551947e-08, ...,\n",
       "         1.37726587e-07, 3.97496879e-05, 7.28014200e-08],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [6.26559427e-07, 7.57104817e-06, 7.19394984e-06, ...,\n",
       "         1.89291995e-07, 1.48630636e-06, 2.12929745e-08],\n",
       "        [1.32636307e-03, 5.59678185e-04, 1.02179721e-02, ...,\n",
       "         7.44999968e-04, 6.27269968e-04, 5.72900579e-04],\n",
       "        [1.09287828e-06, 9.90412218e-07, 7.43137662e-07, ...,\n",
       "         2.66068163e-08, 5.02589444e-07, 1.41313672e-08]]),\n",
       " array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [1.10963434e-08, 5.76047455e-07, 2.87413627e-07, ...,\n",
       "         2.01141503e-09, 3.25061393e-07, 1.26476944e-08],\n",
       "        [3.61810642e-04, 9.48797737e-04, 6.34801621e-03, ...,\n",
       "         1.40385656e-03, 5.81302156e-04, 1.38710614e-03],\n",
       "        [3.51727920e-07, 6.76048941e-08, 8.53405879e-07, ...,\n",
       "         1.45330592e-08, 9.57117436e-07, 7.15137238e-09]])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:21:56.099725Z",
     "start_time": "2020-12-06T12:21:55.983307Z"
    }
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(data_folds)):\n",
    "    res.append(np.load(os.path.join(res_path, \"{}_fold_{}.npy\".format(model_name, i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:22:09.633601Z",
     "start_time": "2020-12-06T12:22:09.543264Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['file_name'] = test_names\n",
    "sub['label'] = np.argmax(np.mean(res, axis=0)[57886:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:22:10.554114Z",
     "start_time": "2020-12-06T12:22:10.480453Z"
    }
   },
   "outputs": [],
   "source": [
    "sub['label'] = sub['label'].map({i:label for i, label in enumerate(labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:22:11.640622Z",
     "start_time": "2020-12-06T12:22:11.604864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3o9p4zffh0.wav</td>\n",
       "      <td>marvin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>srdw856mtq.wav</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k42nwx43w4.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6km36wy1rq.wav</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mi8mrzrdra.wav</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6830</th>\n",
       "      <td>mk1xjjrsuv.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6831</th>\n",
       "      <td>0ctd4hbh13.wav</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6832</th>\n",
       "      <td>akuoa16fdq.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6833</th>\n",
       "      <td>vrjj8ay7x0.wav</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>957wa0sngr.wav</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6835 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name   label\n",
       "0     3o9p4zffh0.wav  marvin\n",
       "1     srdw856mtq.wav   three\n",
       "2     k42nwx43w4.wav     yes\n",
       "3     6km36wy1rq.wav    five\n",
       "4     mi8mrzrdra.wav     two\n",
       "...              ...     ...\n",
       "6830  mk1xjjrsuv.wav   happy\n",
       "6831  0ctd4hbh13.wav     two\n",
       "6832  akuoa16fdq.wav    stop\n",
       "6833  vrjj8ay7x0.wav    tree\n",
       "6834  957wa0sngr.wav    four\n",
       "\n",
       "[6835 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:23:25.226268Z",
     "start_time": "2020-12-06T12:23:25.201280Z"
    }
   },
   "outputs": [],
   "source": [
    "now = time.strftime(\"%Y%m%d_%H%M%S\",time.localtime(time.time())) \n",
    "fname=\"submit_\" + model_name + \"_\" + now + \".csv\"    \n",
    "sub.to_csv(os.path.join(res_path, fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('py36_torch': conda)",
   "language": "python",
   "name": "python361064bitpy36torchcondaa3855d064b844135ba48c06bf4a0fbc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
