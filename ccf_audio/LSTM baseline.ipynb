{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T11:39:00.638005Z",
     "start_time": "2020-12-04T11:39:00.628055Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import pandas as pd\n",
    "import random\n",
    "import heapq\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:20:21.809911Z",
     "start_time": "2020-12-04T10:20:21.455904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:20:21.824871Z",
     "start_time": "2020-12-04T10:20:21.810909Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "GLOBAL_SEED = 42\n",
    "setup_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:20:21.840828Z",
     "start_time": "2020-12-04T10:20:21.825868Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = './data/train'\n",
    "test_path = './data/test'\n",
    "feat_path = './features'\n",
    "res_path = './res'\n",
    "model_save = './model_save'\n",
    "tensorboard_path = './tb_run'\n",
    "if not os.path.exists(model_save):\n",
    "    os.makedirs(model_save)\n",
    "if not os.path.exists(res_path):\n",
    "    os.makedirs(res_path)\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取提取好的特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:20:27.861248Z",
     "start_time": "2020-12-04T10:20:27.848282Z"
    }
   },
   "outputs": [],
   "source": [
    "melspec = np.load(os.path.join(feat_path, 'melspec_256.npz'))\n",
    "basic_feature = np.load(os.path.join(feat_path, 'basic_feature.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:20:31.257328Z",
     "start_time": "2020-12-04T10:20:28.079778Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate([melspec['X'], basic_feature['X']], axis=-1)\n",
    "X_train = X[:57886] \n",
    "X_test = X[57886:]\n",
    "y_train = melspec['y']\n",
    "test_names = melspec['test_names']\n",
    "labels = os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:20:31.305207Z",
     "start_time": "2020-12-04T10:20:31.258305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del melspec, basic_feature\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:20:31.320313Z",
     "start_time": "2020-12-04T10:20:31.306177Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:20:33.306027Z",
     "start_time": "2020-12-04T10:20:31.321307Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN = 256\n",
    "BATCH_SIZE_VAL = 256\n",
    "BATCH_SIZE_TEST = 256\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=GLOBAL_SEED)\n",
    "data_folds = []\n",
    "valid_indexs = []    \n",
    "\n",
    "\n",
    "test_dataset = CustomDataset(X_test, np.random.rand(X_test.shape[0], 1))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, sampler=SequentialSampler(test_dataset), shuffle=False, num_workers=0)\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(X=X_train, y=y_train)):\n",
    "    valid_indexs.append(valid_index)\n",
    "    \n",
    "    train_dataset = CustomDataset(X_train[train_index], y_train[train_index])\n",
    "    val_dataset = CustomDataset(X_train[valid_index], y_train[valid_index])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=0)\n",
    "    valid_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, sampler=SequentialSampler(val_dataset), shuffle=False, num_workers=0)\n",
    "    data_folds.append((train_dataloader, valid_dataloader, test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:20:33.321982Z",
     "start_time": "2020-12-04T10:20:33.307025Z"
    }
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, feature_dim, lstm_size, fc1, fc2, num_layers=1, rnn_dropout=0.2, embedding_dropout=0.2, fc_dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size = feature_dim, \n",
    "                          hidden_size = lstm_size, \n",
    "                          num_layers = num_layers,\n",
    "                          bidirectional = True, \n",
    "                          batch_first = True, \n",
    "                          dropout = rnn_dropout) \n",
    "                                                  \n",
    "        self.fc1 = nn.Linear(2*lstm_size, fc1)\n",
    "        self.fc2 = nn.Linear(fc1, fc2)\n",
    "        self.fc3 = nn.Linear(fc2, 30)\n",
    "        \n",
    "        self.rnn_dropout = nn.Dropout(rnn_dropout)\n",
    "        self.embedding_dropout = nn.Dropout(embedding_dropout)\n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        batch_size, total_length, _= X.size()\n",
    "        X = self.embedding_dropout(X)\n",
    "        lstm_output, (h_n, c_n) = self.lstm(X)\n",
    "        # lstm_output shape: (batchsize, total_length, 2*lstm_size)\n",
    "        max_output = F.max_pool2d(lstm_output, (total_length, 1), stride=(1, 1)).squeeze()\n",
    "        # output shape: (batchsize, 2*lstm_size)\n",
    "        fc_out = F.relu(self.fc1(max_output))\n",
    "        fc_out = self.fc_dropout(fc_out)\n",
    "        fc_out = F.relu(self.fc2(fc_out))\n",
    "        pred = self.fc3(fc_out)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:20:33.351901Z",
     "start_time": "2020-12-04T10:20:33.322955Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader, criterion, history, n_iters):\n",
    "    model.eval()\n",
    "    costs = []\n",
    "    accs = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda().long()\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            costs.append(loss.item())\n",
    "            _, y_preds = torch.max(y_output, 1)\n",
    "            accs.append((y_preds == y).float().mean().item())\n",
    "    mean_accs = np.mean(accs)\n",
    "    mean_costs = np.mean(costs)\n",
    "    writer.add_scalar('age/validate_accuracy', mean_accs, n_iters)\n",
    "    writer.add_scalar('age/validate_loss', mean_costs, n_iters)\n",
    "    if mean_accs > history['best_model'][0][0]:  \n",
    "        heapq.heapify(history['best_model'])\n",
    "        checkpoint_pth = history['best_model'][0][1]\n",
    "        heapq.heappushpop(history['best_model'], (mean_accs, checkpoint_pth))\n",
    "        torch.save(model.state_dict(), checkpoint_pth)\n",
    "    return mean_costs, mean_accs\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, step=True):\n",
    "    model.train()\n",
    "    costs = []\n",
    "    accs = []\n",
    "    val_loss, val_acc = 0, 0\n",
    "    with tqdm(total=len(train_dataloader.dataset), desc='Epoch{}'.format(epoch)) as pbar:\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda().long()\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step:\n",
    "                scheduler.step()\n",
    "            with torch.no_grad():\n",
    "                costs.append(loss.item())\n",
    "                _, y_preds = torch.max(y_output, 1)\n",
    "                accs.append((y_preds == y).float().mean().item())\n",
    "                pbar.update(y.size(0))\n",
    "            n_iters = idx + len(train_dataloader) * (epoch-1)\n",
    "            if idx in validate_points:\n",
    "                val_loss, val_acc = validate(model, val_dataloader, criterion, history, n_iters)\n",
    "                model.train()\n",
    "            \n",
    "            writer.add_scalar('age/train_accuracy', accs[-1], n_iters)\n",
    "            writer.add_scalar('age/train_loss', costs[-1], n_iters)\n",
    "            writer.add_scalar('age/learning_rate', scheduler.get_lr()[0], n_iters)\n",
    "            pbar.set_postfix_str('loss:{:.4f}, acc:{:.4f}, val-loss:{:.4f}, val-acc:{:.4f}'.format(np.mean(costs[-10:]), np.mean(accs[-10:]), val_loss, val_acc))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "def test(oof_train_test, model, test_dataloader, val_dataloader, valid_index, weight=1):\n",
    "    model.eval()\n",
    "    y_preds = []\n",
    "    y_preds_val = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(test_dataloader):\n",
    "            X, _ = batch\n",
    "            X= X.cuda()\n",
    "            y_output = model(X)    \n",
    "            y_preds.append(y_output.cpu())\n",
    "            \n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            X, y = batch\n",
    "            X = X.cuda()\n",
    "            y_output = model(X)\n",
    "            y_preds_val.append(y_output.cpu())\n",
    "    \n",
    "    oof_train_test[valid_index] += F.softmax(torch.cat(y_preds_val)).numpy() * weight\n",
    "    oof_train_test[57886:] += F.softmax(torch.cat(y_preds)).numpy() * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:52:27.357790Z",
     "start_time": "2020-12-04T10:20:33.352875Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|████████| 46305/46305 [00:17<00:00, 2700.29it/s, loss:1.2725, acc:0.5989, val-loss:1.2068, val-acc:0.6232]\n",
      "Epoch2: 100%|████████| 46305/46305 [00:15<00:00, 2911.47it/s, loss:0.7248, acc:0.7743, val-loss:0.6943, val-acc:0.7818]\n",
      "Epoch3: 100%|████████| 46305/46305 [00:16<00:00, 2850.33it/s, loss:0.5933, acc:0.8082, val-loss:0.5623, val-acc:0.8234]\n",
      "Epoch4: 100%|████████| 46305/46305 [00:16<00:00, 2882.69it/s, loss:0.5001, acc:0.8439, val-loss:0.5121, val-acc:0.8385]\n",
      "Epoch5: 100%|████████| 46305/46305 [00:15<00:00, 2926.97it/s, loss:0.4874, acc:0.8394, val-loss:0.4641, val-acc:0.8547]\n",
      "Epoch6: 100%|████████| 46305/46305 [00:15<00:00, 2912.29it/s, loss:0.4357, acc:0.8620, val-loss:0.4372, val-acc:0.8630]\n",
      "Epoch7: 100%|████████| 46305/46305 [00:15<00:00, 2918.11it/s, loss:0.4224, acc:0.8618, val-loss:0.4076, val-acc:0.8673]\n",
      "Epoch8: 100%|████████| 46305/46305 [00:15<00:00, 2916.24it/s, loss:0.3952, acc:0.8777, val-loss:0.3901, val-acc:0.8795]\n",
      "Epoch9: 100%|████████| 46305/46305 [00:15<00:00, 2923.55it/s, loss:0.3724, acc:0.8837, val-loss:0.3857, val-acc:0.8801]\n",
      "Epoch10: 100%|███████| 46305/46305 [00:15<00:00, 2920.95it/s, loss:0.3498, acc:0.8852, val-loss:0.3717, val-acc:0.8851]\n",
      "Epoch11: 100%|███████| 46305/46305 [00:15<00:00, 2912.00it/s, loss:0.3418, acc:0.8907, val-loss:0.3678, val-acc:0.8844]\n",
      "Epoch12: 100%|███████| 46305/46305 [00:15<00:00, 2914.19it/s, loss:0.3216, acc:0.9048, val-loss:0.3581, val-acc:0.8873]\n",
      "Epoch13: 100%|███████| 46305/46305 [00:15<00:00, 2929.26it/s, loss:0.3213, acc:0.8914, val-loss:0.3495, val-acc:0.8925]\n",
      "Epoch14: 100%|███████| 46305/46305 [00:15<00:00, 2901.51it/s, loss:0.3211, acc:0.8952, val-loss:0.3524, val-acc:0.8896]\n",
      "Epoch15: 100%|███████| 46305/46305 [00:15<00:00, 2926.95it/s, loss:0.2830, acc:0.9119, val-loss:0.3445, val-acc:0.8940]\n",
      "Epoch16: 100%|███████| 46305/46305 [00:15<00:00, 2919.23it/s, loss:0.3015, acc:0.9049, val-loss:0.3345, val-acc:0.8959]\n",
      "Epoch17: 100%|███████| 46305/46305 [00:15<00:00, 2929.50it/s, loss:0.2943, acc:0.9117, val-loss:0.3576, val-acc:0.8896]\n",
      "Epoch18: 100%|███████| 46305/46305 [00:15<00:00, 2928.11it/s, loss:0.2833, acc:0.9105, val-loss:0.3469, val-acc:0.8920]\n",
      "Epoch19: 100%|███████| 46305/46305 [00:15<00:00, 2899.53it/s, loss:0.2997, acc:0.9064, val-loss:0.3382, val-acc:0.8944]\n",
      "Epoch20: 100%|███████| 46305/46305 [00:15<00:00, 2902.79it/s, loss:0.2795, acc:0.9118, val-loss:0.3418, val-acc:0.8968]\n",
      "Epoch21: 100%|███████| 46305/46305 [00:15<00:00, 2923.92it/s, loss:0.2463, acc:0.9145, val-loss:0.3233, val-acc:0.9000]\n",
      "Epoch22: 100%|███████| 46305/46305 [00:15<00:00, 2925.30it/s, loss:0.3092, acc:0.8990, val-loss:0.3245, val-acc:0.9009]\n",
      "Epoch23: 100%|███████| 46305/46305 [00:15<00:00, 2923.30it/s, loss:0.2404, acc:0.9201, val-loss:0.3152, val-acc:0.9019]\n",
      "Epoch24: 100%|███████| 46305/46305 [00:15<00:00, 2925.21it/s, loss:0.2593, acc:0.9183, val-loss:0.3232, val-acc:0.9024]\n",
      "Epoch25: 100%|███████| 46305/46305 [00:15<00:00, 2937.23it/s, loss:0.2807, acc:0.9065, val-loss:0.3476, val-acc:0.8935]\n",
      "Epoch26: 100%|███████| 46305/46305 [00:15<00:00, 2917.01it/s, loss:0.2593, acc:0.9203, val-loss:0.3305, val-acc:0.9017]\n",
      "Epoch27: 100%|███████| 46305/46305 [00:15<00:00, 2918.20it/s, loss:0.2646, acc:0.9204, val-loss:0.3171, val-acc:0.9041]\n",
      "Epoch28: 100%|███████| 46305/46305 [00:15<00:00, 2932.60it/s, loss:0.2585, acc:0.9205, val-loss:0.3262, val-acc:0.9014]\n",
      "Epoch29: 100%|███████| 46305/46305 [00:15<00:00, 2927.37it/s, loss:0.2623, acc:0.9140, val-loss:0.3134, val-acc:0.9047]\n",
      "Epoch30: 100%|███████| 46305/46305 [00:15<00:00, 2921.26it/s, loss:0.2613, acc:0.9163, val-loss:0.3191, val-acc:0.9057]\n",
      "Epoch1: 100%|████████| 46309/46309 [00:15<00:00, 2899.89it/s, loss:1.3046, acc:0.5826, val-loss:1.2774, val-acc:0.6009]\n",
      "Epoch2: 100%|████████| 46309/46309 [00:15<00:00, 2919.91it/s, loss:0.7500, acc:0.7464, val-loss:0.7318, val-acc:0.7701]\n",
      "Epoch3: 100%|████████| 46309/46309 [00:15<00:00, 2925.46it/s, loss:0.6639, acc:0.7866, val-loss:0.6203, val-acc:0.8030]\n",
      "Epoch4: 100%|████████| 46309/46309 [00:15<00:00, 2918.60it/s, loss:0.5608, acc:0.8178, val-loss:0.5295, val-acc:0.8293]\n",
      "Epoch5: 100%|████████| 46309/46309 [00:15<00:00, 2942.80it/s, loss:0.4952, acc:0.8463, val-loss:0.4934, val-acc:0.8436]\n",
      "Epoch6: 100%|████████| 46309/46309 [00:15<00:00, 2939.96it/s, loss:0.4509, acc:0.8538, val-loss:0.4544, val-acc:0.8537]\n",
      "Epoch7: 100%|████████| 46309/46309 [00:15<00:00, 2930.72it/s, loss:0.4249, acc:0.8686, val-loss:0.4403, val-acc:0.8628]\n",
      "Epoch8: 100%|████████| 46309/46309 [00:15<00:00, 2934.70it/s, loss:0.4117, acc:0.8698, val-loss:0.4338, val-acc:0.8649]\n",
      "Epoch9: 100%|████████| 46309/46309 [00:15<00:00, 2947.11it/s, loss:0.4204, acc:0.8674, val-loss:0.4196, val-acc:0.8689]\n",
      "Epoch10: 100%|███████| 46309/46309 [00:15<00:00, 2929.01it/s, loss:0.3811, acc:0.8850, val-loss:0.4113, val-acc:0.8722]\n",
      "Epoch11: 100%|███████| 46309/46309 [00:15<00:00, 2946.29it/s, loss:0.3305, acc:0.8978, val-loss:0.3989, val-acc:0.8750]\n",
      "Epoch12: 100%|███████| 46309/46309 [00:15<00:00, 2937.78it/s, loss:0.3260, acc:0.8961, val-loss:0.3812, val-acc:0.8816]\n",
      "Epoch13: 100%|███████| 46309/46309 [00:15<00:00, 2931.62it/s, loss:0.3073, acc:0.9003, val-loss:0.3753, val-acc:0.8830]\n",
      "Epoch14: 100%|███████| 46309/46309 [00:15<00:00, 2938.17it/s, loss:0.2752, acc:0.9119, val-loss:0.3552, val-acc:0.8928]\n",
      "Epoch15: 100%|███████| 46309/46309 [00:15<00:00, 2953.47it/s, loss:0.3132, acc:0.9028, val-loss:0.3588, val-acc:0.8922]\n",
      "Epoch16: 100%|███████| 46309/46309 [00:15<00:00, 2931.71it/s, loss:0.3131, acc:0.9052, val-loss:0.3496, val-acc:0.8916]\n",
      "Epoch17: 100%|███████| 46309/46309 [00:15<00:00, 2951.64it/s, loss:0.2844, acc:0.9106, val-loss:0.3462, val-acc:0.8918]\n",
      "Epoch18: 100%|███████| 46309/46309 [00:15<00:00, 2954.10it/s, loss:0.3228, acc:0.8984, val-loss:0.3598, val-acc:0.8903]\n",
      "Epoch19: 100%|███████| 46309/46309 [00:15<00:00, 2934.45it/s, loss:0.2800, acc:0.9140, val-loss:0.3437, val-acc:0.8939]\n",
      "Epoch20: 100%|███████| 46309/46309 [00:15<00:00, 2942.85it/s, loss:0.2908, acc:0.9093, val-loss:0.3403, val-acc:0.8985]\n",
      "Epoch21: 100%|███████| 46309/46309 [00:15<00:00, 2950.68it/s, loss:0.2792, acc:0.9168, val-loss:0.3451, val-acc:0.8984]\n",
      "Epoch22: 100%|███████| 46309/46309 [00:15<00:00, 2930.23it/s, loss:0.2848, acc:0.9111, val-loss:0.3476, val-acc:0.8970]\n",
      "Epoch23: 100%|███████| 46309/46309 [00:15<00:00, 2966.40it/s, loss:0.2836, acc:0.9181, val-loss:0.3619, val-acc:0.8907]\n",
      "Epoch24: 100%|███████| 46309/46309 [00:15<00:00, 2960.97it/s, loss:0.2593, acc:0.9168, val-loss:0.3458, val-acc:0.8961]\n",
      "Epoch25: 100%|███████| 46309/46309 [00:15<00:00, 2953.47it/s, loss:0.2970, acc:0.9086, val-loss:0.3471, val-acc:0.8965]\n",
      "Epoch26: 100%|███████| 46309/46309 [00:15<00:00, 2945.69it/s, loss:0.2845, acc:0.9096, val-loss:0.3353, val-acc:0.8994]\n",
      "Epoch27: 100%|███████| 46309/46309 [00:15<00:00, 2966.46it/s, loss:0.2809, acc:0.9128, val-loss:0.3480, val-acc:0.8931]\n",
      "Epoch28: 100%|███████| 46309/46309 [00:15<00:00, 2936.72it/s, loss:0.2653, acc:0.9093, val-loss:0.3240, val-acc:0.9032]\n",
      "Epoch29: 100%|███████| 46309/46309 [00:15<00:00, 2968.55it/s, loss:0.2738, acc:0.9183, val-loss:0.3540, val-acc:0.8917]\n",
      "Epoch30: 100%|███████| 46309/46309 [00:15<00:00, 2945.01it/s, loss:0.2594, acc:0.9184, val-loss:0.3225, val-acc:0.9008]\n",
      "Epoch1: 100%|████████| 46315/46315 [00:16<00:00, 2875.41it/s, loss:1.3382, acc:0.5871, val-loss:1.3046, val-acc:0.5908]\n",
      "Epoch2: 100%|████████| 46315/46315 [00:15<00:00, 2950.88it/s, loss:0.7278, acc:0.7674, val-loss:0.7112, val-acc:0.7754]\n",
      "Epoch3: 100%|████████| 46315/46315 [00:15<00:00, 2958.89it/s, loss:0.5836, acc:0.8158, val-loss:0.5919, val-acc:0.8149]\n",
      "Epoch4: 100%|████████| 46315/46315 [00:15<00:00, 2970.23it/s, loss:0.5119, acc:0.8399, val-loss:0.5114, val-acc:0.8400]\n",
      "Epoch5: 100%|████████| 46315/46315 [00:15<00:00, 2954.94it/s, loss:0.4424, acc:0.8520, val-loss:0.4865, val-acc:0.8464]\n",
      "Epoch6: 100%|████████| 46315/46315 [00:15<00:00, 2958.50it/s, loss:0.4676, acc:0.8505, val-loss:0.4597, val-acc:0.8551]\n",
      "Epoch7: 100%|████████| 46315/46315 [00:15<00:00, 2960.37it/s, loss:0.4587, acc:0.8523, val-loss:0.4524, val-acc:0.8590]\n",
      "Epoch8: 100%|████████| 46315/46315 [00:15<00:00, 2961.32it/s, loss:0.4240, acc:0.8660, val-loss:0.4294, val-acc:0.8674]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch9: 100%|████████| 46315/46315 [00:15<00:00, 2968.04it/s, loss:0.3773, acc:0.8813, val-loss:0.4198, val-acc:0.8674]\n",
      "Epoch10: 100%|███████| 46315/46315 [00:15<00:00, 2964.07it/s, loss:0.4045, acc:0.8727, val-loss:0.4211, val-acc:0.8723]\n",
      "Epoch11: 100%|███████| 46315/46315 [00:15<00:00, 2963.26it/s, loss:0.3817, acc:0.8771, val-loss:0.4060, val-acc:0.8772]\n",
      "Epoch12: 100%|███████| 46315/46315 [00:15<00:00, 2966.17it/s, loss:0.3203, acc:0.8994, val-loss:0.3994, val-acc:0.8802]\n",
      "Epoch13: 100%|███████| 46315/46315 [00:15<00:00, 2965.09it/s, loss:0.3583, acc:0.8840, val-loss:0.4057, val-acc:0.8764]\n",
      "Epoch14: 100%|███████| 46315/46315 [00:15<00:00, 2966.37it/s, loss:0.3234, acc:0.8985, val-loss:0.3685, val-acc:0.8865]\n",
      "Epoch15: 100%|███████| 46315/46315 [00:15<00:00, 2974.78it/s, loss:0.3663, acc:0.8828, val-loss:0.3874, val-acc:0.8854]\n",
      "Epoch16: 100%|███████| 46315/46315 [00:15<00:00, 2971.14it/s, loss:0.3303, acc:0.8946, val-loss:0.3706, val-acc:0.8883]\n",
      "Epoch17: 100%|███████| 46315/46315 [00:15<00:00, 2966.06it/s, loss:0.2864, acc:0.9026, val-loss:0.3722, val-acc:0.8909]\n",
      "Epoch18: 100%|███████| 46315/46315 [00:15<00:00, 2978.44it/s, loss:0.2907, acc:0.9106, val-loss:0.3781, val-acc:0.8849]\n",
      "Epoch19: 100%|███████| 46315/46315 [00:15<00:00, 3026.04it/s, loss:0.2807, acc:0.9114, val-loss:0.3755, val-acc:0.8865]\n",
      "Epoch20: 100%|███████| 46315/46315 [00:15<00:00, 3010.65it/s, loss:0.3156, acc:0.9017, val-loss:0.3664, val-acc:0.8875]\n",
      "Epoch21: 100%|███████| 46315/46315 [00:15<00:00, 3033.47it/s, loss:0.3417, acc:0.8883, val-loss:0.3766, val-acc:0.8853]\n",
      "Epoch22: 100%|███████| 46315/46315 [00:15<00:00, 3012.38it/s, loss:0.2790, acc:0.9106, val-loss:0.3652, val-acc:0.8910]\n",
      "Epoch23: 100%|███████| 46315/46315 [00:15<00:00, 2950.27it/s, loss:0.2882, acc:0.9060, val-loss:0.3527, val-acc:0.8944]\n",
      "Epoch24: 100%|███████| 46315/46315 [00:15<00:00, 2973.13it/s, loss:0.3074, acc:0.9025, val-loss:0.3494, val-acc:0.8955]\n",
      "Epoch25: 100%|███████| 46315/46315 [00:16<00:00, 2796.59it/s, loss:0.2894, acc:0.9100, val-loss:0.3475, val-acc:0.8977]\n",
      "Epoch26: 100%|███████| 46315/46315 [00:15<00:00, 2944.50it/s, loss:0.2792, acc:0.9089, val-loss:0.3583, val-acc:0.8937]\n",
      "Epoch27: 100%|███████| 46315/46315 [00:15<00:00, 2951.28it/s, loss:0.2765, acc:0.9113, val-loss:0.3550, val-acc:0.8962]\n",
      "Epoch28: 100%|███████| 46315/46315 [00:15<00:00, 2971.84it/s, loss:0.2954, acc:0.9103, val-loss:0.3597, val-acc:0.8908]\n",
      "Epoch29: 100%|███████| 46315/46315 [00:15<00:00, 2964.00it/s, loss:0.2746, acc:0.9146, val-loss:0.3716, val-acc:0.8893]\n",
      "Epoch30: 100%|███████| 46315/46315 [00:15<00:00, 2941.82it/s, loss:0.2825, acc:0.9150, val-loss:0.3503, val-acc:0.8958]\n",
      "Epoch1: 100%|████████| 46319/46319 [00:16<00:00, 2872.32it/s, loss:1.3131, acc:0.5830, val-loss:1.2516, val-acc:0.6092]\n",
      "Epoch2: 100%|████████| 46319/46319 [00:16<00:00, 2826.12it/s, loss:0.7012, acc:0.7765, val-loss:0.7044, val-acc:0.7766]\n",
      "Epoch3: 100%|████████| 46319/46319 [00:16<00:00, 2887.05it/s, loss:0.5758, acc:0.8275, val-loss:0.5730, val-acc:0.8197]\n",
      "Epoch4: 100%|████████| 46319/46319 [00:15<00:00, 2934.05it/s, loss:0.5460, acc:0.8281, val-loss:0.5106, val-acc:0.8400]\n",
      "Epoch5: 100%|████████| 46319/46319 [00:15<00:00, 2958.13it/s, loss:0.4699, acc:0.8534, val-loss:0.4770, val-acc:0.8504]\n",
      "Epoch6: 100%|████████| 46319/46319 [00:15<00:00, 2948.37it/s, loss:0.4692, acc:0.8534, val-loss:0.4648, val-acc:0.8527]\n",
      "Epoch7: 100%|████████| 46319/46319 [00:15<00:00, 2950.38it/s, loss:0.3843, acc:0.8744, val-loss:0.4348, val-acc:0.8653]\n",
      "Epoch8: 100%|████████| 46319/46319 [00:15<00:00, 2949.20it/s, loss:0.4150, acc:0.8660, val-loss:0.4214, val-acc:0.8730]\n",
      "Epoch9: 100%|████████| 46319/46319 [00:15<00:00, 2943.74it/s, loss:0.3699, acc:0.8778, val-loss:0.4040, val-acc:0.8741]\n",
      "Epoch10: 100%|███████| 46319/46319 [00:16<00:00, 2863.49it/s, loss:0.3536, acc:0.8877, val-loss:0.3859, val-acc:0.8799]\n",
      "Epoch11: 100%|███████| 46319/46319 [00:15<00:00, 2950.44it/s, loss:0.3308, acc:0.9010, val-loss:0.3722, val-acc:0.8839]\n",
      "Epoch12: 100%|███████| 46319/46319 [00:15<00:00, 2978.10it/s, loss:0.3416, acc:0.8852, val-loss:0.3723, val-acc:0.8841]\n",
      "Epoch13: 100%|███████| 46319/46319 [00:15<00:00, 2984.81it/s, loss:0.2977, acc:0.9061, val-loss:0.3812, val-acc:0.8809]\n",
      "Epoch14: 100%|███████| 46319/46319 [00:15<00:00, 2978.23it/s, loss:0.3109, acc:0.8993, val-loss:0.3662, val-acc:0.8871]\n",
      "Epoch15: 100%|███████| 46319/46319 [00:15<00:00, 2966.09it/s, loss:0.3521, acc:0.8876, val-loss:0.3474, val-acc:0.8915]\n",
      "Epoch16: 100%|███████| 46319/46319 [00:16<00:00, 2838.81it/s, loss:0.2961, acc:0.9064, val-loss:0.3509, val-acc:0.8931]\n",
      "Epoch17: 100%|███████| 46319/46319 [00:16<00:00, 2824.92it/s, loss:0.2751, acc:0.9188, val-loss:0.3420, val-acc:0.8974]\n",
      "Epoch18: 100%|███████| 46319/46319 [00:15<00:00, 2999.19it/s, loss:0.2656, acc:0.9150, val-loss:0.3402, val-acc:0.8955]\n",
      "Epoch19: 100%|███████| 46319/46319 [00:15<00:00, 3022.18it/s, loss:0.2762, acc:0.9134, val-loss:0.3494, val-acc:0.8971]\n",
      "Epoch20: 100%|███████| 46319/46319 [00:15<00:00, 2921.18it/s, loss:0.2592, acc:0.9226, val-loss:0.3247, val-acc:0.9011]\n",
      "Epoch21: 100%|███████| 46319/46319 [00:15<00:00, 2972.61it/s, loss:0.3046, acc:0.8997, val-loss:0.3292, val-acc:0.8980]\n",
      "Epoch22: 100%|███████| 46319/46319 [00:15<00:00, 3021.32it/s, loss:0.2628, acc:0.9153, val-loss:0.3239, val-acc:0.9009]\n",
      "Epoch23: 100%|███████| 46319/46319 [00:15<00:00, 3042.25it/s, loss:0.2671, acc:0.9097, val-loss:0.3371, val-acc:0.8972]\n",
      "Epoch24: 100%|███████| 46319/46319 [00:15<00:00, 3029.75it/s, loss:0.2919, acc:0.9066, val-loss:0.3432, val-acc:0.8970]\n",
      "Epoch25: 100%|███████| 46319/46319 [00:15<00:00, 3027.31it/s, loss:0.2972, acc:0.9093, val-loss:0.3620, val-acc:0.8925]\n",
      "Epoch26: 100%|███████| 46319/46319 [00:15<00:00, 3015.73it/s, loss:0.2749, acc:0.9151, val-loss:0.3402, val-acc:0.9000]\n",
      "Epoch27: 100%|███████| 46319/46319 [00:15<00:00, 3003.89it/s, loss:0.2750, acc:0.9157, val-loss:0.3357, val-acc:0.9001]\n",
      "Epoch28: 100%|███████| 46319/46319 [00:15<00:00, 3004.64it/s, loss:0.2335, acc:0.9271, val-loss:0.3203, val-acc:0.9033]\n",
      "Epoch29: 100%|███████| 46319/46319 [00:15<00:00, 3014.42it/s, loss:0.2585, acc:0.9171, val-loss:0.3187, val-acc:0.9015]\n",
      "Epoch30: 100%|███████| 46319/46319 [00:15<00:00, 3007.76it/s, loss:0.2395, acc:0.9191, val-loss:0.3127, val-acc:0.9060]\n"
     ]
    }
   ],
   "source": [
    "def criterion(y_output, y_true):\n",
    "    loss = nn.CrossEntropyLoss()(y_output, y_true)\n",
    "    return loss\n",
    "\n",
    "res_folds = []\n",
    "acc_folds = []\n",
    "model_name = 'lstm_base'\n",
    "best_checkpoint_num = 3\n",
    "for idx, (train_dataloader, val_dataloader, test_dataloader) in enumerate(data_folds):\n",
    "    oof_train_test = np.zeros((X_train.shape[0] + X_test.shape[0], 30))\n",
    "    history = {'best_model': []}\n",
    "    for i in range(best_checkpoint_num):\n",
    "        history['best_model'].append((0, os.path.join(model_save, '{}_checkpoint_fold_{}_{}.pth'.format(model_name, idx, i))))\n",
    "    validate_points = list(np.linspace(0, len(train_dataloader)-1, 3).astype(int))[1:]\n",
    "    \n",
    "    model = BiLSTM(feature_dim=324, lstm_size=512, fc1=512, fc2=256, num_layers=2, rnn_dropout=0.0, fc_dropout=0.2, embedding_dropout=0.0)  \n",
    "\n",
    "    model = model.cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.999), lr=1e-3)\n",
    "    epochs = 30\n",
    "#     scheduler = None\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=1)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-5, max_lr=3e-3, step_size_up=int(len(train_dataloader)/2), cycle_momentum=False, mode='triangular')\n",
    "#     scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, epochs=epochs, steps_per_epoch=len(train_dataloader), pct_start=0.2, anneal_strategy='linear', div_factor=30, final_div_factor=1e4)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        writer = SummaryWriter(log_dir=os.path.join(tensorboard_path, '{}_fold_{}'.format(model_name, idx)))\n",
    "        train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, step=True)\n",
    "#         scheduler.step()\n",
    "        gc.collect()\n",
    "    for (acc, checkpoint_pth), weight in zip(sorted(history['best_model'], reverse=True), [0.5, 0.3, 0.2]):\n",
    "        model.load_state_dict(torch.load(checkpoint_pth, map_location=torch.device('cpu')), strict=True)\n",
    "        test(oof_train_test, model, test_dataloader, val_dataloader, valid_indexs[idx], weight=weight)\n",
    "    acc_folds.append(sorted(history['best_model'], reverse=True)[0][0])\n",
    "    res_folds.append(oof_train_test)\n",
    "    np.save(os.path.join(res_path, \"{}_fold_{}.npy\".format(model_name, idx)), oof_train_test)\n",
    "    del model, history\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T11:19:49.483576Z",
     "start_time": "2020-12-04T11:19:49.469591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [6.22121911e-07, 2.32445025e-08, 2.27266271e-11, ...,\n",
       "         7.62088483e-07, 1.06691051e-10, 4.07728932e-12],\n",
       "        [1.55499918e-03, 1.36706105e-04, 4.98975908e-07, ...,\n",
       "         3.14545230e-08, 4.30256684e-07, 2.36042192e-06],\n",
       "        [5.60847566e-06, 6.33265705e-06, 3.21540896e-09, ...,\n",
       "         8.49415604e-08, 5.57732705e-07, 1.20443138e-06]]),\n",
       " array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [8.77333246e-02, 7.93280080e-04, 2.83893030e-03, ...,\n",
       "         2.22486653e-04, 6.63713476e-03, 1.20070924e-02],\n",
       "        ...,\n",
       "        [2.93307536e-03, 1.11068274e-03, 2.02455080e-07, ...,\n",
       "         4.33413652e-05, 1.45919951e-05, 5.61082350e-07],\n",
       "        [3.98522549e-03, 1.68976897e-04, 7.40984508e-08, ...,\n",
       "         1.15009037e-09, 1.33861206e-07, 2.12882629e-08],\n",
       "        [7.65968480e-05, 2.39392773e-04, 3.25874858e-06, ...,\n",
       "         1.61619906e-05, 2.81682431e-05, 5.89062265e-05]]),\n",
       " array([[8.40667740e-01, 5.92165142e-02, 7.04686114e-04, ...,\n",
       "         3.04249878e-06, 1.56536289e-05, 1.88342065e-04],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [1.27205950e-05, 2.71839054e-06, 1.47825260e-08, ...,\n",
       "         4.75466211e-05, 1.97694479e-06, 1.79602698e-07],\n",
       "        [1.22500217e-04, 2.60126942e-05, 2.91871654e-08, ...,\n",
       "         1.01554549e-09, 3.02371315e-07, 8.78498363e-08],\n",
       "        [3.53987238e-06, 1.02858258e-05, 1.59529141e-07, ...,\n",
       "         1.04264442e-07, 7.90833323e-07, 1.81605057e-06]]),\n",
       " array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.43260967e-01, 1.08815946e-03, 2.19307741e-02, ...,\n",
       "         2.18156341e-04, 7.44104130e-03, 2.41201918e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [1.46524516e-06, 1.34516467e-07, 3.09375938e-11, ...,\n",
       "         4.90729427e-09, 7.12926104e-09, 1.78629109e-12],\n",
       "        [3.36341087e-03, 1.59898110e-04, 1.12963088e-06, ...,\n",
       "         5.70000578e-10, 7.21036673e-06, 1.74363487e-06],\n",
       "        [1.61102566e-06, 5.79142112e-05, 4.44124426e-09, ...,\n",
       "         1.36529444e-09, 4.21355371e-07, 1.61253434e-07]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T11:28:14.214928Z",
     "start_time": "2020-12-04T11:28:14.166037Z"
    }
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(data_folds)):\n",
    "    res.append(np.load(os.path.join(res_path, \"{}_fold_{}.npy\".format(model_name, i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T11:35:19.433679Z",
     "start_time": "2020-12-04T11:35:19.402761Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['file_name'] = test_names\n",
    "sub['label'] = np.argmax(np.mean(res, axis=0)[57886:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T11:37:35.638903Z",
     "start_time": "2020-12-04T11:37:35.627904Z"
    }
   },
   "outputs": [],
   "source": [
    "sub['label'] = sub['label'].map({i:label for i, label in enumerate(labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T11:37:38.181664Z",
     "start_time": "2020-12-04T11:37:38.162721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>003gtit8kw.wav</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>006irl4pgx.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>007sh75o5w.wav</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>009k6j5dbw.wav</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>009lyahcx8.wav</td>\n",
       "      <td>marvin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6830</td>\n",
       "      <td>zyvkhzi7pt.wav</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6831</td>\n",
       "      <td>zzbo90jvjj.wav</td>\n",
       "      <td>nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6832</td>\n",
       "      <td>zzgk3zkfr8.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6833</td>\n",
       "      <td>zzqta071j9.wav</td>\n",
       "      <td>eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6834</td>\n",
       "      <td>zzv63lex0w.wav</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6835 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name   label\n",
       "0     003gtit8kw.wav     one\n",
       "1     006irl4pgx.wav     yes\n",
       "2     007sh75o5w.wav    tree\n",
       "3     009k6j5dbw.wav    tree\n",
       "4     009lyahcx8.wav  marvin\n",
       "...              ...     ...\n",
       "6830  zyvkhzi7pt.wav   house\n",
       "6831  zzbo90jvjj.wav    nine\n",
       "6832  zzgk3zkfr8.wav   right\n",
       "6833  zzqta071j9.wav   eight\n",
       "6834  zzv63lex0w.wav   three\n",
       "\n",
       "[6835 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T11:39:03.443378Z",
     "start_time": "2020-12-04T11:39:03.426443Z"
    }
   },
   "outputs": [],
   "source": [
    "now = time.strftime(\"%Y%m%d_%H%M%S\",time.localtime(time.time())) \n",
    "fname=\"submit_\" + now + \".csv\"    \n",
    "sub.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
