{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:27.574498Z",
     "start_time": "2020-12-05T10:23:26.482692Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import pandas as pd\n",
    "import random\n",
    "import heapq\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:28.049872Z",
     "start_time": "2020-12-05T10:23:27.576657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:28.057364Z",
     "start_time": "2020-12-05T10:23:28.051577Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "GLOBAL_SEED = 42\n",
    "setup_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:28.071418Z",
     "start_time": "2020-12-05T10:23:28.060683Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = '/root/cfl/b/Audio/data/train'\n",
    "test_path = '/root/cfl/b/Audio/data/test'\n",
    "feat_path = '/root/cfl/b/Audio/features'\n",
    "res_path = '/root/cfl/b/Audio/res'\n",
    "model_save = '/root/cfl/b/Audio/model_save'\n",
    "tensorboard_path = '/root/cfl/b/Audio/tb_run'\n",
    "if not os.path.exists(model_save):\n",
    "    os.makedirs(model_save)\n",
    "if not os.path.exists(res_path):\n",
    "    os.makedirs(res_path)\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取特征保存为图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:30.664916Z",
     "start_time": "2020-12-05T10:23:30.659161Z"
    }
   },
   "outputs": [],
   "source": [
    "SR = 65535 * 2\n",
    "NUM_CLASSES = 30\n",
    "LABELS = os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T06:23:27.733691Z",
     "start_time": "2020-12-05T06:23:27.704648Z"
    }
   },
   "outputs": [],
   "source": [
    "def mono_to_color(\n",
    "    X: np.ndarray, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6\n",
    "):\n",
    "    \"\"\"\n",
    "    Sources:\n",
    "        https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data\n",
    "        https://www.kaggle.com/ttahara/training-birdsong-baseline-resnest50-fast\n",
    "    \"\"\"\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V\n",
    "\n",
    "\n",
    "def normalize(image, mean=None, std=None):\n",
    "    image = image / 255.0\n",
    "    if mean is not None and std is not None:\n",
    "        image = (image - mean) / std\n",
    "    return np.moveaxis(image, 2, 0).astype(np.float32)\n",
    "\n",
    "\n",
    "def get_melspec(x, sr, n_mels=256):\n",
    "    mel_spec = lb.feature.melspectrogram(x, sr=sr, n_mels=n_mels, n_fft=2048, hop_length=512, power=2)\n",
    "    mel_spec = lb.power_to_db(mel_spec).astype(np.float32)\n",
    "    image = mono_to_color(mel_spec)\n",
    "#     image = normalize(image, mean=None, std=None)\n",
    "    image = image.transpose(2, 1, 0)\n",
    "#     image = resize(image, (224, 400)) \n",
    "    return image\n",
    "\n",
    "\n",
    "def crop_or_pad(y, length):\n",
    "    if len(y) < length:\n",
    "        y = np.concatenate([y, np.zeros(length - len(y))])\n",
    "    elif len(y) > length:\n",
    "        y = y[: length]\n",
    "    return y\n",
    "\n",
    "def preprocess_train(train_path):\n",
    "    x, y = [], []\n",
    "    for i, label in enumerate(LABELS):\n",
    "        label_dir = os.path.join(train_path, label)\n",
    "        for wav_file in tqdm(os.listdir(label_dir)):\n",
    "            wav_path = os.path.join(train_path, label, wav_file)\n",
    "            wav, sr = lb.load(wav_path, sr=SR)\n",
    "            wav = crop_or_pad(wav, 1*SR)\n",
    "            melspec = get_melspec(wav, sr)\n",
    "            x.append(melspec)\n",
    "            y.append(i)\n",
    "\n",
    "    x, y = np.r_[x], np.r_[y]\n",
    "#     x, y = shuffle(x, y, random_state=GLOBAL_SEED)\n",
    "    return x, y.astype(np.int32)\n",
    "\n",
    "def preprocess_test(test_path):\n",
    "    x, keys = [], []\n",
    "\n",
    "    for wav_file in tqdm(os.listdir(test_path)):\n",
    "        wav_path = os.path.join(test_path, wav_file)\n",
    "        wav, sr = lb.load(wav_path, sr=SR)\n",
    "        wav = crop_or_pad(wav, 1*SR)\n",
    "        melspec = get_melspec(wav, sr)\n",
    "        x.append(melspec)\n",
    "        keys.append(wav_file)\n",
    "    x = np.r_[x]\n",
    "    return x, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T08:19:21.376117Z",
     "start_time": "2020-12-05T06:23:33.704342Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2122/2122 [04:08<00:00,  8.53it/s]\n",
      "100%|██████████| 2095/2095 [04:10<00:00,  8.36it/s]\n",
      "100%|██████████| 2109/2109 [04:12<00:00,  8.34it/s]\n",
      "100%|██████████| 2121/2121 [04:13<00:00,  8.37it/s]\n",
      "100%|██████████| 2138/2138 [04:16<00:00,  8.34it/s]\n",
      "100%|██████████| 1567/1567 [03:06<00:00,  8.42it/s]\n",
      "100%|██████████| 2123/2123 [04:12<00:00,  8.40it/s]\n",
      "100%|██████████| 2126/2126 [04:15<00:00,  8.32it/s]\n",
      "100%|██████████| 2106/2106 [04:13<00:00,  8.30it/s]\n",
      "100%|██████████| 2131/2131 [04:14<00:00,  8.38it/s]\n",
      "100%|██████████| 1562/1562 [03:08<00:00,  8.29it/s]\n",
      "100%|██████████| 1573/1573 [03:07<00:00,  8.41it/s]\n",
      "100%|██████████| 2089/2089 [04:08<00:00,  8.39it/s]\n",
      "100%|██████████| 1584/1584 [03:10<00:00,  8.34it/s]\n",
      "100%|██████████| 2119/2119 [04:14<00:00,  8.34it/s]\n",
      "100%|██████████| 2086/2086 [04:12<00:00,  8.27it/s]\n",
      "100%|██████████| 2108/2108 [04:11<00:00,  8.37it/s]\n",
      "100%|██████████| 1566/1566 [03:08<00:00,  8.32it/s]\n",
      "100%|██████████| 1540/1540 [03:04<00:00,  8.33it/s]\n",
      "100%|██████████| 2125/2125 [04:15<00:00,  8.30it/s]\n",
      "100%|██████████| 2103/2103 [04:09<00:00,  8.42it/s]\n",
      "100%|██████████| 1548/1548 [03:04<00:00,  8.39it/s]\n",
      "100%|██████████| 2121/2121 [04:13<00:00,  8.36it/s]\n",
      "100%|██████████| 1580/1580 [03:08<00:00,  8.40it/s]\n",
      "100%|██████████| 2105/2105 [04:10<00:00,  8.40it/s]\n",
      "100%|██████████| 1600/1600 [03:12<00:00,  8.33it/s]\n",
      "100%|██████████| 2121/2121 [04:13<00:00,  8.37it/s]\n",
      "100%|██████████| 1537/1537 [03:02<00:00,  8.43it/s]\n",
      "100%|██████████| 2086/2086 [04:08<00:00,  8.38it/s]\n",
      "100%|██████████| 2095/2095 [04:10<00:00,  8.36it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = preprocess_train(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T08:32:54.745181Z",
     "start_time": "2020-12-05T08:19:21.378182Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6835/6835 [13:30<00:00,  8.43it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, test_names = preprocess_test(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T08:33:19.174317Z",
     "start_time": "2020-12-05T08:32:54.747568Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savez(os.path.join(feat_path, 'melspec_256_256'), X=np.concatenate([X_train, X_test], axis=0), y=y_train, test_names=test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载特征准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:34.649404Z",
     "start_time": "2020-12-05T10:23:34.642657Z"
    }
   },
   "outputs": [],
   "source": [
    "melspec = np.load(os.path.join(feat_path, 'melspec_256_256.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:50.302971Z",
     "start_time": "2020-12-05T10:23:34.891241Z"
    }
   },
   "outputs": [],
   "source": [
    "X = melspec['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:50.310286Z",
     "start_time": "2020-12-05T10:23:50.305064Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X[:57886] \n",
    "X_test = X[57886:]\n",
    "y_train = melspec['y']\n",
    "test_names = melspec['test_names']\n",
    "labels = os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:50.391884Z",
     "start_time": "2020-12-05T10:23:50.312160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del melspec, X\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:50.593922Z",
     "start_time": "2020-12-05T10:23:50.395792Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, index, is_train=True):\n",
    "        self.index = index\n",
    "        self.is_train = is_train\n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            img = X_train[self.index[idx]] / 255.0\n",
    "            return self.transformer(torch.tensor(img, dtype=torch.float32)), y_train[self.index[idx]]\n",
    "        else:\n",
    "            img = X_test[self.index[idx]] / 255.0\n",
    "            return self.transformer(torch.tensor(img, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:50.609997Z",
     "start_time": "2020-12-05T10:23:50.595445Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN = 128\n",
    "BATCH_SIZE_VAL = 128\n",
    "BATCH_SIZE_TEST = 128\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=GLOBAL_SEED)\n",
    "data_folds = []\n",
    "valid_indexs = []    \n",
    "\n",
    "\n",
    "test_dataset = CustomDataset(np.arange(X_test.shape[0]), is_train=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, sampler=SequentialSampler(test_dataset), shuffle=False, num_workers=0)\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(X=X_train, y=y_train)):\n",
    "    valid_indexs.append(valid_index)\n",
    "    \n",
    "    train_dataset = CustomDataset(train_index, is_train=True)\n",
    "    val_dataset = CustomDataset(valid_index, is_train=True)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=0)\n",
    "    valid_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, sampler=SequentialSampler(val_dataset), shuffle=False, num_workers=0)\n",
    "    data_folds.append((train_dataloader, valid_dataloader, test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:50.622759Z",
     "start_time": "2020-12-05T10:23:50.611337Z"
    }
   },
   "outputs": [],
   "source": [
    "from resnest.torch import resnest50\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:50.634510Z",
     "start_time": "2020-12-05T10:23:50.624212Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNest50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # ResNeSt: Split-Attention Networks\n",
    "        # https://arxiv.org/abs/2004.08955\n",
    "        # Significantly outperforms standard Resnet\n",
    "        self.model = resnest50(pretrained=True)\n",
    "#         self.model = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1024, 30)\n",
    "        )\n",
    "\n",
    "#         self.model.fc = nn.Sequential(\n",
    "#             nn.Linear(2048, 30)\n",
    "#         )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:23:50.658325Z",
     "start_time": "2020-12-05T10:23:50.637141Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader, criterion, history, n_iters):\n",
    "    model.eval()\n",
    "    costs = []\n",
    "    accs = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda().long()\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            costs.append(loss.item())\n",
    "            _, y_preds = torch.max(y_output, 1)\n",
    "            accs.append((y_preds == y).float().mean().item())\n",
    "    mean_accs = np.mean(accs)\n",
    "    mean_costs = np.mean(costs)\n",
    "    writer.add_scalar('age/validate_accuracy', mean_accs, n_iters)\n",
    "    writer.add_scalar('age/validate_loss', mean_costs, n_iters)\n",
    "    if mean_accs > history['best_model'][0][0]:  \n",
    "        heapq.heapify(history['best_model'])\n",
    "        checkpoint_pth = history['best_model'][0][1]\n",
    "        heapq.heappushpop(history['best_model'], (mean_accs, checkpoint_pth))\n",
    "        torch.save(model.state_dict(), checkpoint_pth)\n",
    "    return mean_costs, mean_accs\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, step=True):\n",
    "    model.train()\n",
    "    costs = []\n",
    "    accs = []\n",
    "    val_loss, val_acc = 0, 0\n",
    "    with tqdm(total=len(train_dataloader.dataset), desc='Epoch{}'.format(epoch)) as pbar:\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda().long()\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step:\n",
    "                scheduler.step()\n",
    "            with torch.no_grad():\n",
    "                costs.append(loss.item())\n",
    "                _, y_preds = torch.max(y_output, 1)\n",
    "                accs.append((y_preds == y).float().mean().item())\n",
    "                pbar.update(y.size(0))\n",
    "            n_iters = idx + len(train_dataloader) * (epoch-1)\n",
    "            if idx in validate_points:\n",
    "                val_loss, val_acc = validate(model, val_dataloader, criterion, history, n_iters)\n",
    "                model.train()\n",
    "            \n",
    "            writer.add_scalar('age/train_accuracy', accs[-1], n_iters)\n",
    "            writer.add_scalar('age/train_loss', costs[-1], n_iters)\n",
    "            writer.add_scalar('age/learning_rate', scheduler.get_lr()[0], n_iters)\n",
    "            pbar.set_postfix_str('loss:{:.4f}, acc:{:.4f}, val-loss:{:.4f}, val-acc:{:.4f}'.format(np.mean(costs[-10:]), np.mean(accs[-10:]), val_loss, val_acc))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "def test(oof_train_test, model, test_dataloader, val_dataloader, valid_index, weight=1):\n",
    "    model.eval()\n",
    "    y_preds = []\n",
    "    y_preds_val = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(test_dataloader):\n",
    "            X = batch\n",
    "            X= X.cuda()\n",
    "            y_output = model(X)    \n",
    "            y_preds.append(y_output.cpu())\n",
    "            \n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            X, y = batch\n",
    "            X = X.cuda()\n",
    "            y_output = model(X)\n",
    "            y_preds_val.append(y_output.cpu())\n",
    "    \n",
    "    oof_train_test[valid_index] += F.softmax(torch.cat(y_preds_val)).numpy() * weight\n",
    "    oof_train_test[57886:] += F.softmax(torch.cat(y_preds)).numpy() * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-05T10:25:46.247Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 46309/46309 [08:22<00:00, 92.14it/s, loss:0.1718, acc:0.9470, val-loss:0.1530, val-acc:0.9566] \n",
      "Epoch2: 100%|██████████| 46309/46309 [08:49<00:00, 87.44it/s, loss:0.1879, acc:0.9509, val-loss:0.1302, val-acc:0.9619] \n",
      "Epoch3: 100%|██████████| 46309/46309 [08:47<00:00, 87.80it/s, loss:0.1129, acc:0.9689, val-loss:0.1185, val-acc:0.9662] \n",
      "Epoch4: 100%|██████████| 46309/46309 [08:47<00:00, 87.81it/s, loss:0.1163, acc:0.9661, val-loss:0.1119, val-acc:0.9692] \n",
      "Epoch5: 100%|██████████| 46309/46309 [08:48<00:00, 87.55it/s, loss:0.1245, acc:0.9642, val-loss:0.1154, val-acc:0.9690] \n",
      "Epoch6: 100%|██████████| 46309/46309 [08:57<00:00, 86.10it/s, loss:0.1241, acc:0.9676, val-loss:0.1075, val-acc:0.9703] \n",
      "Epoch7: 100%|██████████| 46309/46309 [08:52<00:00, 86.90it/s, loss:0.0836, acc:0.9769, val-loss:0.1058, val-acc:0.9704] \n",
      "Epoch1: 100%|██████████| 46309/46309 [08:41<00:00, 88.85it/s, loss:0.1619, acc:0.9556, val-loss:0.1709, val-acc:0.9538] \n",
      "Epoch2: 100%|██████████| 46309/46309 [08:42<00:00, 88.59it/s, loss:0.1314, acc:0.9632, val-loss:0.1515, val-acc:0.9575] \n",
      "Epoch3: 100%|██████████| 46309/46309 [08:45<00:00, 88.12it/s, loss:0.1094, acc:0.9646, val-loss:0.1378, val-acc:0.9639] \n",
      "Epoch4:   8%|▊         | 3712/46309 [00:35<06:56, 102.34it/s, loss:0.1008, acc:0.9719, val-loss:0.0000, val-acc:0.0000]"
     ]
    }
   ],
   "source": [
    "def criterion(y_output, y_true):\n",
    "    loss = nn.CrossEntropyLoss()(y_output, y_true)\n",
    "    return loss\n",
    "\n",
    "res_folds = []\n",
    "acc_folds = []\n",
    "model_name = 'resnest50'\n",
    "best_checkpoint_num = 3\n",
    "for idx, (train_dataloader, val_dataloader, test_dataloader) in enumerate(data_folds):\n",
    "    oof_train_test = np.zeros((X_train.shape[0] + X_test.shape[0], 30))\n",
    "    history = {'best_model': []}\n",
    "    for i in range(best_checkpoint_num):\n",
    "        history['best_model'].append((0, os.path.join(model_save, '{}_checkpoint_fold_{}_{}.pth'.format(model_name, idx, i))))\n",
    "    validate_points = list(np.linspace(0, len(train_dataloader)-1, 3).astype(int))[1:]\n",
    "     \n",
    "    model = ResNest50().cuda()\n",
    "#     model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.999), lr=1e-3)\n",
    "    epochs = 7\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-5, max_lr=2e-3, step_size_up=int(len(train_dataloader)/2), cycle_momentum=False, mode='triangular')\n",
    "#     scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, epochs=epochs, steps_per_epoch=len(train_dataloader), pct_start=0.2, anneal_strategy='linear', div_factor=30, final_div_factor=1e4)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        writer = SummaryWriter(log_dir=os.path.join(tensorboard_path, '{}_fold_{}'.format(model_name, idx)))\n",
    "        train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, step=True)\n",
    "#         scheduler.step()\n",
    "        gc.collect()\n",
    "    for (acc, checkpoint_pth), weight in zip(sorted(history['best_model'], reverse=True), [0.5, 0.3, 0.2]):\n",
    "        model.load_state_dict(torch.load(checkpoint_pth, map_location= torch.device('cpu')), strict=True)\n",
    "        test(oof_train_test, model, test_dataloader, val_dataloader, valid_indexs[idx], weight=weight)\n",
    "    acc_folds.append(sorted(history['best_model'], reverse=True)[0][0])\n",
    "    res_folds.append(oof_train_test)\n",
    "    np.save(os.path.join(res_path, \"{}_fold_{}.npy\".format(model_name, idx)), oof_train_test)\n",
    "    del model, history \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:07:58.508977Z",
     "start_time": "2020-12-05T10:07:58.500224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [4.05189260e-02, 1.28448105e-01, 1.30232821e-02, ...,\n",
       "         1.97078560e-02, 1.92916249e-02, 1.51436491e-02],\n",
       "        [9.99314964e-01, 4.72229523e-09, 2.46480514e-10, ...,\n",
       "         1.04051865e-10, 1.42188678e-06, 6.52036278e-10],\n",
       "        ...,\n",
       "        [2.60628326e-09, 2.05265420e-07, 1.25412249e-07, ...,\n",
       "         7.45270863e-09, 2.58160886e-06, 4.72284030e-11],\n",
       "        [2.32501975e-02, 2.21754618e-02, 3.47323222e-02, ...,\n",
       "         2.51573386e-02, 2.74438350e-02, 2.37078201e-02],\n",
       "        [1.56348458e-13, 4.84132573e-13, 8.61053225e-12, ...,\n",
       "         6.28070542e-19, 4.50682092e-12, 2.50901304e-22]])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:19:59.677505Z",
     "start_time": "2020-12-05T10:19:59.659808Z"
    }
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(data_folds)):\n",
    "    res.append(np.load(os.path.join(res_path, \"{}_fold_{}.npy\".format(model_name, i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T15:44:44.822055Z",
     "start_time": "2020-12-04T15:44:44.776179Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['file_name'] = test_names\n",
    "sub['label'] = np.argmax(np.mean(res, axis=0)[57886:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T15:44:46.496983Z",
     "start_time": "2020-12-04T15:44:46.487984Z"
    }
   },
   "outputs": [],
   "source": [
    "sub['label'] = sub['label'].map({i:label for i, label in enumerate(labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T15:44:47.393358Z",
     "start_time": "2020-12-04T15:44:47.372445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>003gtit8kw.wav</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>006irl4pgx.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>007sh75o5w.wav</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>009k6j5dbw.wav</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>009lyahcx8.wav</td>\n",
       "      <td>marvin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6830</td>\n",
       "      <td>zyvkhzi7pt.wav</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6831</td>\n",
       "      <td>zzbo90jvjj.wav</td>\n",
       "      <td>nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6832</td>\n",
       "      <td>zzgk3zkfr8.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6833</td>\n",
       "      <td>zzqta071j9.wav</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6834</td>\n",
       "      <td>zzv63lex0w.wav</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6835 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name   label\n",
       "0     003gtit8kw.wav     one\n",
       "1     006irl4pgx.wav     yes\n",
       "2     007sh75o5w.wav    tree\n",
       "3     009k6j5dbw.wav   three\n",
       "4     009lyahcx8.wav  marvin\n",
       "...              ...     ...\n",
       "6830  zyvkhzi7pt.wav   house\n",
       "6831  zzbo90jvjj.wav    nine\n",
       "6832  zzgk3zkfr8.wav   right\n",
       "6833  zzqta071j9.wav   three\n",
       "6834  zzv63lex0w.wav   three\n",
       "\n",
       "[6835 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T15:44:52.656059Z",
     "start_time": "2020-12-04T15:44:52.639104Z"
    }
   },
   "outputs": [],
   "source": [
    "now = time.strftime(\"%Y%m%d_%H%M%S\",time.localtime(time.time())) \n",
    "fname=\"submit_\" + model_name + \"_\" + now + \".csv\"    \n",
    "sub.to_csv(os.path.join(res_path, fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('py36_torch': conda)",
   "language": "python",
   "name": "python361064bitpy36torchcondaa3855d064b844135ba48c06bf4a0fbc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
