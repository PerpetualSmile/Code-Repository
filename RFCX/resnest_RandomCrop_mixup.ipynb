{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:22.749635Z",
     "start_time": "2021-02-07T01:09:21.794578Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:23.245324Z",
     "start_time": "2021-02-07T01:09:22.751479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:23.768730Z",
     "start_time": "2021-02-07T01:09:23.755927Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "GLOBAL_SEED = 42\n",
    "setup_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:24.663799Z",
     "start_time": "2021-02-07T01:09:24.654505Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/dev/shm/data'\n",
    "feat_path = '/root/s/RFCX/features'\n",
    "res_path = '/root/s/RFCX/res'\n",
    "model_path = '/root/s/RFCX/model_save'\n",
    "tensorboard_path = '/root/s/RFCX/tensorboard'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if not os.path.exists(res_path):\n",
    "    os.makedirs(res_path)\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:25.144226Z",
     "start_time": "2021-02-07T01:09:25.114310Z"
    }
   },
   "outputs": [],
   "source": [
    "data_tp_df=pd.read_csv(os.path.join(data_path, 'train_tp.csv'))\n",
    "data_fp_df=pd.read_csv(os.path.join(data_path, 'train_fp.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:26.132698Z",
     "start_time": "2021-02-07T01:09:26.125322Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_class = 24\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 128\n",
    "    sr = 48000\n",
    "    segment_length = 10 * sr\n",
    "    fmin = 80\n",
    "    fmax = 16000\n",
    "    mixup_proba = 0.5\n",
    "    mixup_alpha = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:28.274989Z",
     "start_time": "2021-02-07T01:09:28.047053Z"
    }
   },
   "outputs": [],
   "source": [
    "\"https://www.kaggle.com/gopidurgaprasad/audio-augmentation-albumentations/\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, PolarityInversion, Gain, AddGaussianSNR\n",
    "\n",
    "\n",
    "class AudioTransform(BasicTransform):\n",
    "    \"\"\"Transform for Audio task\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "    \n",
    "      \n",
    "class MelSpectrogram(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, parameters, always_apply=False, p=0.5):\n",
    "        super(MelSpectrogram, self).__init__(always_apply, p)\n",
    "\n",
    "        self.parameters = parameters\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(sound, sr=sr, **self.parameters)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "        melspec = melspec.astype(np.float32)\n",
    "        melspec = resize(melspec, (128, 400))\n",
    "        return melspec, sr\n",
    "    \n",
    "    \n",
    "class SpecAugment(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, num_mask=2, freq_masking=0.15, time_masking=0.20, always_apply=False, p=0.5):\n",
    "        super(SpecAugment, self).__init__(always_apply, p)\n",
    "\n",
    "        self.num_mask = num_mask\n",
    "        self.freq_masking = freq_masking\n",
    "        self.time_masking = time_masking\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "        spec_aug = self.spec_augment(melspec, \n",
    "                                     self.num_mask,\n",
    "                                     self.freq_masking,\n",
    "                                     self.time_masking,\n",
    "                                     melspec.min())\n",
    "        \n",
    "\n",
    "        return spec_aug, sr\n",
    "    \n",
    "    # Source: https://www.kaggle.com/davids1992/specaugment-quick-implementation\n",
    "    def spec_augment(self, \n",
    "                    spec: np.ndarray,\n",
    "                    num_mask=2,\n",
    "                    freq_masking=0.15,\n",
    "                    time_masking=0.20,\n",
    "                    value=0):\n",
    "        spec = spec.copy()\n",
    "        num_mask = random.randint(1, num_mask)\n",
    "        for i in range(num_mask):\n",
    "            all_freqs_num, all_frames_num  = spec.shape\n",
    "            freq_percentage = random.uniform(0.0, freq_masking)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[f0:f0 + num_freqs_to_mask, :] = value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[:, t0:t0 + num_frames_to_mask] = value\n",
    "\n",
    "        return spec\n",
    "\n",
    "    \n",
    "class SpectToImage(AudioTransform):\n",
    "\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(SpectToImage, self).__init__(always_apply, p)\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        image, sr = data\n",
    "        delta = librosa.feature.delta(image)\n",
    "        accelerate = librosa.feature.delta(image, order=2)\n",
    "        image = np.stack([image, delta, accelerate], axis=-1)\n",
    "        image = image.astype(np.float32) / 100.0\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "sound_augment = Compose([\n",
    "    PolarityInversion(p=0.2),\n",
    "    Gain(min_gain_in_db=-15, max_gain_in_db=15, p=0.3),\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.1),\n",
    "    AddGaussianSNR(max_SNR=0.5, p=0.2),\n",
    "#     TimeStretch(min_rate=0.8, max_rate=1.25, p=0.2)\n",
    "#     Shift(min_fraction=-0.2, max_fraction=0.2, p=0.2)\n",
    "])\n",
    "\n",
    "\n",
    "melspectrogram_parameters = {\n",
    "        \"n_mels\": Config.n_mels,\n",
    "        'n_fft': Config.n_fft, \n",
    "        'hop_length': Config.hop_length,\n",
    "        'fmin': Config.fmin, \n",
    "        'fmax': Config.fmax \n",
    "    }\n",
    "\n",
    "spec_augment = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpecAugment(p=0.2),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "to_image = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "def augment(wav):\n",
    "    data = sound_augment(samples=wav, sample_rate=Config.sr), Config.sr\n",
    "    image = spec_augment(data=data)['data']\n",
    "    return image.transpose(2, 1, 0)\n",
    "\n",
    "def get_image(wav):\n",
    "    data = wav, Config.sr\n",
    "    image = to_image(data=data)['data']\n",
    "    return image.transpose(2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:28.448598Z",
     "start_time": "2021-02-07T01:09:28.426889Z"
    }
   },
   "outputs": [],
   "source": [
    "def mono_to_color(X: np.ndarray,\n",
    "                  mean=None,\n",
    "                  std=None,\n",
    "                  norm_max=None,\n",
    "                  norm_min=None,\n",
    "                  eps=1e-6):\n",
    "    \"\"\"\n",
    "    Code from https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data\n",
    "    \"\"\"\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V\n",
    "\n",
    "\n",
    "def crop_or_pad(y, length, sr, train=True, probs=None):\n",
    "    \"\"\"\n",
    "    Crops an array to a chosen length\n",
    "    Arguments:\n",
    "        y {1D np array} -- Array to crop\n",
    "        length {int} -- Length of the crop\n",
    "        sr {int} -- Sampling rate\n",
    "    Keyword Arguments:\n",
    "        train {bool} -- Whether we are at train time. If so, crop randomly, else return the beginning of y (default: {True})\n",
    "        probs {None or numpy array} -- Probabilities to use to chose where to crop (default: {None})\n",
    "    Returns:\n",
    "        1D np array -- Cropped array\n",
    "    \"\"\"\n",
    "    if len(y) <= length:\n",
    "        y = np.concatenate([y, np.zeros(length - len(y))])\n",
    "    else:\n",
    "        if not train:\n",
    "            start = 0\n",
    "        elif probs is None:\n",
    "            start = np.random.randint(len(y) - length)\n",
    "        else:\n",
    "            start = (\n",
    "                np.random.choice(np.arange(len(probs)), p=probs) + np.random.random()\n",
    "            )\n",
    "            start = int(sr * (start))\n",
    "\n",
    "        y = y[start : start + length]\n",
    "\n",
    "    return y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:28.992981Z",
     "start_time": "2021-02-07T01:09:28.764738Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "ONE_HOT = np.eye(Config.num_class)\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_df, is_valid=False):\n",
    "        self.data_df = data_df\n",
    "        self.is_valid = is_valid\n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def load_audio_clip(self, audio_file_path, t_min, t_max):\n",
    "        # All sound files are 48000 bitrate, no need to slowly resample\n",
    "        wav, _ = librosa.load(audio_file_path, sr=Config.sr)\n",
    "\n",
    "        t_min = float(t_min) * Config.sr\n",
    "        t_max = float(t_max) * Config.sr\n",
    "\n",
    "        # Positioning sound slice\n",
    "        begin = max(t_max - Config.segment_length, 0)\n",
    "        end = t_min\n",
    "        random_begin = np.random.randint(begin, end)\n",
    "        random_end = random_begin + Config.segment_length\n",
    "        if random_end > len(wav):\n",
    "            random_end = len(wav)\n",
    "            random_begin = random_end - Config.segment_length\n",
    "\n",
    "        slice = wav[int(random_begin):int(random_end)]\n",
    "        return slice\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        s = self.data_df.iloc[idx]\n",
    "        audio_file_path = os.path.join(data_path, 'train', s['recording_id']+'.flac')\n",
    "        wav = self.load_audio_clip(audio_file_path, s['t_min'], s['t_max'])\n",
    "        if self.is_valid:\n",
    "            img = get_image(wav)\n",
    "        else:\n",
    "#             img = augment(wav)\n",
    "            img = get_image(wav)\n",
    "        return torch.tensor(img, dtype=torch.float32), ONE_HOT[s['species_id']]\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_files):\n",
    "        self.test_files = test_files \n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_file_path = os.path.join(data_path, 'test', self.test_files[idx])\n",
    "        wav, _ = librosa.load(audio_file_path, sr=Config.sr)\n",
    "        segments = len(wav) / Config.segment_length\n",
    "        segments = int(np.ceil(segments))\n",
    "        img = []\n",
    "        for i in range(0, segments):\n",
    "            # Last segment going from the end\n",
    "            if (i + 1) * Config.segment_length > len(wav):\n",
    "                slice = wav[len(wav) - Config.segment_length:len(wav)]\n",
    "            else:\n",
    "                slice = wav[i * Config.segment_length:(i + 1) * Config.segment_length]\n",
    "            img.append(get_image(slice))\n",
    "        return torch.tensor(img, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:29.052727Z",
     "start_time": "2021-02-07T01:09:29.043534Z"
    }
   },
   "outputs": [],
   "source": [
    "test_files = sorted(os.listdir(os.path.join(data_path, 'test')))\n",
    "test_dataset = TestDataset(test_files)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, sampler=SequentialSampler(test_dataset), shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:29.347636Z",
     "start_time": "2021-02-07T01:09:29.324622Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=GLOBAL_SEED)\n",
    "data_folds = []\n",
    "valid_indexs = []\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(X=data_tp_df, y=data_tp_df['species_id'])):\n",
    "    valid_indexs.append(valid_index)\n",
    "    train_dataset = TrainDataset(data_tp_df.iloc[train_index], is_valid=False)\n",
    "    val_dataset = TrainDataset(data_tp_df.iloc[valid_index], is_valid=True)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    valid_dataloader = DataLoader(val_dataset, batch_size=batch_size, sampler=SequentialSampler(val_dataset), shuffle=False, num_workers=4)\n",
    "    data_folds.append((train_dataloader, valid_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:29.982640Z",
     "start_time": "2021-02-07T01:09:29.975002Z"
    }
   },
   "outputs": [],
   "source": [
    "from resnest.torch import resnest50\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:30.315912Z",
     "start_time": "2021-02-07T01:09:30.306510Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNest(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.model = torchvision.models.densenet161(pretrained=True)\n",
    "#         self.model.classifier = nn.Linear(2208, num_class)   \n",
    "        self.model = resnest50(pretrained=True)\n",
    "        nb_ft = self.model.fc.in_features\n",
    "        del self.model.fc\n",
    "        self.model.fc = nn.Linear(nb_ft, Config.num_class)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:30.621808Z",
     "start_time": "2021-02-07T01:09:30.605966Z"
    }
   },
   "outputs": [],
   "source": [
    "# label-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LWLRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    # Number of GT labels per instance\n",
    "    num_labels = labels.sum(-1)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = scores.sum() / labels.sum()\n",
    "    return score.item()\n",
    "\n",
    "# # Sample usage\n",
    "# y_true = torch.tensor(np.array([[1, 1, 0], [1, 0, 1], [0, 0, 1]]))\n",
    "# y_score = torch.tensor(np.random.randn(3, 3))\n",
    "# print(LRAP(y_score, y_true), LWLRAP(y_score, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:32.177128Z",
     "start_time": "2021-02-07T01:09:32.166957Z"
    }
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=5):\n",
    "    \"\"\"\n",
    "    Applies mixup to a sample\n",
    "    Arguments:\n",
    "        x {torch tensor} -- Input batch\n",
    "        y {torch tensor} -- Labels\n",
    "    Keyword Arguments:\n",
    "        alpha {float} -- Parameter of the beta distribution (default: {0.4})\n",
    "    Returns:\n",
    "        torch tensor  -- Mixed input\n",
    "        torch tensor  -- Labels of the original batch\n",
    "        torch tensor  -- Labels of the shuffle batch\n",
    "        float  -- Probability samples by the beta distribution\n",
    "    \"\"\"\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "    index = torch.randperm(x.size()[0]).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# for step, (x, y_batch) in enumerate(train_loader):\n",
    "    \n",
    "#     if np.random.rand() < mixup_proba:\n",
    "#         x, y_a, y_b, _ = mixup_data(x.cuda(), y_batch.cuda(), alpha=alpha)\n",
    "#         y_batch = torch.clamp(y_a + y_b, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T01:09:33.416258Z",
     "start_time": "2021-02-07T01:09:33.297001Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader, criterion, history, n_iters, writer, fold):\n",
    "    model.eval()\n",
    "    costs = []\n",
    "    accs = []\n",
    "    metrics = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            costs.append(loss.item())\n",
    "            metrics.append(LWLRAP(y_output.detach().cpu(), y.cpu()))\n",
    "            y_prob = y_output.detach().sigmoid()\n",
    "            y_pred = (y_prob+0.5).int()\n",
    "            accs.append((y_pred == y).float().mean().item())\n",
    "    mean_accs = np.mean(accs)\n",
    "    mean_costs = np.mean(costs)\n",
    "    mean_metrics = np.mean(metrics)\n",
    "    writer.add_scalar('fold_{}/validate_accuracy'.format(fold), mean_accs, n_iters)\n",
    "    writer.add_scalar('fold_{}/validate_loss'.format(fold), mean_costs, n_iters)\n",
    "    writer.add_scalar('fold_{}/validate_LWLRAP'.format(fold), mean_metrics, n_iters)\n",
    "    if mean_accs > history['best_acc'][fold]:  \n",
    "        history['best_acc'][fold] = mean_accs\n",
    "        history['best_metrics'][fold] = mean_metrics\n",
    "        torch.save(model.state_dict(), history['best_model_path'][fold])\n",
    "    return mean_costs, mean_accs, mean_metrics\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, writer, fold, step=True):\n",
    "    model.train()\n",
    "    costs = []\n",
    "    accs = []\n",
    "    metrics = []\n",
    "    val_loss, val_acc = 0, 0\n",
    "    optimizer.zero_grad()\n",
    "    with tqdm(total=len(train_dataloader.dataset), desc='Epoch{}'.format(epoch)) as pbar:\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            if np.random.rand() < Config.mixup_proba:\n",
    "                X, y_a, y_b, _ = mixup_data(X, y, alpha=Config.mixup_alpha)\n",
    "                y = torch.clamp(y_a + y_b, 0, 1)\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step:\n",
    "                scheduler.step()\n",
    "            with torch.no_grad():\n",
    "                costs.append(loss.item())\n",
    "                y_prob = y_output.detach().sigmoid()\n",
    "                y_pred = (y_prob+0.5).int()\n",
    "                accs.append((y_pred == y).float().mean().item())\n",
    "                metrics.append(LWLRAP(y_output.detach().cpu(), y.cpu()))\n",
    "                pbar.update(y.size(0))\n",
    "            n_iters = idx + len(train_dataloader) * (epoch-1)\n",
    "            if idx in validate_points:\n",
    "                val_loss, val_acc, val_metrics = validate(model, val_dataloader, criterion, history, n_iters, writer, fold)\n",
    "                model.train()\n",
    "            writer.add_scalar('fold_{}/train_accuracy'.format(fold), accs[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/train_loss'.format(fold), costs[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/train_LWLRAP'.format(fold), metrics[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/learning_rate'.format(fold), scheduler.get_last_lr()[0], n_iters)\n",
    "            pbar.set_postfix_str('loss:{:.3f}, acc:{:.3f}, val-loss:{:.3f}, val-acc:{:.4f}'.format(np.mean(costs[-10:]), np.mean(accs[-10:]), val_loss, val_acc))\n",
    "            torch.cuda.empty_cache()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-07T01:09:36.940Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1:  13%|█▎        | 128/972 [00:08<01:15, 11.15it/s, loss:1.489, acc:0.527, val-loss:0.000, val-acc:0.0000]"
     ]
    }
   ],
   "source": [
    "pos_weights = torch.ones(Config.num_class)\n",
    "counts = data_tp_df['species_id'].value_counts()\n",
    "for i in range(Config.num_class):\n",
    "    pos_weights[i] = (sum(counts)-counts[i])/counts[i]\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weights).cuda()\n",
    "\n",
    "def criterion(y_pred, y_target):\n",
    "    loss = loss_function(y_pred, y_target)\n",
    "    return loss\n",
    "\n",
    "model_name = 'resnest_noaugment_RandomCrop_mixup'\n",
    "time_stamp = '{0:%m_%d_%H_%M}'.format(datetime.datetime.now())\n",
    "history = {\n",
    "    'best_acc': [0]*len(data_folds),\n",
    "    'best_metrics': [0]*len(data_folds), \n",
    "    'best_model_path': [os.path.join(model_path, '{}_{}_fold_{}.pth'.format(model_name, time_stamp, i)) for i in range(len(data_folds))]\n",
    "}\n",
    "writer = SummaryWriter(log_dir=os.path.join(tensorboard_path, '{}_{}'.format(model_name, time_stamp)))\n",
    "for idx, (train_dataloader, val_dataloader) in enumerate(data_folds):\n",
    "    validate_points = list(np.linspace(0, len(train_dataloader)-1, 2).astype(int))[1:]\n",
    "    model = ResNest().cuda()\n",
    "#     model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    epochs = 40\n",
    "    warmup_prob = 0.1\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, epochs=epochs, steps_per_epoch=len(train_dataloader), pct_start=0.3, div_factor=25, anneal_strategy='cos', cycle_momentum=True)\n",
    "#     scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "#                                                 num_warmup_steps=int(warmup_prob*len(train_dataloader)*epochs),\n",
    "#                                                 num_training_steps=len(train_dataloader)*epochs)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler,  writer, fold=idx, step=True)\n",
    "#         scheduler.step()\n",
    "        gc.collect()\n",
    "    del model \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "with open(os.path.join(model_path, '{}_{}_history.pkl'.format(model_name, time_stamp)), 'wb') as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T09:48:23.143898Z",
     "start_time": "2021-02-03T09:48:23.132904Z"
    }
   },
   "source": [
    "## Predict Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T12:56:23.611694Z",
     "start_time": "2021-02-07T12:56:23.602973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnest_noaugment_RandomCrop_mixup_02_07_01_09_history.pkl\n",
      "resnest_augment_RandomCrop_mono_to_color_02_06_15_05_history.pkl\n",
      "resnest_augment_RandomCrop_mixup_02_06_14_33_history.pkl\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(model_path):\n",
    "    if file.endswith('.pkl'):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T12:58:28.703683Z",
     "start_time": "2021-02-07T12:58:28.131096Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(model_path, 'resnest_noaugment_RandomCrop_mixup_02_07_01_09_history.pkl'), 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "model = ResNest().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T13:29:32.931980Z",
     "start_time": "2021-02-07T12:58:35.192203Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [06:15<00:00,  3.00s/it]\n",
      "100%|██████████| 125/125 [06:11<00:00,  2.97s/it]\n",
      "100%|██████████| 125/125 [06:11<00:00,  2.97s/it]\n",
      "100%|██████████| 125/125 [06:09<00:00,  2.96s/it]\n",
      "100%|██████████| 125/125 [06:09<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "for path in history['best_model_path']:\n",
    "    model.load_state_dict(torch.load(path, map_location= torch.device('cpu')), strict=True)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            a, b, c, d, e = batch.size()\n",
    "            X = batch.view(a*b, c, d, e).cuda()\n",
    "            output = model(X)\n",
    "            pred = F.sigmoid(output).view(a, b, -1).max(dim=1)[0].cpu().detach().numpy()\n",
    "            preds.append(pred)\n",
    "    folds.append(np.concatenate(preds, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T13:29:32.969833Z",
     "start_time": "2021-02-07T13:29:32.935687Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(columns=['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'], dtype=np.float32)\n",
    "sub['recording_id'] = [file.split('.')[0] for file in test_files]\n",
    "sub.iloc[:, 1:] = sum(folds)/len(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T13:34:13.623892Z",
     "start_time": "2021-02-07T13:34:13.536674Z"
    }
   },
   "outputs": [],
   "source": [
    "time_stamp = '{0:%m_%d_%H_%M}'.format(datetime.datetime.now())\n",
    "sub.to_csv(os.path.join(res_path, 'submission_resnest_noaugment_RandomCrop_mixup_{}.csv'.format(time_stamp)), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T13:34:14.078170Z",
     "start_time": "2021-02-07T13:34:14.069096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9448633000254631"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history['best_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T13:34:14.965200Z",
     "start_time": "2021-02-07T13:34:14.959167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8679543239792006"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history['best_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
