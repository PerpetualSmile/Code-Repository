{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:08.165066Z",
     "start_time": "2021-02-14T06:20:07.188310Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from skimage.transform import resize\n",
    "import sklearn\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:08.895657Z",
     "start_time": "2021-02-14T06:20:08.166908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from timm.models import resnet34d, resnet34, resnext50d_32x4d, densenet121, resnest50d\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:08.902727Z",
     "start_time": "2021-02-14T06:20:08.897483Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "GLOBAL_SEED = 12415\n",
    "setup_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:08.927948Z",
     "start_time": "2021-02-14T06:20:08.904136Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/dev/shm/data'\n",
    "feat_path = '/root/s/RFCX/features'\n",
    "res_path = '/root/s/RFCX/res'\n",
    "model_path = '/dev/shm/model_save'\n",
    "tensorboard_path = '/root/s/RFCX/tensorboard'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if not os.path.exists(res_path):\n",
    "    os.makedirs(res_path)\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:08.967113Z",
     "start_time": "2021-02-14T06:20:08.931146Z"
    }
   },
   "outputs": [],
   "source": [
    "data_tp_df=pd.read_csv(os.path.join(data_path, 'train_tp.csv'))\n",
    "data_fp_df=pd.read_csv(os.path.join(data_path, 'train_fp.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:08.973176Z",
     "start_time": "2021-02-14T06:20:08.969040Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_class = 24\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 256\n",
    "    sr = 32000\n",
    "    segment_length = 10 * sr\n",
    "    fmin = 80\n",
    "    fmax = 16000\n",
    "    \n",
    "    resize = False\n",
    "    img_shape = (256, 400)\n",
    "    \n",
    "    wav_augment = True\n",
    "    spec_augment = True\n",
    "    mixup_proba = 0.5\n",
    "    mixup_alpha = 5\n",
    "    \n",
    "    model = resnet34d\n",
    "    model_name = 'resnet34d_augment_RandomCrop_mixup_attention'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:09.664097Z",
     "start_time": "2021-02-14T06:20:09.431933Z"
    }
   },
   "outputs": [],
   "source": [
    "\"https://www.kaggle.com/gopidurgaprasad/audio-augmentation-albumentations/\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, PolarityInversion, Gain, AddGaussianSNR, TimeMask, FrequencyMask\n",
    "\n",
    "\n",
    "class AudioTransform(BasicTransform):\n",
    "    \"\"\"Transform for Audio task\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "    \n",
    "      \n",
    "class MelSpectrogram(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, parameters, always_apply=False, p=0.5):\n",
    "        super(MelSpectrogram, self).__init__(always_apply, p)\n",
    "\n",
    "        self.parameters = parameters\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "        melspec = librosa.feature.melspectrogram(sound, sr=sr, **self.parameters)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "        melspec = melspec.astype(np.float32)\n",
    "        return melspec, sr\n",
    "\n",
    "    \n",
    "class SpecAugment(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, num_mask=2, freq_masking=0.15, time_masking=0.20, always_apply=False, p=0.5):\n",
    "        super(SpecAugment, self).__init__(always_apply, p)\n",
    "\n",
    "        self.num_mask = num_mask\n",
    "        self.freq_masking = freq_masking\n",
    "        self.time_masking = time_masking\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "        spec_aug = self.spec_augment(melspec, \n",
    "                                     self.num_mask,\n",
    "                                     self.freq_masking,\n",
    "                                     self.time_masking,\n",
    "                                     melspec.min())\n",
    "        return spec_aug, sr\n",
    "    \n",
    "    # Source: https://www.kaggle.com/davids1992/specaugment-quick-implementation\n",
    "    def spec_augment(self, \n",
    "                    spec: np.ndarray,\n",
    "                    num_mask=2,\n",
    "                    freq_masking=0.15,\n",
    "                    time_masking=0.20,\n",
    "                    value=0):\n",
    "        spec = spec.copy()\n",
    "        num_mask = random.randint(1, num_mask)\n",
    "        for i in range(num_mask):\n",
    "            all_freqs_num, all_frames_num  = spec.shape\n",
    "            freq_percentage = random.uniform(0.0, freq_masking)\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[f0:f0 + num_freqs_to_mask, :] = value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[:, t0:t0 + num_frames_to_mask] = value\n",
    "\n",
    "        return spec\n",
    "\n",
    "    \n",
    "class SpectToImage(AudioTransform):\n",
    "\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(SpectToImage, self).__init__(always_apply, p)\n",
    "        \n",
    "        \n",
    "    def mono_to_color(self, X: np.ndarray,\n",
    "                      mean=None,\n",
    "                      std=None,\n",
    "                      norm_max=None,\n",
    "                      norm_min=None,\n",
    "                      eps=1e-6):\n",
    "        \"\"\"\n",
    "        Code from https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Standardize\n",
    "        mean = mean or X.mean()\n",
    "        X = X - mean\n",
    "        std = std or X.std()\n",
    "        Xstd = X / (std + eps)\n",
    "        _min, _max = Xstd.min(), Xstd.max()\n",
    "        norm_max = norm_max or _max\n",
    "        norm_min = norm_min or _min\n",
    "        if (_max - _min) > eps:\n",
    "            # Normalize to [0, 255]\n",
    "            V = Xstd\n",
    "            V[V < norm_min] = norm_min\n",
    "            V[V > norm_max] = norm_max\n",
    "            V = (V - norm_min) / (norm_max - norm_min)\n",
    "        else:\n",
    "            # Just zero\n",
    "            V = np.zeros_like(Xstd, dtype=np.float32)\n",
    "        return V\n",
    "    \n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "        image = self.mono_to_color(melspec)\n",
    "        if Config.resize:\n",
    "            image = resize(image, Config.img_shape)\n",
    "        image = np.stack([image, image, image], axis=-1)\n",
    "#         delta = librosa.feature.delta(image)\n",
    "#         accelerate = librosa.feature.delta(image, order=2)\n",
    "#         image = np.stack([image, delta, accelerate], axis=-1)\n",
    "#         image = image.astype(np.float32) / 100.0\n",
    "        # (n_mels, time_step, 3) --> (3, time_step, n_mels)\n",
    "        return image.transpose(2, 1, 0)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sound_augment = Compose([\n",
    "    PolarityInversion(p=0.2),\n",
    "    Gain(min_gain_in_db=-15, max_gain_in_db=15, p=0.3),\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.1),\n",
    "    AddGaussianSNR(max_SNR=0.5, p=0.2),\n",
    "    FrequencyMask(min_frequency_band=0.01,  max_frequency_band=0.25, p=0.2),\n",
    "    TimeMask(min_band_part=0.01, max_band_part=0.25, p=0.2)\n",
    "#     TimeStretch(min_rate=0.8, max_rate=1.25, p=0.2)\n",
    "#     Shift(min_fraction=-0.2, max_fraction=0.2, p=0.2)\n",
    "])\n",
    "\n",
    "\n",
    "melspectrogram_parameters = {\n",
    "        \"n_mels\": Config.n_mels,\n",
    "        'n_fft': Config.n_fft, \n",
    "        'hop_length': Config.hop_length,\n",
    "        'fmin': Config.fmin, \n",
    "        'fmax': Config.fmax \n",
    "    }\n",
    "\n",
    "spec_augment = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpecAugment(p=0.2),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "to_image = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:09.679015Z",
     "start_time": "2021-02-14T06:20:09.665707Z"
    }
   },
   "outputs": [],
   "source": [
    "ONE_HOT = np.eye(Config.num_class)\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_df, is_valid=False):\n",
    "        self.data_df = data_df\n",
    "        self.is_valid = is_valid\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def load_audio_clip(self, audio_file_path, t_min, t_max):\n",
    "        # All sound files are 48000 bitrate, no need to slowly resample\n",
    "        wav, _ = librosa.load(audio_file_path, sr=Config.sr)\n",
    "\n",
    "        t_min = float(t_min) * Config.sr\n",
    "        t_max = float(t_max) * Config.sr\n",
    "\n",
    "        # Positioning sound slice\n",
    "        begin = max(t_max - Config.segment_length, 0)\n",
    "        end = t_min\n",
    "        random_begin = np.random.randint(begin, end)\n",
    "        random_end = random_begin + Config.segment_length\n",
    "        if random_end > len(wav):\n",
    "            random_end = len(wav)\n",
    "            random_begin = random_end - Config.segment_length\n",
    "\n",
    "        slice = wav[int(random_begin):int(random_end)]\n",
    "        return slice\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        s = self.data_df.iloc[idx]\n",
    "        audio_file_path = os.path.join(data_path, 'train', s['recording_id']+'.wav')\n",
    "        wav = self.load_audio_clip(audio_file_path, s['t_min'], s['t_max'])\n",
    "        if self.is_valid:\n",
    "            image = to_image(data=(wav, Config.sr))['data']\n",
    "        else:\n",
    "            if Config.wav_augment:\n",
    "                data = sound_augment(samples=wav, sample_rate=Config.sr), Config.sr\n",
    "            else:\n",
    "                data = wav, Config.sr\n",
    "            if Config.spec_augment:\n",
    "                image = spec_augment(data=data)['data']\n",
    "            else:\n",
    "                image = to_image(data=data)['data']\n",
    "        return torch.tensor(image, dtype=torch.float32), ONE_HOT[s['species_id']]\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_files):\n",
    "        self.test_files = test_files \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_file_path = os.path.join(data_path, 'test', self.test_files[idx])\n",
    "        wav, _ = librosa.load(audio_file_path, sr=Config.sr)\n",
    "        segments = len(wav) / Config.segment_length\n",
    "        segments = int(np.ceil(segments))\n",
    "        img = []\n",
    "        for i in range(0, segments):\n",
    "            # Last segment going from the end\n",
    "            if (i + 1) * Config.segment_length > len(wav):\n",
    "                slice = wav[len(wav) - Config.segment_length:len(wav)]\n",
    "            else:\n",
    "                slice = wav[i * Config.segment_length:(i + 1) * Config.segment_length]\n",
    "            img.append(to_image(data=(slice, Config.sr))['data'])\n",
    "        return torch.tensor(img, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:09.696049Z",
     "start_time": "2021-02-14T06:20:09.690532Z"
    }
   },
   "outputs": [],
   "source": [
    "test_files = sorted(os.listdir(os.path.join(data_path, 'test')))\n",
    "test_dataset = TestDataset(test_files)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, sampler=SequentialSampler(test_dataset), shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:10.057385Z",
     "start_time": "2021-02-14T06:20:10.031824Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=GLOBAL_SEED)\n",
    "data_folds = []\n",
    "valid_indexs = []\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(X=data_tp_df, y=data_tp_df['species_id'])):\n",
    "    valid_indexs.append(valid_index)\n",
    "    train_dataset = TrainDataset(data_tp_df.iloc[train_index], is_valid=False)\n",
    "    val_dataset = TrainDataset(data_tp_df.iloc[valid_index], is_valid=True)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    valid_dataloader = DataLoader(val_dataset, batch_size=batch_size, sampler=SequentialSampler(val_dataset), shuffle=False, num_workers=4)\n",
    "    data_folds.append((train_dataloader, valid_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:10.796238Z",
     "start_time": "2021-02-14T06:20:10.770185Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\",\n",
    "                 temperature=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.temperature = temperature\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.bn_att = nn.BatchNorm1d(out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        energy = torch.tanh(self.att(x))\n",
    "        norm_att = torch.softmax(energy, dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Config.model(pretrained=True)\n",
    "        if Config.model_name.startswith('densenet'):\n",
    "            self.in_features = self.model.classifier.in_features\n",
    "        else:\n",
    "            self.in_features = self.model.fc.in_features\n",
    "        self.fc = nn.Linear(self.in_features, self.in_features, bias=True)\n",
    "        self.att_block = AttBlock(self.in_features, Config.num_class, activation='sigmoid')\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.model.forward_features(X)\n",
    "        X = torch.mean(X, dim=-1)\n",
    "        X = X.transpose(1, 2)\n",
    "        X = F.relu(self.fc(X))\n",
    "        X = X.transpose(1, 2)\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(X)\n",
    "        output_dict = {\n",
    "            'framewise_output': segmentwise_output,\n",
    "            'clipwise_output': clipwise_output,\n",
    "        }\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:11.202051Z",
     "start_time": "2021-02-14T06:20:11.186266Z"
    }
   },
   "outputs": [],
   "source": [
    "# label-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LWLRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    # Number of GT labels per instance\n",
    "    num_labels = labels.sum(-1)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = scores.sum() / labels.sum()\n",
    "    return score.item()\n",
    "\n",
    "# # Sample usage\n",
    "# y_true = torch.tensor(np.array([[1, 1, 0], [1, 0, 1], [0, 0, 1]]))\n",
    "# y_score = torch.tensor(np.random.randn(3, 3))\n",
    "# print(LRAP(y_score, y_true), LWLRAP(y_score, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:20:11.546510Z",
     "start_time": "2021-02-14T06:20:11.536530Z"
    }
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=5):\n",
    "    \"\"\"\n",
    "    Applies mixup to a sample\n",
    "    Arguments:\n",
    "        x {torch tensor} -- Input batch\n",
    "        y {torch tensor} -- Labels\n",
    "    Keyword Arguments:\n",
    "        alpha {float} -- Parameter of the beta distribution (default: {0.4})\n",
    "    Returns:\n",
    "        torch tensor  -- Mixed input\n",
    "        torch tensor  -- Labels of the original batch\n",
    "        torch tensor  -- Labels of the shuffle batch\n",
    "        float  -- Probability samples by the beta distribution\n",
    "    \"\"\"\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "    index = torch.randperm(x.size()[0]).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# for step, (x, y_batch) in enumerate(train_loader):\n",
    "    \n",
    "#     if np.random.rand() < mixup_proba:\n",
    "#         x, y_a, y_b, _ = mixup_data(x.cuda(), y_batch.cuda(), alpha=alpha)\n",
    "#         y_batch = torch.clamp(y_a + y_b, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:23:24.579497Z",
     "start_time": "2021-02-14T06:23:24.541280Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader, criterion, history, n_iters, writer, fold):\n",
    "    model.eval()\n",
    "    costs = []\n",
    "    rocs = []\n",
    "    metrics = []\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    y_probs = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            costs.append(loss.item())\n",
    "            y_true, y_prob= y.cpu(), y_output['clipwise_output'].detach().cpu()\n",
    "            y_pred = (y_prob+0.5).int()\n",
    "            y_trues.append(y_true.numpy())\n",
    "            y_probs.append(y_prob.numpy())\n",
    "            y_preds.append(y_pred.numpy())\n",
    "            metrics.append(LWLRAP(y_prob, y.cpu()))\n",
    "    \n",
    "    mean_rocs = sklearn.metrics.roc_auc_score(np.concatenate(y_trues), np.concatenate(y_probs))\n",
    "    mean_costs = np.mean(costs)\n",
    "    mean_metrics = np.mean(metrics)\n",
    "    writer.add_scalar('fold_{}/validate_roc'.format(fold), mean_rocs, n_iters)\n",
    "    writer.add_scalar('fold_{}/validate_loss'.format(fold), mean_costs, n_iters)\n",
    "    writer.add_scalar('fold_{}/validate_LWLRAP'.format(fold), mean_metrics, n_iters)\n",
    "    if mean_metrics > history['best_metrics'][fold]: \n",
    "        history['best_roc'][fold] = mean_rocs\n",
    "        history['best_metrics'][fold] = mean_metrics\n",
    "        torch.save(model.state_dict(), history['best_model_path'][fold])\n",
    "    return mean_costs, mean_rocs, mean_metrics\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, writer, fold, step=True):\n",
    "    model.train()\n",
    "    costs = []\n",
    "    metrics = []\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    y_probs = []\n",
    "    val_loss, val_roc = 0, 0\n",
    "    optimizer.zero_grad()\n",
    "    with tqdm(total=len(train_dataloader.dataset), desc='Epoch{}'.format(epoch)) as pbar:\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            if np.random.rand() < Config.mixup_proba:\n",
    "                X, y_a, y_b, _ = mixup_data(X, y, alpha=Config.mixup_alpha)\n",
    "                y = torch.clamp(y_a + y_b, 0, 1)\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "            optimizer.step()\n",
    "            if step:\n",
    "                scheduler.step()\n",
    "            costs.append(loss.item())\n",
    "            y_true, y_prob= y.cpu(), y_output['clipwise_output'].detach().cpu()\n",
    "            y_pred = (y_prob+0.5).int()\n",
    "            y_trues.append(y_true.numpy())\n",
    "            y_probs.append(y_prob.numpy())\n",
    "            y_preds.append(y_pred.numpy())\n",
    "            metrics.append(LWLRAP(y_prob, y_true))\n",
    "#             rocs.append(sklearn.metrics.roc_auc_score(y.cpu(), y_prob))\n",
    "#                 rocs.append((y_pred == y.cpu()).float().mean().item())\n",
    "            pbar.update(y.size(0))\n",
    "            n_iters = idx + len(train_dataloader) * (epoch-1)\n",
    "            if idx in validate_points:\n",
    "                val_loss, val_roc, val_metrics = validate(model, val_dataloader, criterion, history, n_iters, writer, fold)\n",
    "                model.train()\n",
    "            writer.add_scalar('fold_{}/train_loss'.format(fold), costs[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/train_LWLRAP'.format(fold), metrics[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/learning_rate'.format(fold), scheduler.get_last_lr()[0], n_iters)\n",
    "            pbar.set_postfix_str('loss:{:.3f}, val-loss:{:.3f}, val-roc:{:.4f}'.format(np.mean(costs[-10:]),  val_loss, val_roc))\n",
    "            torch.cuda.empty_cache()\n",
    "        writer.add_scalar('fold_{}/train_roc'.format(fold), sklearn.metrics.roc_auc_score(np.concatenate(y_trues), np.concatenate(y_probs)), n_iters)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:23:24.645926Z",
     "start_time": "2021-02-14T06:23:24.636641Z"
    }
   },
   "outputs": [],
   "source": [
    "class PANNsLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_ = input[\"clipwise_output\"]\n",
    "        input_ = torch.clamp(input_, 0, 1)\n",
    "        target = target.float()\n",
    "        return self.bce(input_, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-14T06:23:24.434Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 972/972 [00:41<00:00, 51.36it/s, loss:0.381, val-loss:0.255, val-roc:0.4978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1581940020202078 0\n",
      "save_model\n"
     ]
    }
   ],
   "source": [
    "# pos_weights = torch.ones(Config.num_class)\n",
    "# counts = data_tp_df['species_id'].value_counts()\n",
    "# for i in range(Config.num_class):\n",
    "#     pos_weights[i] = (sum(counts)-counts[i])/counts[i]\n",
    "# loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weights).cuda()\n",
    "\n",
    "# def criterion(y_pred, y_target):\n",
    "#     loss = loss_function(y_pred, y_target.float())\n",
    "#     return loss\n",
    "criterion = PANNsLoss().cuda()\n",
    "\n",
    "\n",
    "time_stamp = '{0:%m_%d_%H_%M}'.format(datetime.datetime.now())\n",
    "history = {\n",
    "    'config': Config,\n",
    "    'best_roc': [0]*len(data_folds),\n",
    "    'best_metrics': [0]*len(data_folds), \n",
    "    'best_model_path': [os.path.join(model_path, '{}_{}_fold_{}.pth'.format(Config.model_name, time_stamp, i)) for i in range(len(data_folds))]\n",
    "}\n",
    "writer = SummaryWriter(log_dir=os.path.join(tensorboard_path, '{}_{}'.format(Config.model_name, time_stamp)))\n",
    "for idx, (train_dataloader, val_dataloader) in enumerate(data_folds):\n",
    "    validate_points = list(np.linspace(0, len(train_dataloader)-1, 2).astype(int))[1:]\n",
    "    model = Net().cuda()\n",
    "#     model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    epochs = 30\n",
    "    warmup_prob = 0.1\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, epochs=epochs, steps_per_epoch=len(train_dataloader), pct_start=warmup_prob, div_factor=25, anneal_strategy='cos', cycle_momentum=True)\n",
    "#     scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(warmup_prob*len(train_dataloader)*epochs), num_training_steps=len(train_dataloader)*epochs)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler,  writer, fold=idx, step=True)\n",
    "#         scheduler.step()\n",
    "        gc.collect()\n",
    "#     torch.save(model.state_dict(), history['best_model_path'][idx])\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "with open(os.path.join(model_path, '{}_{}_history.pkl'.format(Config.model_name, time_stamp)), 'wb') as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T09:48:23.143898Z",
     "start_time": "2021-02-03T09:48:23.132904Z"
    }
   },
   "source": [
    "## Predict Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T12:51:00.785477Z",
     "start_time": "2021-02-08T12:51:00.779770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnest_augment_RandomCrop_mixup_256_600_02_08_03_40_history.pkl\n"
     ]
    }
   ],
   "source": [
    "# for file in os.listdir(model_path):\n",
    "#     if file.endswith('.pkl'):\n",
    "#         print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:12:52.118691Z",
     "start_time": "2021-02-14T06:12:51.639064Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(os.path.join(model_path, 'resnest_augment_RandomCrop_mixup_256_600_02_08_03_40_history.pkl'), 'rb') as f:\n",
    "#     history = pickle.load(f)\n",
    "model = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:14:04.272880Z",
     "start_time": "2021-02-14T06:14:04.263475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': __main__.Config,\n",
       " 'best_roc': [0.982298636332259,\n",
       "  0.9831462753720066,\n",
       "  0.9764797753874944,\n",
       "  0.9701418814880866,\n",
       "  0.9774833974142592],\n",
       " 'best_metrics': [0.8677614182692308,\n",
       "  0.8792319723942208,\n",
       "  0.8869343361659356,\n",
       "  0.8781604891134085,\n",
       "  0.8872028704573935],\n",
       " 'best_model_path': ['/dev/shm/model_save/resnet34d_augment_RandomCrop_mixup_attention_02_14_04_25_fold_0.pth',\n",
       "  '/dev/shm/model_save/resnet34d_augment_RandomCrop_mixup_attention_02_14_04_25_fold_1.pth',\n",
       "  '/dev/shm/model_save/resnet34d_augment_RandomCrop_mixup_attention_02_14_04_25_fold_2.pth',\n",
       "  '/dev/shm/model_save/resnet34d_augment_RandomCrop_mixup_attention_02_14_04_25_fold_3.pth',\n",
       "  '/dev/shm/model_save/resnet34d_augment_RandomCrop_mixup_attention_02_14_04_25_fold_4.pth']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:12:53.070151Z",
     "start_time": "2021-02-14T06:12:52.874612Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dev/shm/model_save/resnet34d_augment_RandomCrop_mixup_attention_02_14_04_25_fold_0.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-44cb7b2ffb9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_model_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dev/shm/model_save/resnet34d_augment_RandomCrop_mixup_attention_02_14_04_25_fold_0.pth'"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "for path in history['best_model_path']:\n",
    "    model.load_state_dict(torch.load(path, map_location= torch.device('cpu')), strict=True)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            a, b, c, d, e = batch.size()\n",
    "            X = batch.view(a*b, c, d, e).cuda()\n",
    "            output = model(X, attn_mask=False)\n",
    "            pred1 = output['clipwise_output'].view(a, b, 24).max(dim=1)[0].cpu().detach().numpy()\n",
    "\n",
    "            pred2 = output['framewise_output'].view(a, b, -1, 24).max(dim=2)[0].max(dim=1)[0].cpu().detach().numpy()\n",
    "            preds.append((pred1+pred2)/2)\n",
    "    folds.append(np.concatenate(preds, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-13T01:10:28.999Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(columns=['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'], dtype=np.float32)\n",
    "sub['recording_id'] = [file.split('.')[0] for file in test_files]\n",
    "sub.iloc[:, 1:] = sum(folds)/len(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-13T01:10:29.631Z"
    }
   },
   "outputs": [],
   "source": [
    "time_stamp = '{0:%m_%d_%H_%M}'.format(datetime.datetime.now())\n",
    "sub.to_csv(os.path.join(res_path, 'submission_{}_{}_{:.4f}.csv'.format(Config.model_name, time_stamp, np.mean(history['best_metrics']))), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T00:56:49.565103Z",
     "start_time": "2021-02-13T00:56:49.555333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317194581031799"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history['best_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T00:56:50.307802Z",
     "start_time": "2021-02-13T00:56:50.300029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8855923084819054"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history['best_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
