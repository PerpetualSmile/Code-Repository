{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:12:57.510850Z",
     "start_time": "2021-02-13T07:12:56.457610Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:12:58.174406Z",
     "start_time": "2021-02-13T07:12:57.512685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:12:58.184758Z",
     "start_time": "2021-02-13T07:12:58.176724Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "GLOBAL_SEED = 0\n",
    "setup_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:12:58.202877Z",
     "start_time": "2021-02-13T07:12:58.188409Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/dev/shm/data'\n",
    "feat_path = '/root/s/RFCX/features'\n",
    "res_path = '/root/s/RFCX/res'\n",
    "model_path = '/dev/shm/model_save'\n",
    "tensorboard_path = '/root/s/RFCX/tensorboard'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if not os.path.exists(res_path):\n",
    "    os.makedirs(res_path)\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:12:58.249563Z",
     "start_time": "2021-02-13T07:12:58.206247Z"
    }
   },
   "outputs": [],
   "source": [
    "data_tp_df=pd.read_csv(os.path.join(data_path, 'train_tp.csv'))\n",
    "data_fp_df=pd.read_csv(os.path.join(data_path, 'train_fp.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:12:58.256304Z",
     "start_time": "2021-02-13T07:12:58.251549Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_class = 24\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 256\n",
    "    sr = 32000\n",
    "    segment_length = 10 * sr\n",
    "    fmin = 80\n",
    "    fmax = 16000\n",
    "    \n",
    "    resize = True\n",
    "    img_shape = (256, 400)\n",
    "    \n",
    "    wav_augment = True\n",
    "    spec_augment = True\n",
    "    mixup_proba = 0.5\n",
    "    mixup_alpha = 5\n",
    "    \n",
    "    model = 'resnest50'\n",
    "    model_name = 'resnest50_augment_RandomCrop_mixup'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:12:59.028238Z",
     "start_time": "2021-02-13T07:12:58.796367Z"
    }
   },
   "outputs": [],
   "source": [
    "\"https://www.kaggle.com/gopidurgaprasad/audio-augmentation-albumentations/\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, PolarityInversion, Gain, AddGaussianSNR\n",
    "\n",
    "\n",
    "class AudioTransform(BasicTransform):\n",
    "    \"\"\"Transform for Audio task\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "    \n",
    "      \n",
    "class MelSpectrogram(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, parameters, always_apply=False, p=0.5):\n",
    "        super(MelSpectrogram, self).__init__(always_apply, p)\n",
    "\n",
    "        self.parameters = parameters\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "        melspec = librosa.feature.melspectrogram(sound, sr=sr, **self.parameters)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "        melspec = melspec.astype(np.float32)\n",
    "        return melspec, sr\n",
    "\n",
    "    \n",
    "class SpecAugment(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, num_mask=2, freq_masking=0.15, time_masking=0.20, always_apply=False, p=0.5):\n",
    "        super(SpecAugment, self).__init__(always_apply, p)\n",
    "\n",
    "        self.num_mask = num_mask\n",
    "        self.freq_masking = freq_masking\n",
    "        self.time_masking = time_masking\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "        spec_aug = self.spec_augment(melspec, \n",
    "                                     self.num_mask,\n",
    "                                     self.freq_masking,\n",
    "                                     self.time_masking,\n",
    "                                     melspec.min())\n",
    "        return spec_aug, sr\n",
    "    \n",
    "    # Source: https://www.kaggle.com/davids1992/specaugment-quick-implementation\n",
    "    def spec_augment(self, \n",
    "                    spec: np.ndarray,\n",
    "                    num_mask=2,\n",
    "                    freq_masking=0.15,\n",
    "                    time_masking=0.20,\n",
    "                    value=0):\n",
    "        spec = spec.copy()\n",
    "        num_mask = random.randint(1, num_mask)\n",
    "        for i in range(num_mask):\n",
    "            all_freqs_num, all_frames_num  = spec.shape\n",
    "            freq_percentage = random.uniform(0.0, freq_masking)\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[f0:f0 + num_freqs_to_mask, :] = value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[:, t0:t0 + num_frames_to_mask] = value\n",
    "\n",
    "        return spec\n",
    "\n",
    "    \n",
    "class SpectToImage(AudioTransform):\n",
    "\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(SpectToImage, self).__init__(always_apply, p)\n",
    "        \n",
    "        \n",
    "    def mono_to_color(self, X: np.ndarray,\n",
    "                      mean=None,\n",
    "                      std=None,\n",
    "                      norm_max=None,\n",
    "                      norm_min=None,\n",
    "                      eps=1e-6):\n",
    "        \"\"\"\n",
    "        Code from https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Standardize\n",
    "        mean = mean or X.mean()\n",
    "        X = X - mean\n",
    "        std = std or X.std()\n",
    "        Xstd = X / (std + eps)\n",
    "        _min, _max = Xstd.min(), Xstd.max()\n",
    "        norm_max = norm_max or _max\n",
    "        norm_min = norm_min or _min\n",
    "        if (_max - _min) > eps:\n",
    "            # Normalize to [0, 255]\n",
    "            V = Xstd\n",
    "            V[V < norm_min] = norm_min\n",
    "            V[V > norm_max] = norm_max\n",
    "            V = (V - norm_min) / (norm_max - norm_min)\n",
    "        else:\n",
    "            # Just zero\n",
    "            V = np.zeros_like(Xstd, dtype=np.float32)\n",
    "        return V\n",
    "    \n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "        image = self.mono_to_color(melspec)\n",
    "        if Config.resize:\n",
    "            image = resize(image, Config.img_shape)\n",
    "        image = np.stack([image, image, image], axis=-1)\n",
    "#         delta = librosa.feature.delta(image)\n",
    "#         accelerate = librosa.feature.delta(image, order=2)\n",
    "#         image = np.stack([image, delta, accelerate], axis=-1)\n",
    "#         image = image.astype(np.float32) / 100.0\n",
    "        # (n_mels, time_step, 3) --> (3, time_step, n_mels)\n",
    "        return image.transpose(2, 1, 0)\n",
    "\n",
    "\n",
    "sound_augment = Compose([\n",
    "    PolarityInversion(p=0.2),\n",
    "    Gain(min_gain_in_db=-15, max_gain_in_db=15, p=0.3),\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.1),\n",
    "    AddGaussianSNR(max_SNR=0.5, p=0.2),\n",
    "#     TimeStretch(min_rate=0.8, max_rate=1.25, p=0.2)\n",
    "#     Shift(min_fraction=-0.2, max_fraction=0.2, p=0.2)\n",
    "])\n",
    "\n",
    "\n",
    "melspectrogram_parameters = {\n",
    "        \"n_mels\": Config.n_mels,\n",
    "        'n_fft': Config.n_fft, \n",
    "        'hop_length': Config.hop_length,\n",
    "        'fmin': Config.fmin, \n",
    "        'fmax': Config.fmax \n",
    "    }\n",
    "\n",
    "spec_augment = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpecAugment(p=0.2),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "to_image = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:12:59.045886Z",
     "start_time": "2021-02-13T07:12:59.030469Z"
    }
   },
   "outputs": [],
   "source": [
    "ONE_HOT = np.eye(Config.num_class)\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_df, is_valid=False):\n",
    "        self.data_df = data_df\n",
    "        self.is_valid = is_valid\n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def load_audio_clip(self, audio_file_path, t_min, t_max):\n",
    "        # All sound files are 48000 bitrate, no need to slowly resample\n",
    "        wav, _ = librosa.load(audio_file_path, sr=Config.sr)\n",
    "\n",
    "        t_min = float(t_min) * Config.sr\n",
    "        t_max = float(t_max) * Config.sr\n",
    "\n",
    "        # Positioning sound slice\n",
    "        begin = max(t_max - Config.segment_length, 0)\n",
    "        end = t_min\n",
    "        random_begin = np.random.randint(begin, end)\n",
    "        random_end = random_begin + Config.segment_length\n",
    "        if random_end > len(wav):\n",
    "            random_end = len(wav)\n",
    "            random_begin = random_end - Config.segment_length\n",
    "\n",
    "        slice = wav[int(random_begin):int(random_end)]\n",
    "        return slice\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        s = self.data_df.iloc[idx]\n",
    "        audio_file_path = os.path.join(data_path, 'train', s['recording_id']+'.wav')\n",
    "        wav = self.load_audio_clip(audio_file_path, s['t_min'], s['t_max'])\n",
    "        if self.is_valid:\n",
    "            image = to_image(data=(wav, Config.sr))['data']\n",
    "        else:\n",
    "            if Config.wav_augment:\n",
    "                data = sound_augment(samples=wav, sample_rate=Config.sr), Config.sr\n",
    "            else:\n",
    "                data = wav, Config.sr\n",
    "            if Config.spec_augment:\n",
    "                image = spec_augment(data=data)['data']\n",
    "            else:\n",
    "                image = to_image(data=data)['data']\n",
    "        return torch.tensor(image, dtype=torch.float32), ONE_HOT[s['species_id']]\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_files):\n",
    "        self.test_files = test_files \n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_file_path = os.path.join(data_path, 'test', self.test_files[idx])\n",
    "        wav, _ = librosa.load(audio_file_path, sr=Config.sr)\n",
    "        segments = len(wav) / Config.segment_length\n",
    "        segments = int(np.ceil(segments))\n",
    "        img = []\n",
    "        for i in range(0, segments):\n",
    "            # Last segment going from the end\n",
    "            if (i + 1) * Config.segment_length > len(wav):\n",
    "                slice = wav[len(wav) - Config.segment_length:len(wav)]\n",
    "            else:\n",
    "                slice = wav[i * Config.segment_length:(i + 1) * Config.segment_length]\n",
    "            img.append(to_image(data=(slice, Config.sr))['data'])\n",
    "        return torch.tensor(img, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:12:59.083584Z",
     "start_time": "2021-02-13T07:12:59.047892Z"
    }
   },
   "outputs": [],
   "source": [
    "test_files = sorted(os.listdir(os.path.join(data_path, 'test')))\n",
    "test_dataset = TestDataset(test_files)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, sampler=SequentialSampler(test_dataset), shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:12:59.357916Z",
     "start_time": "2021-02-13T07:12:59.335004Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=GLOBAL_SEED)\n",
    "data_folds = []\n",
    "valid_indexs = []\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(X=data_tp_df, y=data_tp_df['species_id'])):\n",
    "    valid_indexs.append(valid_index)\n",
    "    train_dataset = TrainDataset(data_tp_df.iloc[train_index], is_valid=False)\n",
    "    val_dataset = TrainDataset(data_tp_df.iloc[valid_index], is_valid=True)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    valid_dataloader = DataLoader(val_dataset, batch_size=batch_size, sampler=SequentialSampler(val_dataset), shuffle=False, num_workers=4)\n",
    "    data_folds.append((train_dataloader, valid_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:12:59.866370Z",
     "start_time": "2021-02-13T07:12:59.855982Z"
    }
   },
   "outputs": [],
   "source": [
    "from resnest.torch import resnest50, resnest101, resnest200\n",
    "from torchvision.models import resnet34, resnet50, resnet101, resnet152, densenet121, densenet169, densenet201, mobilenet_v2, resnext50_32x4d, resnext101_32x8d, wide_resnet50_2, wide_resnet101_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:13:00.181761Z",
     "start_time": "2021-02-13T07:13:00.173827Z"
    }
   },
   "outputs": [],
   "source": [
    "model_map = {\n",
    "    'resnest50': resnest50, \n",
    "    'resnest101': resnest101, \n",
    "    'resnest200': resnest200, \n",
    "    'resnet34': resnet34, \n",
    "    'resnet50': resnet50, \n",
    "    'resnet101': resnet101, \n",
    "    'densenet121': densenet121,\n",
    "    'densenet169': densenet169,\n",
    "    'densenet201': densenet201,\n",
    "    'mobilenet_v2': mobilenet_v2,\n",
    "    'resnext50': resnext50_32x4d,\n",
    "    'resnext101': resnext101_32x8d,\n",
    "    'wide_resnet50': wide_resnet50_2,\n",
    "    'wide_resnet101': wide_resnet101_2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:13:00.593953Z",
     "start_time": "2021-02-13T07:13:00.577603Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = model_map[Config.model](pretrained=True)\n",
    "        if Config.model.startswith('res') or Config.model.startswith('wide'):\n",
    "            nb_ft = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(nb_ft, Config.num_class)\n",
    "        if Config.model.startswith('dense'):\n",
    "            nb_ft = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(nb_ft, Config.num_class)   \n",
    "        if Config.model == 'mobilenet_v2':\n",
    "            self.model.classifier = nn.Linear(1280, Config.num_class)\n",
    "        if Config.model.startswith('efficientnet'):\n",
    "            nb_ft = self.model._fc.in_features\n",
    "            self.model._fc = nn.Linear(nb_ft, Config.num_class)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:13:01.051223Z",
     "start_time": "2021-02-13T07:13:01.034038Z"
    }
   },
   "outputs": [],
   "source": [
    "# label-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LWLRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    # Number of GT labels per instance\n",
    "    num_labels = labels.sum(-1)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = scores.sum() / labels.sum()\n",
    "    return score.item()\n",
    "\n",
    "# # Sample usage\n",
    "# y_true = torch.tensor(np.array([[1, 1, 0], [1, 0, 1], [0, 0, 1]]))\n",
    "# y_score = torch.tensor(np.random.randn(3, 3))\n",
    "# print(LRAP(y_score, y_true), LWLRAP(y_score, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:13:01.637583Z",
     "start_time": "2021-02-13T07:13:01.627520Z"
    }
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=5):\n",
    "    \"\"\"\n",
    "    Applies mixup to a sample\n",
    "    Arguments:\n",
    "        x {torch tensor} -- Input batch\n",
    "        y {torch tensor} -- Labels\n",
    "    Keyword Arguments:\n",
    "        alpha {float} -- Parameter of the beta distribution (default: {0.4})\n",
    "    Returns:\n",
    "        torch tensor  -- Mixed input\n",
    "        torch tensor  -- Labels of the original batch\n",
    "        torch tensor  -- Labels of the shuffle batch\n",
    "        float  -- Probability samples by the beta distribution\n",
    "    \"\"\"\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "    index = torch.randperm(x.size()[0]).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# for step, (x, y_batch) in enumerate(train_loader):\n",
    "    \n",
    "#     if np.random.rand() < mixup_proba:\n",
    "#         x, y_a, y_b, _ = mixup_data(x.cuda(), y_batch.cuda(), alpha=alpha)\n",
    "#         y_batch = torch.clamp(y_a + y_b, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:13:02.509720Z",
     "start_time": "2021-02-13T07:13:02.476224Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader, criterion, history, n_iters, writer, fold):\n",
    "    model.eval()\n",
    "    costs = []\n",
    "    accs = []\n",
    "    metrics = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            costs.append(loss.item())\n",
    "            metrics.append(LWLRAP(y_output.detach().cpu(), y.cpu()))\n",
    "            y_prob = y_output.detach().sigmoid()\n",
    "            y_pred = (y_prob+0.5).int()\n",
    "            accs.append((y_pred == y).float().mean().item())\n",
    "    mean_accs = np.mean(accs)\n",
    "    mean_costs = np.mean(costs)\n",
    "    mean_metrics = np.mean(metrics)\n",
    "    writer.add_scalar('fold_{}/validate_accuracy'.format(fold), mean_accs, n_iters)\n",
    "    writer.add_scalar('fold_{}/validate_loss'.format(fold), mean_costs, n_iters)\n",
    "    writer.add_scalar('fold_{}/validate_LWLRAP'.format(fold), mean_metrics, n_iters)\n",
    "    history['best_acc'][fold] = mean_accs\n",
    "    history['best_metrics'][fold] = mean_metrics\n",
    "#     if mean_accs > history['best_acc'][fold]:  \n",
    "#         history['best_acc'][fold] = mean_accs\n",
    "#         history['best_metrics'][fold] = mean_metrics\n",
    "#         torch.save(model.state_dict(), history['best_model_path'][fold])\n",
    "    return mean_costs, mean_accs, mean_metrics\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, writer, fold, step=True):\n",
    "    model.train()\n",
    "    costs = []\n",
    "    accs = []\n",
    "    metrics = []\n",
    "    val_loss, val_acc = 0, 0\n",
    "    optimizer.zero_grad()\n",
    "    with tqdm(total=len(train_dataloader.dataset), desc='Epoch{}'.format(epoch)) as pbar:\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            X, y = batch\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            if np.random.rand() < Config.mixup_proba:\n",
    "                X, y_a, y_b, _ = mixup_data(X, y, alpha=Config.mixup_alpha)\n",
    "                y = torch.clamp(y_a + y_b, 0, 1)\n",
    "            y_output = model(X)    \n",
    "            loss = criterion(y_output, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "            optimizer.step()\n",
    "            if step:\n",
    "                scheduler.step()\n",
    "            with torch.no_grad():\n",
    "                costs.append(loss.item())\n",
    "                y_prob = y_output.detach().sigmoid()\n",
    "                y_pred = (y_prob+0.5).int()\n",
    "                accs.append((y_pred == y).float().mean().item())\n",
    "                metrics.append(LWLRAP(y_output.detach().cpu(), y.cpu()))\n",
    "                pbar.update(y.size(0))\n",
    "            n_iters = idx + len(train_dataloader) * (epoch-1)\n",
    "            if idx in validate_points:\n",
    "                val_loss, val_acc, val_metrics = validate(model, val_dataloader, criterion, history, n_iters, writer, fold)\n",
    "                model.train()\n",
    "            writer.add_scalar('fold_{}/train_accuracy'.format(fold), accs[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/train_loss'.format(fold), costs[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/train_LWLRAP'.format(fold), metrics[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/learning_rate'.format(fold), scheduler.get_last_lr()[0], n_iters)\n",
    "            pbar.set_postfix_str('loss:{:.3f}, acc:{:.3f}, val-loss:{:.3f}, val-acc:{:.4f}'.format(np.mean(costs[-10:]), np.mean(accs[-10:]), val_loss, val_acc))\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:13:36.324043Z",
     "start_time": "2021-02-13T07:13:04.297446Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1:  49%|████▉     | 480/972 [00:24<00:25, 19.46it/s, loss:1.680, acc:0.496, val-loss:0.000, val-acc:0.0000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6f7ff63c288b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#     scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(warmup_prob*len(train_dataloader)*epochs), num_training_steps=len(train_dataloader)*epochs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#         scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-8a1735dbd989>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, writer, fold, step)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pos_weights = torch.ones(Config.num_class)\n",
    "counts = data_tp_df['species_id'].value_counts()\n",
    "for i in range(Config.num_class):\n",
    "    pos_weights[i] = (sum(counts)-counts[i])/counts[i]\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weights).cuda()\n",
    "\n",
    "def criterion(y_pred, y_target):\n",
    "    loss = loss_function(y_pred, y_target.float())\n",
    "    return loss\n",
    "\n",
    "\n",
    "time_stamp = '{0:%m_%d_%H_%M}'.format(datetime.datetime.now())\n",
    "history = {\n",
    "    'config': Config,\n",
    "    'best_acc': [0]*len(data_folds),\n",
    "    'best_metrics': [0]*len(data_folds), \n",
    "    'best_model_path': [os.path.join(model_path, '{}_{}_fold_{}.pth'.format(Config.model_name, time_stamp, i)) for i in range(len(data_folds))]\n",
    "}\n",
    "writer = SummaryWriter(log_dir=os.path.join(tensorboard_path, '{}_{}'.format(Config.model_name, time_stamp)))\n",
    "for idx, (train_dataloader, val_dataloader) in enumerate(data_folds):\n",
    "    validate_points = list(np.linspace(0, len(train_dataloader)-1, 2).astype(int))[1:]\n",
    "    model = Net().cuda()\n",
    "#     model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    epochs = 40\n",
    "    warmup_prob = 0.3\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, epochs=epochs, steps_per_epoch=len(train_dataloader), pct_start=warmup_prob, div_factor=25, anneal_strategy='cos', cycle_momentum=True)\n",
    "#     scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(warmup_prob*len(train_dataloader)*epochs), num_training_steps=len(train_dataloader)*epochs)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler,  writer, fold=idx, step=True)\n",
    "#         scheduler.step()\n",
    "        gc.collect()\n",
    "    torch.save(model.state_dict(), history['best_model_path'][idx])\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "with open(os.path.join(model_path, '{}_{}_history.pkl'.format(Config.model_name, time_stamp)), 'wb') as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T09:48:23.143898Z",
     "start_time": "2021-02-03T09:48:23.132904Z"
    }
   },
   "source": [
    "## Predict Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T12:51:00.785477Z",
     "start_time": "2021-02-08T12:51:00.779770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnest_augment_RandomCrop_mixup_256_600_02_08_03_40_history.pkl\n"
     ]
    }
   ],
   "source": [
    "# for file in os.listdir(model_path):\n",
    "#     if file.endswith('.pkl'):\n",
    "#         print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T05:51:02.844500Z",
     "start_time": "2021-02-13T05:51:01.788814Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(os.path.join(model_path, 'resnest_augment_RandomCrop_mixup_256_600_02_08_03_40_history.pkl'), 'rb') as f:\n",
    "#     history = pickle.load(f)\n",
    "model = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T06:21:54.387998Z",
     "start_time": "2021-02-13T05:51:03.557295Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [06:09<00:00,  2.96s/it]\n",
      "100%|██████████| 125/125 [06:12<00:00,  2.98s/it]\n",
      "100%|██████████| 125/125 [06:08<00:00,  2.94s/it]\n",
      "100%|██████████| 125/125 [06:08<00:00,  2.95s/it]\n",
      "100%|██████████| 125/125 [06:10<00:00,  2.97s/it]\n"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "for path in history['best_model_path']:\n",
    "    model.load_state_dict(torch.load(path, map_location= torch.device('cpu')), strict=True)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            a, b, c, d, e = batch.size()\n",
    "            X = batch.view(a*b, c, d, e).cuda()\n",
    "            output = model(X)\n",
    "            pred = F.sigmoid(output).view(a, b, -1).max(dim=1)[0].cpu().detach().numpy()\n",
    "            preds.append(pred)\n",
    "    folds.append(np.concatenate(preds, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T06:21:54.431491Z",
     "start_time": "2021-02-13T06:21:54.392566Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(columns=['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'], dtype=np.float32)\n",
    "sub['recording_id'] = [file.split('.')[0] for file in test_files]\n",
    "sub.iloc[:, 1:] = sum(folds)/len(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T06:21:54.516947Z",
     "start_time": "2021-02-13T06:21:54.433227Z"
    }
   },
   "outputs": [],
   "source": [
    "time_stamp = '{0:%m_%d_%H_%M}'.format(datetime.datetime.now())\n",
    "sub.to_csv(os.path.join(res_path, 'submission_{}_{}_{:.4f}.csv'.format(Config.model_name, time_stamp, np.mean(history['best_metrics']))), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T00:56:49.565103Z",
     "start_time": "2021-02-13T00:56:49.555333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317194581031799"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history['best_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T00:56:50.307802Z",
     "start_time": "2021-02-13T00:56:50.300029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8855923084819054"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history['best_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
