{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:36.194902Z",
     "start_time": "2021-02-11T05:07:34.144891Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "import sklearn\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:37.413900Z",
     "start_time": "2021-02-11T05:07:36.196280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from IPython.core.debugger import set_trace\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:37.427445Z",
     "start_time": "2021-02-11T05:07:37.418904Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "GLOBAL_SEED = 42\n",
    "setup_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:37.443390Z",
     "start_time": "2021-02-11T05:07:37.431682Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/dev/shm/data'\n",
    "feat_path = '/root/s/RFCX/features'\n",
    "res_path = '/root/s/RFCX/res'\n",
    "model_path = '/root/s/RFCX/model_save'\n",
    "tensorboard_path = '/root/s/RFCX/tensorboard'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if not os.path.exists(res_path):\n",
    "    os.makedirs(res_path)\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:37.473720Z",
     "start_time": "2021-02-11T05:07:37.444848Z"
    }
   },
   "outputs": [],
   "source": [
    "data_tp_df=pd.read_csv(os.path.join(data_path, 'train_tp.csv'))\n",
    "data_fp_df=pd.read_csv(os.path.join(data_path, 'train_fp.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:37.477596Z",
     "start_time": "2021-02-11T05:07:37.475136Z"
    }
   },
   "outputs": [],
   "source": [
    "# count_series = data_tp_df['recording_id'].value_counts()[data_tp_df['recording_id']]\n",
    "# count_series.index = data_tp_df.index\n",
    "# data_tp_df['counts'] = count_series\n",
    "# def process_overlap(df):\n",
    "#     if df.counts() == 1:\n",
    "#         return d\n",
    "#     return d\n",
    "# data_tp_df.groupby('recording_id').apply(f)\n",
    "# data_tp_df[data_tp_df['counts'] >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:37.489093Z",
     "start_time": "2021-02-11T05:07:37.478846Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_class = 24\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 256\n",
    "    sr = 32000\n",
    "    segment_length = 10 * sr\n",
    "    fmin = 80\n",
    "    fmax = 16000\n",
    "    \n",
    "    resize = False\n",
    "    img_shape = (256, 600)\n",
    "    \n",
    "    wav_augment = True\n",
    "    spec_augment = True\n",
    "    spec_augprob = 0.5\n",
    "    mixup_proba = 0.0\n",
    "    mixup_alpha = 5\n",
    "    \n",
    "    attenion_border = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:38.043485Z",
     "start_time": "2021-02-11T05:07:37.490649Z"
    }
   },
   "outputs": [],
   "source": [
    "\"https://www.kaggle.com/gopidurgaprasad/audio-augmentation-albumentations/\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, PolarityInversion, Gain, AddGaussianSNR\n",
    "\n",
    "\n",
    "class AudioTransform(BasicTransform):\n",
    "    \"\"\"Transform for Audio task\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "    \n",
    "      \n",
    "class MelSpectrogram(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, parameters, always_apply=False, p=0.5):\n",
    "        super(MelSpectrogram, self).__init__(always_apply, p)\n",
    "\n",
    "        self.parameters = parameters\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(sound, sr=sr, **self.parameters)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "        melspec = melspec.astype(np.float32)\n",
    "        return melspec, sr\n",
    "    \n",
    "    \n",
    "class SpecAugment(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, num_mask=2, freq_masking=0.15, time_masking=0.20, always_apply=False, p=0.5):\n",
    "        super(SpecAugment, self).__init__(always_apply, p)\n",
    "\n",
    "        self.num_mask = num_mask\n",
    "        self.freq_masking = freq_masking\n",
    "        self.time_masking = time_masking\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "\n",
    "        spec_aug = self.spec_augment(melspec, \n",
    "                                     self.num_mask,\n",
    "                                     self.freq_masking,\n",
    "                                     self.time_masking,\n",
    "                                     melspec.min())\n",
    "        \n",
    "\n",
    "        return spec_aug, sr\n",
    "    \n",
    "    # Source: https://www.kaggle.com/davids1992/specaugment-quick-implementation\n",
    "    def spec_augment(self, \n",
    "                    spec: np.ndarray,\n",
    "                    num_mask=2,\n",
    "                    freq_masking=0.15,\n",
    "                    time_masking=0.20,\n",
    "                    value=0):\n",
    "        spec = spec.copy()\n",
    "        num_mask = random.randint(1, num_mask)\n",
    "        for i in range(num_mask):\n",
    "            all_freqs_num, all_frames_num  = spec.shape\n",
    "            freq_percentage = random.uniform(0.0, freq_masking)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[f0:f0 + num_freqs_to_mask, :] = value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[:, t0:t0 + num_frames_to_mask] = value\n",
    "\n",
    "        return spec\n",
    "\n",
    "    \n",
    "class SpectToImage(AudioTransform):\n",
    "\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(SpectToImage, self).__init__(always_apply, p)\n",
    "        \n",
    "        \n",
    "    def mono_to_color(self, X: np.ndarray,\n",
    "                      mean=None,\n",
    "                      std=None,\n",
    "                      norm_max=None,\n",
    "                      norm_min=None,\n",
    "                      eps=1e-6):\n",
    "        \"\"\"\n",
    "        Code from https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Standardize\n",
    "        mean = mean or X.mean()\n",
    "        X = X - mean\n",
    "        std = std or X.std()\n",
    "        Xstd = X / (std + eps)\n",
    "        _min, _max = Xstd.min(), Xstd.max()\n",
    "        norm_max = norm_max or _max\n",
    "        norm_min = norm_min or _min\n",
    "        if (_max - _min) > eps:\n",
    "            # Normalize to [0, 255]\n",
    "            V = Xstd\n",
    "            V[V < norm_min] = norm_min\n",
    "            V[V > norm_max] = norm_max\n",
    "            V = (V - norm_min) / (norm_max - norm_min)\n",
    "        else:\n",
    "            # Just zero\n",
    "            V = np.zeros_like(Xstd, dtype=np.float32)\n",
    "        return V\n",
    "    \n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "        image = self.mono_to_color(melspec)\n",
    "        if Config.resize:\n",
    "            image = resize(image, Config.img_shape)\n",
    "        image = np.stack([image, image, image], axis=-1)\n",
    "#         delta = librosa.feature.delta(image)\n",
    "#         accelerate = librosa.feature.delta(image, order=2)\n",
    "#         image = np.stack([image, delta, accelerate], axis=-1)\n",
    "#         image = image.astype(np.float32) / 100.0\n",
    "        # (n_mels, time_step, 3) --> (3, time_step, n_mels)\n",
    "        return image.transpose(2, 1, 0)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "sound_augment = Compose([\n",
    "    PolarityInversion(p=0.2),\n",
    "    Gain(min_gain_in_db=-15, max_gain_in_db=15, p=0.2),\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.2),\n",
    "    AddGaussianSNR(max_SNR=0.5, p=0.2),\n",
    "#     TimeStretch(min_rate=0.8, max_rate=1.25, p=0.2)\n",
    "#     Shift(min_fraction=-0.2, max_fraction=0.2, p=0.2)\n",
    "])\n",
    "\n",
    "\n",
    "melspectrogram_parameters = {\n",
    "        \"n_mels\": Config.n_mels,\n",
    "        'n_fft': Config.n_fft, \n",
    "        'hop_length': Config.hop_length,\n",
    "        'fmin': Config.fmin, \n",
    "        'fmax': Config.fmax \n",
    "    }\n",
    "\n",
    "spec_augment = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpecAugment(p=0.2),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "to_image = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:38.577327Z",
     "start_time": "2021-02-11T05:07:38.046033Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "ONE_HOT = np.eye(Config.num_class)\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_df, is_valid=False):\n",
    "        self.data_df = data_df\n",
    "        self.is_valid = is_valid\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def load_audio_clip(self, audio_file_path, t_min, t_max):\n",
    "        # All sound files are 48000 bitrate, no need to slowly resample\n",
    "        wav, _ = librosa.load(audio_file_path, sr=Config.sr)\n",
    "\n",
    "        t_min = float(t_min) * Config.sr\n",
    "        t_max = float(t_max) * Config.sr\n",
    "\n",
    "        # Positioning sound slice\n",
    "        begin = max(t_max - Config.segment_length, 0)\n",
    "        end = t_min\n",
    "        random_begin = np.random.randint(begin, end)\n",
    "        random_end = random_begin + Config.segment_length\n",
    "        if random_end > len(wav):\n",
    "            random_end = len(wav)\n",
    "            random_begin = random_end - Config.segment_length\n",
    "\n",
    "        slice = wav[int(random_begin):int(random_end)]\n",
    "        t_min_ratio = (t_min - random_begin)/Config.segment_length\n",
    "        t_max_ratio = (t_max - random_begin)/Config.segment_length\n",
    "        return slice, t_min_ratio, t_max_ratio\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        s = self.data_df.iloc[idx]\n",
    "        audio_file_path = os.path.join(data_path, 'train', s['recording_id']+'.wav')\n",
    "        wav, t_min_ratio, t_max_ratio = self.load_audio_clip(audio_file_path, s['t_min'], s['t_max'])\n",
    "        if not self.is_valid and Config.wav_augment:\n",
    "            wav = sound_augment(samples=wav, sample_rate=Config.sr)\n",
    "        return torch.tensor(wav, dtype=torch.float32), ONE_HOT[s['species_id']], t_min_ratio, t_max_ratio\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_files):\n",
    "        self.test_files = test_files \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_file_path = os.path.join(data_path, 'test', self.test_files[idx])\n",
    "        wav, _ = librosa.load(audio_file_path, sr=Config.sr)\n",
    "        segments = len(wav) / Config.segment_length\n",
    "        segments = int(np.ceil(segments))\n",
    "        wavs = []\n",
    "        for i in range(0, segments):\n",
    "            # Last segment going from the end\n",
    "            if (i + 1) * Config.segment_length > len(wav):\n",
    "                slice = wav[len(wav) - Config.segment_length:len(wav)]\n",
    "            else:\n",
    "                slice = wav[i * Config.segment_length:(i + 1) * Config.segment_length]\n",
    "                \n",
    "            wavs.append(slice)\n",
    "#             img.append(to_image(data=(slice, Config.sr))['data'])\n",
    "        return torch.tensor(wavs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:38.604749Z",
     "start_time": "2021-02-11T05:07:38.579233Z"
    }
   },
   "outputs": [],
   "source": [
    "test_files = sorted(os.listdir(os.path.join(data_path, 'test')))\n",
    "test_dataset = TestDataset(test_files)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, sampler=SequentialSampler(test_dataset), shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:38.625093Z",
     "start_time": "2021-02-11T05:07:38.607175Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=GLOBAL_SEED)\n",
    "data_folds = []\n",
    "valid_indexs = []\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(X=data_tp_df, y=data_tp_df['species_id'])):\n",
    "    valid_indexs.append(valid_index)\n",
    "    train_dataset = TrainDataset(data_tp_df.iloc[train_index], is_valid=False)\n",
    "    val_dataset = TrainDataset(data_tp_df.iloc[valid_index], is_valid=True)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    valid_dataloader = DataLoader(val_dataset, batch_size=batch_size, sampler=SequentialSampler(val_dataset), shuffle=False, num_workers=4)\n",
    "    data_folds.append((train_dataloader, valid_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:38.628364Z",
     "start_time": "2021-02-11T05:07:38.626476Z"
    }
   },
   "outputs": [],
   "source": [
    "# time_steps = X.shape[2]\n",
    "# start = (time_steps * t_min_ratio).int()\n",
    "# end = torch.clamp((time_steps * t_max_ratio).int() + 2, min=0, max=time_steps)\n",
    "# attn_mask = torch.zeros_like(X) == 0\n",
    "# for i in range(X.shape[0]):\n",
    "#     attn_mask[i, :, start[i]:end[i], :] = False\n",
    "# X.masked_fill_(attn_mask, -float('inf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:38.660755Z",
     "start_time": "2021-02-11T05:07:38.629441Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:38.717647Z",
     "start_time": "2021-02-11T05:07:38.661735Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    pad = framewise_output[:, -1:, :].repeat(\n",
    "        1, frames_num - framewise_output.shape[1], 1)\n",
    "    \"\"\"tensor for padding\"\"\"\n",
    "\n",
    "    output = torch.cat((framewise_output, pad), dim=1)\n",
    "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "            bias=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "            bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
    "\n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        if pool_type == 'max':\n",
    "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg+max':\n",
    "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            raise Exception('Incorrect argument!')\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\",\n",
    "                 temperature=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.temperature = temperature\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.bn_att = nn.BatchNorm1d(out_features)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "        init_bn(self.bn_att)\n",
    "\n",
    "    def forward(self, x, t_min_ratio=None, t_max_ratio=None, attn_mask=False):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        energy = torch.tanh(self.att(x))\n",
    "        if attn_mask:\n",
    "            time_steps = energy.shape[2]\n",
    "            start = torch.clamp((time_steps * t_min_ratio).int()-Config.attenion_border, min=0, max=time_steps)\n",
    "            end = torch.clamp((time_steps * t_max_ratio).int() + 2 + Config.attenion_border, min=0, max=time_steps)\n",
    "            mask = torch.zeros_like(energy) == 0\n",
    "            if len(start.size()) == 1:\n",
    "                for i in range(energy.shape[0]):\n",
    "                    mask[i, :, start[i]:end[i]] = False\n",
    "            else:\n",
    "                for i in range(energy.shape[0]):\n",
    "                    mask[i, :, start[i][0]:end[i][0]] = False\n",
    "                    mask[i, :, start[i][1]:end[i][1]] = False\n",
    "            energy = energy.masked_fill(mask, -float('inf'))\n",
    "        norm_att = torch.softmax(energy, dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class feature_extractor(nn.Module):\n",
    "    def __init__(self, original):\n",
    "        super().__init__()\n",
    "        self.model = original\n",
    "    def forward(self, x):\n",
    "        x= self.model.extract_features(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class PANNsAtt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "        self.interpolate_ratio = 32  # Downsampled ratio\n",
    "        self.apply_aug = Config.spec_augment\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(\n",
    "            n_fft=Config.n_fft,\n",
    "            hop_length=Config.hop_length,\n",
    "            win_length=Config.n_fft,\n",
    "            window=window,\n",
    "            center=center,\n",
    "            pad_mode=pad_mode,\n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(\n",
    "            sr=Config.sr,\n",
    "            n_fft=Config.n_fft,\n",
    "            n_mels=Config.n_mels,\n",
    "            fmin=Config.fmin,\n",
    "            fmax=Config.fmax,\n",
    "            ref=ref,\n",
    "            amin=amin,\n",
    "            top_db=top_db,\n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(\n",
    "            time_drop_width=64,\n",
    "            time_stripes_num=2,\n",
    "            freq_drop_width=8,\n",
    "            freq_stripes_num=2)\n",
    "        \n",
    "        \n",
    "        self.feature_net = feature_extractor(EfficientNet.from_pretrained('efficientnet-b4'))\n",
    "#         self.out_features = 1280 # b0\n",
    "        self.out_features = 1792 # b4\n",
    "        self.bn0 = nn.BatchNorm2d(Config.n_mels)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.out_features, 1792, bias=True)\n",
    "        self.att_block = AttBlock(1792, Config.num_class, activation='sigmoid')\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "           \n",
    "            \n",
    "    def preprocess(self, input_x, mixup_lambda=None):\n",
    "\n",
    "        x = self.spectrogram_extractor(input_x)  # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)  # (batch_size, 1, time_steps, mel_bins)\n",
    "        x = x.expand(-1, 3, -1, -1)\n",
    "        frames_num = x.shape[2]\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        if self.training and self.apply_aug:\n",
    "            if np.random.rand() < Config.spec_augprob:\n",
    "                x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "#         if self.training  and self.apply_aug and mixup_lambda is not None:\n",
    "#             x = do_mixup(x, mixup_lambda)\n",
    "        return x, frames_num\n",
    "        \n",
    "\n",
    "    def forward(self, x, t_min_ratio=None, t_max_ratio=None, attn_mask=False):\n",
    "#         input_x, mixup_lambda = input_data\n",
    "#         \"\"\"\n",
    "#         Input: (batch_size, data_length)\"\"\"\n",
    "#         b, c, s = input_x.shape\n",
    "#         input_x = input_x.reshape(b*c, s)\n",
    "        x, frames_num = self.preprocess(x)\n",
    "#         if mixup_lambda is not None:\n",
    "#             b = (b*c)//2\n",
    "#             c = 1\n",
    "        # Output shape (batch size, channels, time, frequency)\n",
    "        x = self.feature_net(x)\n",
    "        \n",
    "        # Aggregate in frequency axis\n",
    "        x = torch.mean(x, dim=3)\n",
    "\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        if attn_mask:\n",
    "            (clipwise_output, norm_att, segmentwise_output) = self.att_block(x, t_min_ratio, t_max_ratio, attn_mask=True)\n",
    "        else:\n",
    "            (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "        framewise_output = segmentwise_output\n",
    "        # Get framewise output\n",
    "#         framewise_output = interpolate(segmentwise_output,\n",
    "#                                        self.interpolate_ratio)\n",
    "#         framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "#         frame_shape =  framewise_output.shape\n",
    "#         clip_shape = clipwise_output.shape\n",
    "        output_dict = {\n",
    "            'framewise_output': framewise_output,\n",
    "            'clipwise_output': clipwise_output,\n",
    "        }\n",
    "\n",
    "        return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:38.744915Z",
     "start_time": "2021-02-11T05:07:38.719234Z"
    }
   },
   "outputs": [],
   "source": [
    "# label-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LWLRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    # Number of GT labels per instance\n",
    "    num_labels = labels.sum(-1)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = scores.sum() / labels.sum()\n",
    "    return score.item()\n",
    "\n",
    "# # Sample usage\n",
    "# y_true = torch.tensor(np.array([[1, 1, 0], [1, 0, 1], [0, 0, 1]]))\n",
    "# y_score = torch.tensor(np.random.randn(3, 3))\n",
    "# print(LRAP(y_score, y_true), LWLRAP(y_score, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:38.772159Z",
     "start_time": "2021-02-11T05:07:38.746313Z"
    }
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, t_min_ratio, t_max_ratio, alpha=5):\n",
    "    \"\"\"\n",
    "    Applies mixup to a sample\n",
    "    Arguments:\n",
    "        x {torch tensor} -- Input batch\n",
    "        y {torch tensor} -- Labels\n",
    "    Keyword Arguments:\n",
    "        alpha {float} -- Parameter of the beta distribution (default: {0.4})\n",
    "    Returns:\n",
    "        torch tensor  -- Mixed input\n",
    "        torch tensor  -- Labels of the original batch\n",
    "        torch tensor  -- Labels of the shuffle batch\n",
    "        float  -- Probability samples by the beta distribution\n",
    "    \"\"\"\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "    index = torch.randperm(x.size()[0]).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    t_min = torch.stack([t_min_ratio, t_min_ratio[index]], dim=1)\n",
    "    t_max = torch.stack([t_max_ratio, t_max_ratio[index]], dim=1)\n",
    "    return mixed_x, y_a, y_b, t_min, t_max, lam\n",
    "\n",
    "# for step, (x, y_batch) in enumerate(train_loader):\n",
    "    \n",
    "#     if np.random.rand() < mixup_proba:\n",
    "#         x, y_a, y_b, _ = mixup_data(x.cuda(), y_batch.cuda(), alpha=alpha)\n",
    "#         y_batch = torch.clamp(y_a + y_b, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:38.822457Z",
     "start_time": "2021-02-11T05:07:38.773179Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader, criterion, history, n_iters, writer, fold):\n",
    "    model.eval()\n",
    "    costs = []\n",
    "    rocs = []\n",
    "    metrics = []\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    y_probs = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            X, y, t_min_ratio, t_max_ratio = batch\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            y_output = model(X, t_min_ratio=t_min_ratio, t_max_ratio=t_max_ratio, attn_mask=True)    \n",
    "            loss = criterion(y_output, y)\n",
    "            costs.append(loss.item())\n",
    "            y_true, y_prob= y.cpu(), y_output['clipwise_output'].detach().cpu()\n",
    "            y_pred = (y_prob+0.5).int()\n",
    "            y_trues.append(y_true.numpy())\n",
    "            y_probs.append(y_prob.numpy())\n",
    "            y_preds.append(y_pred.numpy())\n",
    "            metrics.append(LWLRAP(y_prob, y.cpu()))\n",
    "    \n",
    "    mean_rocs = sklearn.metrics.roc_auc_score(np.concatenate(y_trues), np.concatenate(y_probs))\n",
    "    mean_costs = np.mean(costs)\n",
    "    mean_metrics = np.mean(metrics)\n",
    "    writer.add_scalar('fold_{}/validate_roc'.format(fold), mean_rocs, n_iters)\n",
    "    writer.add_scalar('fold_{}/validate_loss'.format(fold), mean_costs, n_iters)\n",
    "    writer.add_scalar('fold_{}/validate_LWLRAP'.format(fold), mean_metrics, n_iters)\n",
    "    history['best_roc'][fold] = mean_rocs\n",
    "    history['best_metrics'][fold] = mean_metrics\n",
    "#     if mean_rocs > history['best_roc'][fold]:  \n",
    "#         history['best_roc'][fold] = mean_rocs\n",
    "#         history['best_metrics'][fold] = mean_metrics\n",
    "#         torch.save(model.state_dict(), history['best_model_path'][fold])\n",
    "    return mean_costs, mean_rocs, mean_metrics\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, writer, fold, step=True):\n",
    "    model.train()\n",
    "    costs = []\n",
    "    metrics = []\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    y_probs = []\n",
    "    val_loss, val_roc = 0, 0\n",
    "    optimizer.zero_grad()\n",
    "    with tqdm(total=len(train_dataloader.dataset), desc='Epoch{}'.format(epoch)) as pbar:\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            X, y, t_min_ratio, t_max_ratio = batch\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            if np.random.rand() < Config.mixup_proba:\n",
    "                X, y_a, y_b, t_min_ratio, t_max_ratio, _ = mixup_data(X, y, t_min_ratio, t_max_ratio, alpha=Config.mixup_alpha)\n",
    "                y = torch.clamp(y_a + y_b, 0, 1)\n",
    "            y_output = model(X, t_min_ratio=t_min_ratio, t_max_ratio=t_max_ratio, attn_mask=True)    \n",
    "            loss = criterion(y_output, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step:\n",
    "                scheduler.step()\n",
    "            costs.append(loss.item())\n",
    "            y_true, y_prob= y.cpu(), y_output['clipwise_output'].detach().cpu()\n",
    "            y_pred = (y_prob+0.5).int()\n",
    "            y_trues.append(y_true.numpy())\n",
    "            y_probs.append(y_prob.numpy())\n",
    "            y_preds.append(y_pred.numpy())\n",
    "            metrics.append(LWLRAP(y_prob, y_true))\n",
    "#             rocs.append(sklearn.metrics.roc_auc_score(y.cpu(), y_prob))\n",
    "#                 rocs.append((y_pred == y.cpu()).float().mean().item())\n",
    "            pbar.update(y.size(0))\n",
    "            n_iters = idx + len(train_dataloader) * (epoch-1)\n",
    "            if idx in validate_points:\n",
    "                val_loss, val_roc, val_metrics = validate(model, val_dataloader, criterion, history, n_iters, writer, fold)\n",
    "                model.train()\n",
    "            writer.add_scalar('fold_{}/train_loss'.format(fold), costs[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/train_LWLRAP'.format(fold), metrics[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/learning_rate'.format(fold), scheduler.get_last_lr()[0], n_iters)\n",
    "            pbar.set_postfix_str('loss:{:.3f}, val-loss:{:.3f}, val-roc:{:.4f}'.format(np.mean(costs[-10:]),  val_loss, val_roc))\n",
    "            torch.cuda.empty_cache()\n",
    "        writer.add_scalar('fold_{}/train_roc'.format(fold), sklearn.metrics.roc_auc_score(np.concatenate(y_trues), np.concatenate(y_probs)), n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:07:39.215909Z",
     "start_time": "2021-02-11T05:07:39.212252Z"
    }
   },
   "outputs": [],
   "source": [
    "class PANNsLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_ = input[\"clipwise_output\"]\n",
    "#         input_ = torch.where(torch.isnan(input_),\n",
    "#                              torch.zeros_like(input_),\n",
    "#                              input_)\n",
    "#         input_ = torch.where(torch.isinf(input_),\n",
    "#                              torch.zeros_like(input_),\n",
    "#                              input_)\n",
    "        input_ = torch.clamp(input_, 0, 1)\n",
    "        target = target.float()\n",
    "        return self.bce(input_, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T07:35:25.130883Z",
     "start_time": "2021-02-11T05:07:50.027250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 972/972 [00:44<00:00, 21.93it/s, loss:0.276, val-loss:0.346, val-roc:0.5052]\n",
      "Epoch2: 100%|██████████| 972/972 [00:44<00:00, 21.77it/s, loss:0.198, val-loss:0.208, val-roc:0.5223]\n",
      "Epoch3: 100%|██████████| 972/972 [00:46<00:00, 20.79it/s, loss:0.177, val-loss:0.195, val-roc:0.5957]\n",
      "Epoch4: 100%|██████████| 972/972 [00:46<00:00, 21.03it/s, loss:0.156, val-loss:0.174, val-roc:0.7288]\n",
      "Epoch5: 100%|██████████| 972/972 [00:44<00:00, 21.80it/s, loss:0.133, val-loss:0.141, val-roc:0.8435]\n",
      "Epoch6: 100%|██████████| 972/972 [00:44<00:00, 21.83it/s, loss:0.108, val-loss:0.132, val-roc:0.8880]\n",
      "Epoch7: 100%|██████████| 972/972 [00:43<00:00, 22.11it/s, loss:0.089, val-loss:0.122, val-roc:0.9230]\n",
      "Epoch8: 100%|██████████| 972/972 [00:43<00:00, 22.12it/s, loss:0.070, val-loss:0.093, val-roc:0.9529]\n",
      "Epoch9: 100%|██████████| 972/972 [00:45<00:00, 21.31it/s, loss:0.064, val-loss:0.105, val-roc:0.9410]\n",
      "Epoch10: 100%|██████████| 972/972 [00:45<00:00, 21.47it/s, loss:0.053, val-loss:0.097, val-roc:0.9572]\n",
      "Epoch11: 100%|██████████| 972/972 [00:45<00:00, 21.22it/s, loss:0.050, val-loss:0.119, val-roc:0.9452]\n",
      "Epoch12: 100%|██████████| 972/972 [00:45<00:00, 21.54it/s, loss:0.042, val-loss:0.134, val-roc:0.9506]\n",
      "Epoch13: 100%|██████████| 972/972 [00:44<00:00, 21.79it/s, loss:0.041, val-loss:0.066, val-roc:0.9698]\n",
      "Epoch14: 100%|██████████| 972/972 [00:45<00:00, 21.42it/s, loss:0.039, val-loss:0.086, val-roc:0.9744]\n",
      "Epoch15: 100%|██████████| 972/972 [00:45<00:00, 21.52it/s, loss:0.039, val-loss:0.095, val-roc:0.9615]\n",
      "Epoch16: 100%|██████████| 972/972 [00:44<00:00, 22.07it/s, loss:0.036, val-loss:0.093, val-roc:0.9613]\n",
      "Epoch17: 100%|██████████| 972/972 [00:35<00:00, 27.56it/s, loss:0.033, val-loss:0.100, val-roc:0.9596]\n",
      "Epoch18: 100%|██████████| 972/972 [00:35<00:00, 27.17it/s, loss:0.023, val-loss:0.062, val-roc:0.9789]\n",
      "Epoch19: 100%|██████████| 972/972 [00:35<00:00, 27.58it/s, loss:0.035, val-loss:0.158, val-roc:0.9477]\n",
      "Epoch20: 100%|██████████| 972/972 [00:35<00:00, 27.37it/s, loss:0.026, val-loss:0.081, val-roc:0.9685]\n",
      "Epoch21: 100%|██████████| 972/972 [00:35<00:00, 27.26it/s, loss:0.021, val-loss:0.127, val-roc:0.9652]\n",
      "Epoch22: 100%|██████████| 972/972 [00:35<00:00, 27.53it/s, loss:0.023, val-loss:0.097, val-roc:0.9700]\n",
      "Epoch23: 100%|██████████| 972/972 [00:35<00:00, 27.48it/s, loss:0.015, val-loss:0.107, val-roc:0.9729]\n",
      "Epoch24: 100%|██████████| 972/972 [00:35<00:00, 27.58it/s, loss:0.022, val-loss:0.082, val-roc:0.9768]\n",
      "Epoch25: 100%|██████████| 972/972 [00:35<00:00, 27.55it/s, loss:0.013, val-loss:0.077, val-roc:0.9816]\n",
      "Epoch26: 100%|██████████| 972/972 [00:35<00:00, 27.51it/s, loss:0.014, val-loss:0.082, val-roc:0.9864]\n",
      "Epoch27: 100%|██████████| 972/972 [00:35<00:00, 27.63it/s, loss:0.011, val-loss:0.072, val-roc:0.9851]\n",
      "Epoch28: 100%|██████████| 972/972 [00:35<00:00, 27.58it/s, loss:0.015, val-loss:0.117, val-roc:0.9737]\n",
      "Epoch29: 100%|██████████| 972/972 [00:35<00:00, 27.56it/s, loss:0.014, val-loss:0.072, val-roc:0.9798]\n",
      "Epoch30: 100%|██████████| 972/972 [00:35<00:00, 27.63it/s, loss:0.012, val-loss:0.093, val-roc:0.9782]\n",
      "Epoch31: 100%|██████████| 972/972 [00:35<00:00, 27.56it/s, loss:0.008, val-loss:0.079, val-roc:0.9818]\n",
      "Epoch32: 100%|██████████| 972/972 [00:35<00:00, 27.57it/s, loss:0.009, val-loss:0.061, val-roc:0.9850]\n",
      "Epoch33: 100%|██████████| 972/972 [00:35<00:00, 27.44it/s, loss:0.008, val-loss:0.075, val-roc:0.9852]\n",
      "Epoch34: 100%|██████████| 972/972 [00:35<00:00, 27.50it/s, loss:0.009, val-loss:0.087, val-roc:0.9849]\n",
      "Epoch35: 100%|██████████| 972/972 [00:35<00:00, 27.44it/s, loss:0.005, val-loss:0.099, val-roc:0.9818]\n",
      "Epoch36: 100%|██████████| 972/972 [00:35<00:00, 27.57it/s, loss:0.010, val-loss:0.073, val-roc:0.9818]\n",
      "Epoch37: 100%|██████████| 972/972 [00:35<00:00, 27.44it/s, loss:0.008, val-loss:0.102, val-roc:0.9814]\n",
      "Epoch38: 100%|██████████| 972/972 [00:35<00:00, 27.39it/s, loss:0.010, val-loss:0.103, val-roc:0.9820]\n",
      "Epoch39: 100%|██████████| 972/972 [00:35<00:00, 27.53it/s, loss:0.008, val-loss:0.103, val-roc:0.9814]\n",
      "Epoch40: 100%|██████████| 972/972 [00:35<00:00, 27.53it/s, loss:0.007, val-loss:0.128, val-roc:0.9813]\n",
      "Epoch1:   0%|          | 0/973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 973/973 [00:33<00:00, 29.21it/s, loss:0.279, val-loss:0.338, val-roc:0.5163]\n",
      "Epoch2: 100%|██████████| 973/973 [00:34<00:00, 28.20it/s, loss:0.197, val-loss:0.224, val-roc:0.5397]\n",
      "Epoch3: 100%|██████████| 973/973 [00:34<00:00, 28.13it/s, loss:0.174, val-loss:0.210, val-roc:0.6336]\n",
      "Epoch4: 100%|██████████| 973/973 [00:34<00:00, 27.82it/s, loss:0.154, val-loss:0.171, val-roc:0.7434]\n",
      "Epoch5: 100%|██████████| 973/973 [00:34<00:00, 27.97it/s, loss:0.133, val-loss:0.146, val-roc:0.8345]\n",
      "Epoch6: 100%|██████████| 973/973 [00:34<00:00, 28.20it/s, loss:0.106, val-loss:0.126, val-roc:0.8764]\n",
      "Epoch7: 100%|██████████| 973/973 [00:34<00:00, 27.86it/s, loss:0.086, val-loss:0.099, val-roc:0.9384]\n",
      "Epoch8: 100%|██████████| 973/973 [00:34<00:00, 28.07it/s, loss:0.061, val-loss:0.086, val-roc:0.9533]\n",
      "Epoch9: 100%|██████████| 973/973 [00:34<00:00, 28.09it/s, loss:0.064, val-loss:0.084, val-roc:0.9500]\n",
      "Epoch10: 100%|██████████| 973/973 [00:34<00:00, 28.10it/s, loss:0.064, val-loss:0.147, val-roc:0.9374]\n",
      "Epoch11: 100%|██████████| 973/973 [00:34<00:00, 27.98it/s, loss:0.049, val-loss:0.075, val-roc:0.9636]\n",
      "Epoch12: 100%|██████████| 973/973 [00:35<00:00, 27.79it/s, loss:0.036, val-loss:0.100, val-roc:0.9555]\n",
      "Epoch13: 100%|██████████| 973/973 [00:34<00:00, 27.89it/s, loss:0.043, val-loss:0.157, val-roc:0.9275]\n",
      "Epoch14: 100%|██████████| 973/973 [00:34<00:00, 28.21it/s, loss:0.045, val-loss:0.181, val-roc:0.9385]\n",
      "Epoch15: 100%|██████████| 973/973 [00:34<00:00, 28.08it/s, loss:0.034, val-loss:0.110, val-roc:0.9627]\n",
      "Epoch16: 100%|██████████| 973/973 [00:34<00:00, 28.18it/s, loss:0.043, val-loss:0.129, val-roc:0.9530]\n",
      "Epoch17: 100%|██████████| 973/973 [00:34<00:00, 27.99it/s, loss:0.038, val-loss:0.138, val-roc:0.9462]\n",
      "Epoch18: 100%|██████████| 973/973 [00:34<00:00, 28.05it/s, loss:0.040, val-loss:0.191, val-roc:0.9455]\n",
      "Epoch19: 100%|██████████| 973/973 [00:34<00:00, 27.95it/s, loss:0.026, val-loss:0.109, val-roc:0.9638]\n",
      "Epoch20: 100%|██████████| 973/973 [00:35<00:00, 27.35it/s, loss:0.035, val-loss:0.157, val-roc:0.9471]\n",
      "Epoch21: 100%|██████████| 973/973 [00:34<00:00, 28.01it/s, loss:0.018, val-loss:0.129, val-roc:0.9638]\n",
      "Epoch22: 100%|██████████| 973/973 [00:34<00:00, 27.84it/s, loss:0.021, val-loss:0.159, val-roc:0.9514]\n",
      "Epoch23: 100%|██████████| 973/973 [00:34<00:00, 28.11it/s, loss:0.014, val-loss:0.107, val-roc:0.9643]\n",
      "Epoch24: 100%|██████████| 973/973 [00:34<00:00, 27.96it/s, loss:0.013, val-loss:0.122, val-roc:0.9665]\n",
      "Epoch25: 100%|██████████| 973/973 [00:34<00:00, 28.08it/s, loss:0.015, val-loss:0.103, val-roc:0.9617]\n",
      "Epoch26: 100%|██████████| 973/973 [00:34<00:00, 27.83it/s, loss:0.018, val-loss:0.117, val-roc:0.9648]\n",
      "Epoch27: 100%|██████████| 973/973 [00:34<00:00, 27.90it/s, loss:0.012, val-loss:0.094, val-roc:0.9686]\n",
      "Epoch28: 100%|██████████| 973/973 [00:34<00:00, 27.91it/s, loss:0.009, val-loss:0.097, val-roc:0.9627]\n",
      "Epoch29: 100%|██████████| 973/973 [00:34<00:00, 27.98it/s, loss:0.012, val-loss:0.132, val-roc:0.9623]\n",
      "Epoch30: 100%|██████████| 973/973 [00:34<00:00, 28.10it/s, loss:0.008, val-loss:0.102, val-roc:0.9625]\n",
      "Epoch31: 100%|██████████| 973/973 [00:34<00:00, 28.15it/s, loss:0.009, val-loss:0.104, val-roc:0.9700]\n",
      "Epoch32: 100%|██████████| 973/973 [00:34<00:00, 28.21it/s, loss:0.008, val-loss:0.129, val-roc:0.9645]\n",
      "Epoch33: 100%|██████████| 973/973 [00:34<00:00, 28.19it/s, loss:0.011, val-loss:0.105, val-roc:0.9705]\n",
      "Epoch34: 100%|██████████| 973/973 [00:34<00:00, 27.98it/s, loss:0.008, val-loss:0.098, val-roc:0.9640]\n",
      "Epoch35: 100%|██████████| 973/973 [00:34<00:00, 28.06it/s, loss:0.010, val-loss:0.108, val-roc:0.9690]\n",
      "Epoch36: 100%|██████████| 973/973 [00:34<00:00, 28.21it/s, loss:0.007, val-loss:0.080, val-roc:0.9668]\n",
      "Epoch37: 100%|██████████| 973/973 [00:34<00:00, 28.04it/s, loss:0.006, val-loss:0.099, val-roc:0.9619]\n",
      "Epoch38: 100%|██████████| 973/973 [00:34<00:00, 28.06it/s, loss:0.007, val-loss:0.109, val-roc:0.9664]\n",
      "Epoch39: 100%|██████████| 973/973 [00:34<00:00, 27.82it/s, loss:0.007, val-loss:0.125, val-roc:0.9651]\n",
      "Epoch40: 100%|██████████| 973/973 [00:34<00:00, 27.89it/s, loss:0.005, val-loss:0.095, val-roc:0.9647]\n",
      "Epoch1:   0%|          | 0/973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 973/973 [00:33<00:00, 29.26it/s, loss:0.272, val-loss:0.352, val-roc:0.5118]\n",
      "Epoch2: 100%|██████████| 973/973 [00:33<00:00, 28.64it/s, loss:0.200, val-loss:0.232, val-roc:0.5151]\n",
      "Epoch3: 100%|██████████| 973/973 [00:34<00:00, 28.52it/s, loss:0.179, val-loss:0.225, val-roc:0.5976]\n",
      "Epoch4: 100%|██████████| 973/973 [00:34<00:00, 28.48it/s, loss:0.161, val-loss:0.184, val-roc:0.7268]\n",
      "Epoch5: 100%|██████████| 973/973 [00:33<00:00, 28.63it/s, loss:0.125, val-loss:0.144, val-roc:0.8310]\n",
      "Epoch6: 100%|██████████| 973/973 [00:33<00:00, 28.65it/s, loss:0.101, val-loss:0.123, val-roc:0.8979]\n",
      "Epoch7: 100%|██████████| 973/973 [00:34<00:00, 28.61it/s, loss:0.081, val-loss:0.108, val-roc:0.9303]\n",
      "Epoch8: 100%|██████████| 973/973 [00:34<00:00, 28.45it/s, loss:0.079, val-loss:0.106, val-roc:0.9398]\n",
      "Epoch9: 100%|██████████| 973/973 [00:33<00:00, 28.66it/s, loss:0.065, val-loss:0.087, val-roc:0.9485]\n",
      "Epoch10: 100%|██████████| 973/973 [00:34<00:00, 28.44it/s, loss:0.051, val-loss:0.096, val-roc:0.9490]\n",
      "Epoch11: 100%|██████████| 973/973 [00:33<00:00, 28.71it/s, loss:0.049, val-loss:0.139, val-roc:0.9514]\n",
      "Epoch12: 100%|██████████| 973/973 [00:34<00:00, 28.32it/s, loss:0.057, val-loss:0.123, val-roc:0.9611]\n",
      "Epoch13: 100%|██████████| 973/973 [00:34<00:00, 28.51it/s, loss:0.044, val-loss:0.214, val-roc:0.9317]\n",
      "Epoch14: 100%|██████████| 973/973 [00:34<00:00, 28.59it/s, loss:0.049, val-loss:0.096, val-roc:0.9638]\n",
      "Epoch15: 100%|██████████| 973/973 [00:34<00:00, 28.40it/s, loss:0.032, val-loss:0.111, val-roc:0.9587]\n",
      "Epoch16: 100%|██████████| 973/973 [00:34<00:00, 28.52it/s, loss:0.032, val-loss:0.127, val-roc:0.9641]\n",
      "Epoch17: 100%|██████████| 973/973 [00:34<00:00, 28.47it/s, loss:0.031, val-loss:0.071, val-roc:0.9752]\n",
      "Epoch18: 100%|██████████| 973/973 [00:34<00:00, 28.56it/s, loss:0.031, val-loss:0.060, val-roc:0.9796]\n",
      "Epoch19: 100%|██████████| 973/973 [00:33<00:00, 28.67it/s, loss:0.026, val-loss:0.093, val-roc:0.9812]\n",
      "Epoch20: 100%|██████████| 973/973 [00:33<00:00, 28.66it/s, loss:0.025, val-loss:0.077, val-roc:0.9805]\n",
      "Epoch21: 100%|██████████| 973/973 [00:34<00:00, 28.36it/s, loss:0.018, val-loss:0.055, val-roc:0.9824]\n",
      "Epoch22: 100%|██████████| 973/973 [00:34<00:00, 28.41it/s, loss:0.020, val-loss:0.048, val-roc:0.9863]\n",
      "Epoch23: 100%|██████████| 973/973 [00:33<00:00, 28.67it/s, loss:0.014, val-loss:0.058, val-roc:0.9836]\n",
      "Epoch24: 100%|██████████| 973/973 [00:33<00:00, 28.83it/s, loss:0.022, val-loss:0.052, val-roc:0.9821]\n",
      "Epoch25: 100%|██████████| 973/973 [00:34<00:00, 28.33it/s, loss:0.017, val-loss:0.071, val-roc:0.9798]\n",
      "Epoch26: 100%|██████████| 973/973 [00:34<00:00, 28.60it/s, loss:0.018, val-loss:0.048, val-roc:0.9866]\n",
      "Epoch27: 100%|██████████| 973/973 [00:34<00:00, 28.57it/s, loss:0.010, val-loss:0.061, val-roc:0.9863]\n",
      "Epoch28: 100%|██████████| 973/973 [00:33<00:00, 28.63it/s, loss:0.008, val-loss:0.078, val-roc:0.9802]\n",
      "Epoch29: 100%|██████████| 973/973 [00:34<00:00, 28.54it/s, loss:0.016, val-loss:0.084, val-roc:0.9833]\n",
      "Epoch30: 100%|██████████| 973/973 [00:34<00:00, 28.54it/s, loss:0.013, val-loss:0.055, val-roc:0.9864]\n",
      "Epoch31: 100%|██████████| 973/973 [00:34<00:00, 28.41it/s, loss:0.011, val-loss:0.049, val-roc:0.9892]\n",
      "Epoch32: 100%|██████████| 973/973 [00:34<00:00, 28.41it/s, loss:0.011, val-loss:0.055, val-roc:0.9893]\n",
      "Epoch33: 100%|██████████| 973/973 [00:34<00:00, 28.54it/s, loss:0.008, val-loss:0.050, val-roc:0.9884]\n",
      "Epoch34: 100%|██████████| 973/973 [00:34<00:00, 28.48it/s, loss:0.009, val-loss:0.052, val-roc:0.9874]\n",
      "Epoch35: 100%|██████████| 973/973 [00:34<00:00, 28.37it/s, loss:0.009, val-loss:0.047, val-roc:0.9886]\n",
      "Epoch36: 100%|██████████| 973/973 [00:34<00:00, 28.56it/s, loss:0.008, val-loss:0.056, val-roc:0.9872]\n",
      "Epoch37: 100%|██████████| 973/973 [00:34<00:00, 28.61it/s, loss:0.006, val-loss:0.047, val-roc:0.9912]\n",
      "Epoch38: 100%|██████████| 973/973 [00:34<00:00, 28.42it/s, loss:0.009, val-loss:0.047, val-roc:0.9914]\n",
      "Epoch39: 100%|██████████| 973/973 [00:47<00:00, 20.47it/s, loss:0.011, val-loss:0.044, val-roc:0.9923]\n",
      "Epoch40: 100%|██████████| 973/973 [00:55<00:00, 17.42it/s, loss:0.009, val-loss:0.054, val-roc:0.9858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 973/973 [00:53<00:00, 18.09it/s, loss:0.265, val-loss:0.320, val-roc:0.5380]\n",
      "Epoch2: 100%|██████████| 973/973 [00:55<00:00, 17.41it/s, loss:0.197, val-loss:0.211, val-roc:0.5476]\n",
      "Epoch3: 100%|██████████| 973/973 [00:54<00:00, 17.77it/s, loss:0.172, val-loss:0.196, val-roc:0.6302]\n",
      "Epoch4: 100%|██████████| 973/973 [00:58<00:00, 16.61it/s, loss:0.153, val-loss:0.168, val-roc:0.7512]\n",
      "Epoch5: 100%|██████████| 973/973 [00:56<00:00, 17.36it/s, loss:0.129, val-loss:0.150, val-roc:0.8561]\n",
      "Epoch6: 100%|██████████| 973/973 [00:52<00:00, 18.40it/s, loss:0.108, val-loss:0.128, val-roc:0.8838]\n",
      "Epoch7: 100%|██████████| 973/973 [00:57<00:00, 17.04it/s, loss:0.088, val-loss:0.112, val-roc:0.9236]\n",
      "Epoch8: 100%|██████████| 973/973 [00:57<00:00, 16.91it/s, loss:0.082, val-loss:0.112, val-roc:0.9419]\n",
      "Epoch9: 100%|██████████| 973/973 [00:54<00:00, 17.86it/s, loss:0.071, val-loss:0.080, val-roc:0.9637]\n",
      "Epoch10: 100%|██████████| 973/973 [00:52<00:00, 18.55it/s, loss:0.051, val-loss:0.098, val-roc:0.9551]\n",
      "Epoch11: 100%|██████████| 973/973 [00:55<00:00, 17.53it/s, loss:0.056, val-loss:0.103, val-roc:0.9491]\n",
      "Epoch12: 100%|██████████| 973/973 [00:53<00:00, 18.18it/s, loss:0.044, val-loss:0.146, val-roc:0.9475]\n",
      "Epoch13: 100%|██████████| 973/973 [00:55<00:00, 17.42it/s, loss:0.041, val-loss:0.121, val-roc:0.9520]\n",
      "Epoch14: 100%|██████████| 973/973 [00:53<00:00, 18.26it/s, loss:0.036, val-loss:0.114, val-roc:0.9599]\n",
      "Epoch15: 100%|██████████| 973/973 [00:55<00:00, 17.41it/s, loss:0.037, val-loss:0.070, val-roc:0.9738]\n",
      "Epoch16: 100%|██████████| 973/973 [00:57<00:00, 16.83it/s, loss:0.043, val-loss:0.185, val-roc:0.8912]\n",
      "Epoch17: 100%|██████████| 973/973 [00:55<00:00, 17.54it/s, loss:0.044, val-loss:0.184, val-roc:0.9351]\n",
      "Epoch18: 100%|██████████| 973/973 [00:54<00:00, 17.79it/s, loss:0.041, val-loss:0.118, val-roc:0.9621]\n",
      "Epoch19: 100%|██████████| 973/973 [00:58<00:00, 16.57it/s, loss:0.035, val-loss:0.112, val-roc:0.9616]\n",
      "Epoch20: 100%|██████████| 973/973 [00:53<00:00, 18.23it/s, loss:0.023, val-loss:0.107, val-roc:0.9651]\n",
      "Epoch21: 100%|██████████| 973/973 [00:55<00:00, 17.55it/s, loss:0.026, val-loss:0.103, val-roc:0.9703]\n",
      "Epoch22: 100%|██████████| 973/973 [00:57<00:00, 17.02it/s, loss:0.018, val-loss:0.086, val-roc:0.9723]\n",
      "Epoch23: 100%|██████████| 973/973 [00:56<00:00, 17.16it/s, loss:0.021, val-loss:0.106, val-roc:0.9729]\n",
      "Epoch24: 100%|██████████| 973/973 [00:55<00:00, 17.67it/s, loss:0.015, val-loss:0.111, val-roc:0.9679]\n",
      "Epoch25: 100%|██████████| 973/973 [00:56<00:00, 17.26it/s, loss:0.010, val-loss:0.099, val-roc:0.9728]\n",
      "Epoch26: 100%|██████████| 973/973 [00:54<00:00, 17.92it/s, loss:0.016, val-loss:0.095, val-roc:0.9749]\n",
      "Epoch27: 100%|██████████| 973/973 [00:52<00:00, 18.44it/s, loss:0.016, val-loss:0.100, val-roc:0.9747]\n",
      "Epoch28: 100%|██████████| 973/973 [00:53<00:00, 18.02it/s, loss:0.012, val-loss:0.095, val-roc:0.9763]\n",
      "Epoch29: 100%|██████████| 973/973 [00:57<00:00, 16.93it/s, loss:0.009, val-loss:0.104, val-roc:0.9748]\n",
      "Epoch30: 100%|██████████| 973/973 [00:55<00:00, 17.64it/s, loss:0.010, val-loss:0.096, val-roc:0.9731]\n",
      "Epoch31: 100%|██████████| 973/973 [00:54<00:00, 17.88it/s, loss:0.010, val-loss:0.066, val-roc:0.9780]\n",
      "Epoch32: 100%|██████████| 973/973 [00:53<00:00, 18.13it/s, loss:0.009, val-loss:0.090, val-roc:0.9763]\n",
      "Epoch33: 100%|██████████| 973/973 [00:56<00:00, 17.09it/s, loss:0.007, val-loss:0.094, val-roc:0.9757]\n",
      "Epoch34: 100%|██████████| 973/973 [00:54<00:00, 17.88it/s, loss:0.009, val-loss:0.094, val-roc:0.9753]\n",
      "Epoch35: 100%|██████████| 973/973 [00:53<00:00, 18.21it/s, loss:0.008, val-loss:0.095, val-roc:0.9756]\n",
      "Epoch36: 100%|██████████| 973/973 [00:57<00:00, 16.85it/s, loss:0.008, val-loss:0.096, val-roc:0.9757]\n",
      "Epoch37: 100%|██████████| 973/973 [00:55<00:00, 17.46it/s, loss:0.007, val-loss:0.095, val-roc:0.9770]\n",
      "Epoch38: 100%|██████████| 973/973 [00:55<00:00, 17.52it/s, loss:0.006, val-loss:0.091, val-roc:0.9798]\n",
      "Epoch39: 100%|██████████| 973/973 [00:54<00:00, 17.86it/s, loss:0.008, val-loss:0.096, val-roc:0.9761]\n",
      "Epoch40: 100%|██████████| 973/973 [00:56<00:00, 17.11it/s, loss:0.005, val-loss:0.092, val-roc:0.9775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 973/973 [00:49<00:00, 19.48it/s, loss:0.302, val-loss:0.356, val-roc:0.4995]\n",
      "Epoch2: 100%|██████████| 973/973 [00:54<00:00, 17.71it/s, loss:0.204, val-loss:0.221, val-roc:0.5173]\n",
      "Epoch3: 100%|██████████| 973/973 [00:55<00:00, 17.42it/s, loss:0.182, val-loss:0.207, val-roc:0.5690]\n",
      "Epoch4: 100%|██████████| 973/973 [00:55<00:00, 17.50it/s, loss:0.160, val-loss:0.181, val-roc:0.7059]\n",
      "Epoch5: 100%|██████████| 973/973 [00:52<00:00, 18.36it/s, loss:0.136, val-loss:0.151, val-roc:0.8187]\n",
      "Epoch6: 100%|██████████| 973/973 [00:55<00:00, 17.63it/s, loss:0.112, val-loss:0.125, val-roc:0.9095]\n",
      "Epoch7: 100%|██████████| 973/973 [00:55<00:00, 17.62it/s, loss:0.087, val-loss:0.093, val-roc:0.9379]\n",
      "Epoch8: 100%|██████████| 973/973 [00:53<00:00, 18.20it/s, loss:0.073, val-loss:0.093, val-roc:0.9424]\n",
      "Epoch9: 100%|██████████| 973/973 [00:53<00:00, 18.20it/s, loss:0.062, val-loss:0.113, val-roc:0.9388]\n",
      "Epoch10: 100%|██████████| 973/973 [00:54<00:00, 17.82it/s, loss:0.065, val-loss:0.111, val-roc:0.9305]\n",
      "Epoch11: 100%|██████████| 973/973 [00:56<00:00, 17.33it/s, loss:0.049, val-loss:0.109, val-roc:0.9485]\n",
      "Epoch12: 100%|██████████| 973/973 [00:53<00:00, 18.20it/s, loss:0.040, val-loss:0.117, val-roc:0.9489]\n",
      "Epoch13: 100%|██████████| 973/973 [00:54<00:00, 17.95it/s, loss:0.045, val-loss:0.081, val-roc:0.9604]\n",
      "Epoch14: 100%|██████████| 973/973 [00:57<00:00, 16.90it/s, loss:0.045, val-loss:0.118, val-roc:0.9519]\n",
      "Epoch15: 100%|██████████| 973/973 [00:56<00:00, 17.33it/s, loss:0.048, val-loss:0.121, val-roc:0.9413]\n",
      "Epoch16: 100%|██████████| 973/973 [00:55<00:00, 17.39it/s, loss:0.036, val-loss:0.125, val-roc:0.9543]\n",
      "Epoch17: 100%|██████████| 973/973 [00:55<00:00, 17.51it/s, loss:0.034, val-loss:0.083, val-roc:0.9543]\n",
      "Epoch18: 100%|██████████| 973/973 [00:57<00:00, 17.01it/s, loss:0.028, val-loss:0.138, val-roc:0.9569]\n",
      "Epoch19: 100%|██████████| 973/973 [00:52<00:00, 18.46it/s, loss:0.021, val-loss:0.147, val-roc:0.9544]\n",
      "Epoch20: 100%|██████████| 973/973 [00:54<00:00, 17.92it/s, loss:0.029, val-loss:0.137, val-roc:0.9500]\n",
      "Epoch21: 100%|██████████| 973/973 [00:55<00:00, 17.54it/s, loss:0.024, val-loss:0.130, val-roc:0.9439]\n",
      "Epoch22: 100%|██████████| 973/973 [00:55<00:00, 17.46it/s, loss:0.022, val-loss:0.091, val-roc:0.9650]\n",
      "Epoch23: 100%|██████████| 973/973 [00:56<00:00, 17.28it/s, loss:0.016, val-loss:0.100, val-roc:0.9701]\n",
      "Epoch24: 100%|██████████| 973/973 [00:52<00:00, 18.49it/s, loss:0.017, val-loss:0.075, val-roc:0.9718]\n",
      "Epoch25: 100%|██████████| 973/973 [00:55<00:00, 17.64it/s, loss:0.017, val-loss:0.098, val-roc:0.9737]\n",
      "Epoch26: 100%|██████████| 973/973 [00:54<00:00, 17.84it/s, loss:0.010, val-loss:0.082, val-roc:0.9754]\n",
      "Epoch27: 100%|██████████| 973/973 [00:53<00:00, 18.08it/s, loss:0.010, val-loss:0.099, val-roc:0.9752]\n",
      "Epoch28: 100%|██████████| 973/973 [00:53<00:00, 18.08it/s, loss:0.012, val-loss:0.096, val-roc:0.9781]\n",
      "Epoch29: 100%|██████████| 973/973 [00:55<00:00, 17.39it/s, loss:0.009, val-loss:0.113, val-roc:0.9718]\n",
      "Epoch30: 100%|██████████| 973/973 [00:54<00:00, 17.82it/s, loss:0.012, val-loss:0.091, val-roc:0.9762]\n",
      "Epoch31: 100%|██████████| 973/973 [00:53<00:00, 18.27it/s, loss:0.009, val-loss:0.075, val-roc:0.9810]\n",
      "Epoch32: 100%|██████████| 973/973 [00:55<00:00, 17.57it/s, loss:0.008, val-loss:0.081, val-roc:0.9765]\n",
      "Epoch33: 100%|██████████| 973/973 [00:53<00:00, 18.09it/s, loss:0.012, val-loss:0.122, val-roc:0.9742]\n",
      "Epoch34: 100%|██████████| 973/973 [00:54<00:00, 17.83it/s, loss:0.005, val-loss:0.093, val-roc:0.9742]\n",
      "Epoch35: 100%|██████████| 973/973 [00:53<00:00, 18.33it/s, loss:0.007, val-loss:0.074, val-roc:0.9799]\n",
      "Epoch36: 100%|██████████| 973/973 [00:57<00:00, 16.98it/s, loss:0.008, val-loss:0.093, val-roc:0.9768]\n",
      "Epoch37: 100%|██████████| 973/973 [00:56<00:00, 17.31it/s, loss:0.006, val-loss:0.090, val-roc:0.9764]\n",
      "Epoch38: 100%|██████████| 973/973 [00:52<00:00, 18.54it/s, loss:0.011, val-loss:0.092, val-roc:0.9760]\n",
      "Epoch39: 100%|██████████| 973/973 [00:54<00:00, 17.88it/s, loss:0.005, val-loss:0.092, val-roc:0.9755]\n",
      "Epoch40: 100%|██████████| 973/973 [00:56<00:00, 17.28it/s, loss:0.005, val-loss:0.074, val-roc:0.9780]\n"
     ]
    }
   ],
   "source": [
    "pos_weights = torch.ones(Config.num_class)\n",
    "counts = data_tp_df['species_id'].value_counts()\n",
    "for i in range(Config.num_class):\n",
    "    pos_weights[i] = (sum(counts)-counts[i])/counts[i]\n",
    "criterion = PANNsLoss().cuda()\n",
    "# loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weights).cuda()\n",
    "\n",
    "# def criterion(y_pred, y_target):\n",
    "#     loss = loss_function(y_pred, y_target.float())\n",
    "#     return loss\n",
    "\n",
    "model_name = 'SED_new_noaugment_RandomCrop_nomixup_attention_effb4'\n",
    "time_stamp = '{0:%m_%d_%H_%M}'.format(datetime.datetime.now())\n",
    "# time_stamp = '02_09_16_16'\n",
    "\n",
    "history = {\n",
    "    'config': Config,\n",
    "    'best_roc': [0]*len(data_folds),\n",
    "    'best_metrics': [0]*len(data_folds), \n",
    "    'best_model_path': [os.path.join(model_path, '{}_{}_fold_{}.pth'.format(model_name, time_stamp, i)) for i in range(len(data_folds))]\n",
    "}\n",
    "writer = SummaryWriter(log_dir=os.path.join(tensorboard_path, '{}_{}'.format(model_name, time_stamp)))\n",
    "for idx, (train_dataloader, val_dataloader) in enumerate(data_folds):\n",
    "    validate_points = list(np.linspace(0, len(train_dataloader)-1, 2).astype(int))[1:]\n",
    "    model = PANNsAtt().cuda()\n",
    "#     model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    epochs = 40\n",
    "    warmup_prob = 0.3\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, epochs=epochs, steps_per_epoch=len(train_dataloader), pct_start=warmup_prob, div_factor=25, anneal_strategy='cos', cycle_momentum=True)\n",
    "#     scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(warmup_prob*len(train_dataloader)*epochs), num_training_steps=len(train_dataloader)*epochs)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler,  writer, fold=idx, step=True)\n",
    "#         scheduler.step()\n",
    "        gc.collect()\n",
    "    torch.save(model.state_dict(), history['best_model_path'][idx])\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "with open(os.path.join(model_path, '{}_{}_history.pkl'.format(model_name, time_stamp)), 'wb') as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T09:48:23.143898Z",
     "start_time": "2021-02-03T09:48:23.132904Z"
    }
   },
   "source": [
    "## Predict Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:04:17.459349Z",
     "start_time": "2021-02-11T01:04:17.450757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SED_augment_RandomCrop_wavmixup_attention_effb4_02_10_14_20_history.pkl\n",
      "SED_old_augment_RandomCrop_specmixup_attention_effb4_02_10_14_26_history.pkl\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(model_path):\n",
    "    if file.endswith('.pkl'):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T07:37:33.590821Z",
     "start_time": "2021-02-11T07:37:27.884249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(model_path, 'SED_augment_RandomCrop_wavmixup_attention_effb4_02_10_14_20_history.pkl'), 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "model = PANNsAtt().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T07:58:52.617650Z",
     "start_time": "2021-02-11T07:37:33.994989Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [04:09<00:00,  2.00s/it]\n",
      "100%|██████████| 125/125 [04:20<00:00,  2.08s/it]\n",
      "100%|██████████| 125/125 [04:13<00:00,  2.03s/it]\n",
      "100%|██████████| 125/125 [04:11<00:00,  2.01s/it]\n",
      "100%|██████████| 125/125 [04:20<00:00,  2.09s/it]\n"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "for path in history['best_model_path']:\n",
    "    model.load_state_dict(torch.load(path, map_location= torch.device('cpu')), strict=True)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            a, b, c = batch.size()\n",
    "            X = batch.view(a*b, c).cuda()\n",
    "            output = model(X, attn_mask=False)\n",
    "            pred = output['framewise_output'].view(a, b, -1, 24).max(dim=2)[0].max(dim=1)[0].cpu().detach().numpy()\n",
    "            preds.append(pred)\n",
    "    folds.append(np.concatenate(preds, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T07:58:52.695027Z",
     "start_time": "2021-02-11T07:58:52.618972Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(columns=['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'], dtype=np.float32)\n",
    "sub['recording_id'] = [file.split('.')[0] for file in test_files]\n",
    "sub.iloc[:, 1:] = sum(folds) / len(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T07:58:52.862327Z",
     "start_time": "2021-02-11T07:58:52.699464Z"
    }
   },
   "outputs": [],
   "source": [
    "time_stamp = '{0:%m_%d_%H_%M}'.format(datetime.datetime.now())\n",
    "sub.to_csv(os.path.join(res_path, 'submission_SED_new_noaugment_RandomCrop_nomixup_attention_effb4_{}.csv'.format(time_stamp)), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T07:36:52.597760Z",
     "start_time": "2021-02-11T07:36:52.593783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9774732011686715"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history['best_roc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T07:36:54.008509Z",
     "start_time": "2021-02-11T07:36:54.001441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894425490044201"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history['best_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
