{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:52:55.239083Z",
     "start_time": "2021-02-11T01:52:54.283012Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "import sklearn\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:52:55.744235Z",
     "start_time": "2021-02-11T01:52:55.240889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from IPython.core.debugger import set_trace\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:52:55.751913Z",
     "start_time": "2021-02-11T01:52:55.746097Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "GLOBAL_SEED = 42\n",
    "setup_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:52:55.775810Z",
     "start_time": "2021-02-11T01:52:55.755320Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/dev/shm/data'\n",
    "feat_path = '/root/s/RFCX/features'\n",
    "res_path = '/root/s/RFCX/res'\n",
    "model_path = '/root/s/RFCX/model_save'\n",
    "tensorboard_path = '/root/s/RFCX/tensorboard'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if not os.path.exists(res_path):\n",
    "    os.makedirs(res_path)\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:52:55.830861Z",
     "start_time": "2021-02-11T01:52:55.778945Z"
    }
   },
   "outputs": [],
   "source": [
    "data_tp_df=pd.read_csv(os.path.join(data_path, 'train_tp.csv'))\n",
    "data_fp_df=pd.read_csv(os.path.join(data_path, 'train_fp.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:52:55.835408Z",
     "start_time": "2021-02-11T01:52:55.832732Z"
    }
   },
   "outputs": [],
   "source": [
    "# count_series = data_tp_df['recording_id'].value_counts()[data_tp_df['recording_id']]\n",
    "# count_series.index = data_tp_df.index\n",
    "# data_tp_df['counts'] = count_series\n",
    "# def process_overlap(df):\n",
    "#     if df.counts() == 1:\n",
    "#         return d\n",
    "#     return d\n",
    "# data_tp_df.groupby('recording_id').apply(f)\n",
    "# data_tp_df[data_tp_df['counts'] >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:52:58.729388Z",
     "start_time": "2021-02-11T01:52:58.720291Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_class = 24\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 256\n",
    "    sr = 32000\n",
    "    segment_length = 10 * sr\n",
    "    fmin = 80\n",
    "    fmax = 16000\n",
    "    \n",
    "    resize = False\n",
    "    img_shape = (240, 480)\n",
    "    \n",
    "    wav_augment = True\n",
    "    spec_augment = True\n",
    "    mixup_proba = 0.0\n",
    "    mixup_alpha = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:53:00.021755Z",
     "start_time": "2021-02-11T01:52:59.789251Z"
    }
   },
   "outputs": [],
   "source": [
    "\"https://www.kaggle.com/gopidurgaprasad/audio-augmentation-albumentations/\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, PolarityInversion, Gain, AddGaussianSNR\n",
    "\n",
    "\n",
    "class AudioTransform(BasicTransform):\n",
    "    \"\"\"Transform for Audio task\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "    \n",
    "      \n",
    "class MelSpectrogram(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, parameters, always_apply=False, p=0.5):\n",
    "        super(MelSpectrogram, self).__init__(always_apply, p)\n",
    "\n",
    "        self.parameters = parameters\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(sound, sr=sr, **self.parameters)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "        melspec = melspec.astype(np.float32)\n",
    "        return melspec, sr\n",
    "    \n",
    "    \n",
    "class SpecAugment(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, num_mask=2, freq_masking=0.15, time_masking=0.20, always_apply=False, p=0.5):\n",
    "        super(SpecAugment, self).__init__(always_apply, p)\n",
    "\n",
    "        self.num_mask = num_mask\n",
    "        self.freq_masking = freq_masking\n",
    "        self.time_masking = time_masking\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "\n",
    "        spec_aug = self.spec_augment(melspec, \n",
    "                                     self.num_mask,\n",
    "                                     self.freq_masking,\n",
    "                                     self.time_masking,\n",
    "                                     melspec.min())\n",
    "        \n",
    "\n",
    "        return spec_aug, sr\n",
    "    \n",
    "    # Source: https://www.kaggle.com/davids1992/specaugment-quick-implementation\n",
    "    def spec_augment(self, \n",
    "                    spec: np.ndarray,\n",
    "                    num_mask=2,\n",
    "                    freq_masking=0.15,\n",
    "                    time_masking=0.20,\n",
    "                    value=0):\n",
    "        spec = spec.copy()\n",
    "        num_mask = random.randint(1, num_mask)\n",
    "        for i in range(num_mask):\n",
    "            all_freqs_num, all_frames_num  = spec.shape\n",
    "            freq_percentage = random.uniform(0.0, freq_masking)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[f0:f0 + num_freqs_to_mask, :] = value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[:, t0:t0 + num_frames_to_mask] = value\n",
    "\n",
    "        return spec\n",
    "\n",
    "    \n",
    "class SpectToImage(AudioTransform):\n",
    "\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(SpectToImage, self).__init__(always_apply, p)\n",
    "        \n",
    "        \n",
    "    def mono_to_color(self, X: np.ndarray,\n",
    "                      mean=None,\n",
    "                      std=None,\n",
    "                      norm_max=None,\n",
    "                      norm_min=None,\n",
    "                      eps=1e-6):\n",
    "        \"\"\"\n",
    "        Code from https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Standardize\n",
    "        mean = mean or X.mean()\n",
    "        X = X - mean\n",
    "        std = std or X.std()\n",
    "        Xstd = X / (std + eps)\n",
    "        _min, _max = Xstd.min(), Xstd.max()\n",
    "        norm_max = norm_max or _max\n",
    "        norm_min = norm_min or _min\n",
    "        if (_max - _min) > eps:\n",
    "            # Normalize to [0, 255]\n",
    "            V = Xstd\n",
    "            V[V < norm_min] = norm_min\n",
    "            V[V > norm_max] = norm_max\n",
    "            V = (V - norm_min) / (norm_max - norm_min)\n",
    "        else:\n",
    "            # Just zero\n",
    "            V = np.zeros_like(Xstd, dtype=np.float32)\n",
    "        return V\n",
    "    \n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "        image = self.mono_to_color(melspec)\n",
    "        if Config.resize:\n",
    "            image = resize(image, Config.img_shape)\n",
    "        image = np.stack([image, image, image], axis=-1)\n",
    "#         delta = librosa.feature.delta(image)\n",
    "#         accelerate = librosa.feature.delta(image, order=2)\n",
    "#         image = np.stack([image, delta, accelerate], axis=-1)\n",
    "#         image = image.astype(np.float32) / 100.0\n",
    "        # (n_mels, time_step, 3) --> (3, time_step, n_mels)\n",
    "        return image.transpose(2, 1, 0)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "sound_augment = Compose([\n",
    "    PolarityInversion(p=0.2),\n",
    "    Gain(min_gain_in_db=-15, max_gain_in_db=15, p=0.3),\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.1),\n",
    "    AddGaussianSNR(max_SNR=0.5, p=0.2),\n",
    "#     TimeStretch(min_rate=0.8, max_rate=1.25, p=0.2)\n",
    "#     Shift(min_fraction=-0.2, max_fraction=0.2, p=0.2)\n",
    "])\n",
    "\n",
    "\n",
    "melspectrogram_parameters = {\n",
    "        \"n_mels\": Config.n_mels,\n",
    "        'n_fft': Config.n_fft, \n",
    "        'hop_length': Config.hop_length,\n",
    "        'fmin': Config.fmin, \n",
    "        'fmax': Config.fmax \n",
    "    }\n",
    "\n",
    "spec_augment = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpecAugment(p=0.2),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "to_image = albumentations.Compose([\n",
    "    MelSpectrogram(parameters=melspectrogram_parameters, always_apply=True),\n",
    "    SpectToImage(always_apply=True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:53:00.770222Z",
     "start_time": "2021-02-11T01:53:00.464266Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "ONE_HOT = np.eye(Config.num_class)\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_df, is_valid=False):\n",
    "        self.data_df = data_df\n",
    "        self.is_valid = is_valid\n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def load_audio_clip(self, audio_file_path, t_min, t_max):\n",
    "        # All sound files are 48000 bitrate, no need to slowly resample\n",
    "        wav, _ = librosa.load(audio_file_path, sr=Config.sr)\n",
    "\n",
    "        t_min = float(t_min) * Config.sr\n",
    "        t_max = float(t_max) * Config.sr\n",
    "\n",
    "        # Positioning sound slice\n",
    "        begin = max(t_max - Config.segment_length, 0)\n",
    "        end = t_min\n",
    "        random_begin = np.random.randint(begin, end)\n",
    "        random_end = random_begin + Config.segment_length\n",
    "        if random_end > len(wav):\n",
    "            random_end = len(wav)\n",
    "            random_begin = random_end - Config.segment_length\n",
    "\n",
    "        slice = wav[int(random_begin):int(random_end)]\n",
    "        t_min_ratio = (t_min - random_begin)/Config.segment_length\n",
    "        t_max_ratio = (t_max - random_begin)/Config.segment_length\n",
    "        return slice, t_min_ratio, t_max_ratio\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        s = self.data_df.iloc[idx]\n",
    "        audio_file_path = os.path.join(data_path, 'train', s['recording_id']+'.wav')\n",
    "        wav, t_min_ratio, t_max_ratio = self.load_audio_clip(audio_file_path, s['t_min'], s['t_max'])\n",
    "        if self.is_valid:\n",
    "            image = to_image(data=(wav, Config.sr))['data']\n",
    "        else:\n",
    "            if Config.wav_augment:\n",
    "                data = sound_augment(samples=wav, sample_rate=Config.sr), Config.sr\n",
    "            else:\n",
    "                data = wav, Config.sr\n",
    "            if Config.spec_augment:\n",
    "                image = spec_augment(data=data)['data']\n",
    "            else:\n",
    "                image = to_image(data=data)['data']\n",
    "        return torch.tensor(image, dtype=torch.float32), ONE_HOT[s['species_id']], t_min_ratio, t_max_ratio\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_files):\n",
    "        self.test_files = test_files \n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_file_path = os.path.join(data_path, 'test', self.test_files[idx])\n",
    "        wav, _ = librosa.load(audio_file_path, sr=Config.sr)\n",
    "        segments = len(wav) / Config.segment_length\n",
    "        segments = int(np.ceil(segments))\n",
    "        img = []\n",
    "        for i in range(0, segments):\n",
    "            # Last segment going from the end\n",
    "            if (i + 1) * Config.segment_length > len(wav):\n",
    "                slice = wav[len(wav) - Config.segment_length:len(wav)]\n",
    "            else:\n",
    "                slice = wav[i * Config.segment_length:(i + 1) * Config.segment_length]\n",
    "            img.append(to_image(data=(slice, Config.sr))['data'])\n",
    "        return torch.tensor(img, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:53:01.281543Z",
     "start_time": "2021-02-11T01:53:01.272155Z"
    }
   },
   "outputs": [],
   "source": [
    "test_files = sorted(os.listdir(os.path.join(data_path, 'test')))\n",
    "test_dataset = TestDataset(test_files)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, sampler=SequentialSampler(test_dataset), shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:53:03.265152Z",
     "start_time": "2021-02-11T01:53:03.238645Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=GLOBAL_SEED)\n",
    "data_folds = []\n",
    "valid_indexs = []\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(X=data_tp_df, y=data_tp_df['species_id'])):\n",
    "    valid_indexs.append(valid_index)\n",
    "    train_dataset = TrainDataset(data_tp_df.iloc[train_index], is_valid=False)\n",
    "    val_dataset = TrainDataset(data_tp_df.iloc[valid_index], is_valid=True)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    valid_dataloader = DataLoader(val_dataset, batch_size=batch_size, sampler=SequentialSampler(val_dataset), shuffle=False, num_workers=4)\n",
    "    data_folds.append((train_dataloader, valid_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:53:03.687249Z",
     "start_time": "2021-02-11T01:53:03.683088Z"
    }
   },
   "outputs": [],
   "source": [
    "# time_steps = X.shape[2]\n",
    "# start = (time_steps * t_min_ratio).int()\n",
    "# end = torch.clamp((time_steps * t_max_ratio).int() + 2, min=0, max=time_steps)\n",
    "# attn_mask = torch.zeros_like(X) == 0\n",
    "# for i in range(X.shape[0]):\n",
    "#     attn_mask[i, :, start[i]:end[i], :] = False\n",
    "# X.masked_fill_(attn_mask, -float('inf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:53:04.490274Z",
     "start_time": "2021-02-11T01:53:04.481407Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:53:05.858653Z",
     "start_time": "2021-02-11T01:53:05.806492Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    pad = framewise_output[:, -1:, :].repeat(\n",
    "        1, frames_num - framewise_output.shape[1], 1)\n",
    "    \"\"\"tensor for padding\"\"\"\n",
    "\n",
    "    output = torch.cat((framewise_output, pad), dim=1)\n",
    "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "            bias=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "            bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
    "\n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        if pool_type == 'max':\n",
    "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg+max':\n",
    "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            raise Exception('Incorrect argument!')\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\",\n",
    "                 temperature=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.temperature = temperature\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.bn_att = nn.BatchNorm1d(out_features)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "        init_bn(self.bn_att)\n",
    "\n",
    "    def forward(self, x, t_min_ratio=None, t_max_ratio=None, attn_mask=False):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        energy = torch.tanh(self.att(x))\n",
    "        if attn_mask:\n",
    "            time_steps = energy.shape[2]\n",
    "            start = (time_steps * t_min_ratio).int()\n",
    "            end = torch.clamp((time_steps * t_max_ratio).int() + 2, min=0, max=time_steps)\n",
    "            mask = torch.zeros_like(energy) == 0\n",
    "            if len(start.size()) == 1:\n",
    "                for i in range(energy.shape[0]):\n",
    "                    mask[i, :, start[i]:end[i]] = False\n",
    "            else:\n",
    "                for i in range(energy.shape[0]):\n",
    "                    mask[i, :, start[i][0]:end[i][0]] = False\n",
    "                    mask[i, :, start[i][1]:end[i][1]] = False\n",
    "            energy = energy.masked_fill(mask, -float('inf'))\n",
    "        norm_att = torch.softmax(energy, dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class feature_extractor(nn.Module):\n",
    "    def __init__(self, original):\n",
    "        super().__init__()\n",
    "        self.model = original\n",
    "    def forward(self, x):\n",
    "        x= self.model.extract_features(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class PANNsAtt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "        self.interpolate_ratio = 32  # Downsampled ratio\n",
    "        self.apply_aug = Config.spec_augment\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(\n",
    "            n_fft=Config.n_fft,\n",
    "            hop_length=Config.hop_length,\n",
    "            win_length=Config.n_fft,\n",
    "            window=window,\n",
    "            center=center,\n",
    "            pad_mode=pad_mode,\n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(\n",
    "            sr=Config.sr,\n",
    "            n_fft=Config.n_fft,\n",
    "            n_mels=Config.n_mels,\n",
    "            fmin=Config.fmin,\n",
    "            fmax=Config.fmax,\n",
    "            ref=ref,\n",
    "            amin=amin,\n",
    "            top_db=top_db,\n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(\n",
    "            time_drop_width=64,\n",
    "            time_stripes_num=2,\n",
    "            freq_drop_width=8,\n",
    "            freq_stripes_num=2)\n",
    "        \n",
    "        \n",
    "        self.feature_net = feature_extractor(EfficientNet.from_pretrained('efficientnet-b0'))\n",
    "        self.out_features = 1280 # b0`\n",
    "#         self.out_features = 1792 # b4\n",
    "        self.bn0 = nn.BatchNorm2d(Config.n_mels)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.out_features, 1280, bias=True)\n",
    "        self.att_block = AttBlock(1280, Config.num_class, activation='sigmoid')\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        \n",
    "    \n",
    "    def preprocess(self, input_x, mixup_lambda=None):\n",
    "\n",
    "        x = self.spectrogram_extractor(input_x)  # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)  # (batch_size, 1, time_steps, mel_bins)\n",
    "\n",
    "        frames_num = x.shape[2]\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        if self.training and self.apply_aug:\n",
    "            x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        if self.training  and self.apply_aug and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "        return x, frames_num\n",
    "        \n",
    "\n",
    "    def forward(self, x, t_min_ratio=None, t_max_ratio=None, attn_mask=False):\n",
    "#         input_x, mixup_lambda = input_data\n",
    "#         \"\"\"\n",
    "#         Input: (batch_size, data_length)\"\"\"\n",
    "#         b, c, s = input_x.shape\n",
    "#         input_x = input_x.reshape(b*c, s)\n",
    "#         x, frames_num = self.preprocess(wav)\n",
    "#         if mixup_lambda is not None:\n",
    "#             b = (b*c)//2\n",
    "#             c = 1\n",
    "        # Output shape (batch size, channels, time, frequency)\n",
    "        x = self.feature_net(x)\n",
    "        \n",
    "        # Aggregate in frequency axis\n",
    "        x = torch.mean(x, dim=3)\n",
    "\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        if attn_mask:\n",
    "            (clipwise_output, norm_att, segmentwise_output) = self.att_block(x, t_min_ratio, t_max_ratio, attn_mask=True)\n",
    "        else:\n",
    "            (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "        framewise_output = segmentwise_output\n",
    "        # Get framewise output\n",
    "#         framewise_output = interpolate(segmentwise_output,\n",
    "#                                        self.interpolate_ratio)\n",
    "#         framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "#         frame_shape =  framewise_output.shape\n",
    "#         clip_shape = clipwise_output.shape\n",
    "        output_dict = {\n",
    "            'framewise_output': framewise_output,\n",
    "            'clipwise_output': clipwise_output,\n",
    "        }\n",
    "\n",
    "        return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:53:06.411716Z",
     "start_time": "2021-02-11T01:53:06.395049Z"
    }
   },
   "outputs": [],
   "source": [
    "# label-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LWLRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    # Number of GT labels per instance\n",
    "    num_labels = labels.sum(-1)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = scores.sum() / labels.sum()\n",
    "    return score.item()\n",
    "\n",
    "# # Sample usage\n",
    "# y_true = torch.tensor(np.array([[1, 1, 0], [1, 0, 1], [0, 0, 1]]))\n",
    "# y_score = torch.tensor(np.random.randn(3, 3))\n",
    "# print(LRAP(y_score, y_true), LWLRAP(y_score, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:53:07.138215Z",
     "start_time": "2021-02-11T01:53:07.125919Z"
    }
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, t_min_ratio, t_max_ratio, alpha=5):\n",
    "    \"\"\"\n",
    "    Applies mixup to a sample\n",
    "    Arguments:\n",
    "        x {torch tensor} -- Input batch\n",
    "        y {torch tensor} -- Labels\n",
    "    Keyword Arguments:\n",
    "        alpha {float} -- Parameter of the beta distribution (default: {0.4})\n",
    "    Returns:\n",
    "        torch tensor  -- Mixed input\n",
    "        torch tensor  -- Labels of the original batch\n",
    "        torch tensor  -- Labels of the shuffle batch\n",
    "        float  -- Probability samples by the beta distribution\n",
    "    \"\"\"\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "    index = torch.randperm(x.size()[0]).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    t_min = torch.stack([t_min_ratio, t_min_ratio[index]], dim=1)\n",
    "    t_max = torch.stack([t_max_ratio, t_max_ratio[index]], dim=1)\n",
    "    return mixed_x, y_a, y_b, t_min, t_max, lam\n",
    "\n",
    "# for step, (x, y_batch) in enumerate(train_loader):\n",
    "    \n",
    "#     if np.random.rand() < mixup_proba:\n",
    "#         x, y_a, y_b, _ = mixup_data(x.cuda(), y_batch.cuda(), alpha=alpha)\n",
    "#         y_batch = torch.clamp(y_a + y_b, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:53:07.944486Z",
     "start_time": "2021-02-11T01:53:07.909456Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader, criterion, history, n_iters, writer, fold):\n",
    "    model.eval()\n",
    "    costs = []\n",
    "    rocs = []\n",
    "    metrics = []\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    y_probs = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            X, y, t_min_ratio, t_max_ratio = batch\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            y_output = model(X, t_min_ratio=t_min_ratio, t_max_ratio=t_max_ratio, attn_mask=True)    \n",
    "            loss = criterion(y_output, y)\n",
    "            costs.append(loss.item())\n",
    "            y_true, y_prob= y.cpu(), y_output['clipwise_output'].detach().cpu()\n",
    "            y_pred = (y_prob+0.5).int()\n",
    "            y_trues.append(y_true.numpy())\n",
    "            y_probs.append(y_prob.numpy())\n",
    "            y_preds.append(y_pred.numpy())\n",
    "            metrics.append(LWLRAP(y_prob, y.cpu()))\n",
    "    \n",
    "    mean_rocs = sklearn.metrics.roc_auc_score(np.concatenate(y_trues), np.concatenate(y_probs))\n",
    "    mean_costs = np.mean(costs)\n",
    "    mean_metrics = np.mean(metrics)\n",
    "    writer.add_scalar('fold_{}/validate_roc'.format(fold), mean_rocs, n_iters)\n",
    "    writer.add_scalar('fold_{}/validate_loss'.format(fold), mean_costs, n_iters)\n",
    "    writer.add_scalar('fold_{}/validate_LWLRAP'.format(fold), mean_metrics, n_iters)\n",
    "    history['best_roc'][fold] = mean_rocs\n",
    "    history['best_metrics'][fold] = mean_metrics\n",
    "#     if mean_rocs > history['best_roc'][fold]:  \n",
    "#         history['best_roc'][fold] = mean_rocs\n",
    "#         history['best_metrics'][fold] = mean_metrics\n",
    "#         torch.save(model.state_dict(), history['best_model_path'][fold])\n",
    "    return mean_costs, mean_rocs, mean_metrics\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler, writer, fold, step=True):\n",
    "    model.train()\n",
    "    costs = []\n",
    "    metrics = []\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    y_probs = []\n",
    "    val_loss, val_roc = 0, 0\n",
    "    optimizer.zero_grad()\n",
    "    with tqdm(total=len(train_dataloader.dataset), desc='Epoch{}'.format(epoch)) as pbar:\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            X, y, t_min_ratio, t_max_ratio = batch\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            if np.random.rand() < Config.mixup_proba:\n",
    "                X, y_a, y_b, t_min_ratio, t_max_ratio, _ = mixup_data(X, y, t_min_ratio, t_max_ratio, alpha=Config.mixup_alpha)\n",
    "                y = torch.clamp(y_a + y_b, 0, 1)\n",
    "            y_output = model(X, t_min_ratio=t_min_ratio, t_max_ratio=t_max_ratio, attn_mask=True)    \n",
    "            loss = criterion(y_output, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step:\n",
    "                scheduler.step()\n",
    "            costs.append(loss.item())\n",
    "            y_true, y_prob= y.cpu(), y_output['clipwise_output'].detach().cpu()\n",
    "            y_pred = (y_prob+0.5).int()\n",
    "            y_trues.append(y_true.numpy())\n",
    "            y_probs.append(y_prob.numpy())\n",
    "            y_preds.append(y_pred.numpy())\n",
    "            metrics.append(LWLRAP(y_prob, y_true))\n",
    "#             rocs.append(sklearn.metrics.roc_auc_score(y.cpu(), y_prob))\n",
    "#                 rocs.append((y_pred == y.cpu()).float().mean().item())\n",
    "            pbar.update(y.size(0))\n",
    "            n_iters = idx + len(train_dataloader) * (epoch-1)\n",
    "            if idx in validate_points:\n",
    "                val_loss, val_roc, val_metrics = validate(model, val_dataloader, criterion, history, n_iters, writer, fold)\n",
    "                model.train()\n",
    "            writer.add_scalar('fold_{}/train_loss'.format(fold), costs[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/train_LWLRAP'.format(fold), metrics[-1], n_iters)\n",
    "            writer.add_scalar('fold_{}/learning_rate'.format(fold), scheduler.get_last_lr()[0], n_iters)\n",
    "            pbar.set_postfix_str('loss:{:.3f}, val-loss:{:.3f}, val-roc:{:.4f}'.format(np.mean(costs[-10:]),  val_loss, val_roc))\n",
    "            torch.cuda.empty_cache()\n",
    "        writer.add_scalar('fold_{}/train_roc'.format(fold), sklearn.metrics.roc_auc_score(np.concatenate(y_trues), np.concatenate(y_probs)), n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:53:09.432182Z",
     "start_time": "2021-02-11T01:53:09.422530Z"
    }
   },
   "outputs": [],
   "source": [
    "class PANNsLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_ = input[\"clipwise_output\"]\n",
    "#         input_ = torch.where(torch.isnan(input_),\n",
    "#                              torch.zeros_like(input_),\n",
    "#                              input_)\n",
    "#         input_ = torch.where(torch.isinf(input_),\n",
    "#                              torch.zeros_like(input_),\n",
    "#                              input_)\n",
    "        input_ = torch.clamp(input_, 0, 1)\n",
    "        target = target.float()\n",
    "        return self.bce(input_, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T04:15:05.276469Z",
     "start_time": "2021-02-11T01:53:59.499400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 972/972 [00:40<00:00, 23.72it/s, loss:0.258, val-loss:0.546, val-roc:0.5045]\n",
      "Epoch2: 100%|██████████| 972/972 [00:39<00:00, 24.74it/s, loss:0.200, val-loss:0.254, val-roc:0.5069]\n",
      "Epoch3: 100%|██████████| 972/972 [00:39<00:00, 24.31it/s, loss:0.175, val-loss:0.223, val-roc:0.5242]\n",
      "Epoch4: 100%|██████████| 972/972 [00:42<00:00, 22.70it/s, loss:0.160, val-loss:0.192, val-roc:0.5650]\n",
      "Epoch5: 100%|██████████| 972/972 [00:43<00:00, 22.20it/s, loss:0.139, val-loss:0.187, val-roc:0.6349]\n",
      "Epoch6: 100%|██████████| 972/972 [00:42<00:00, 22.98it/s, loss:0.117, val-loss:0.186, val-roc:0.6982]\n",
      "Epoch7: 100%|██████████| 972/972 [00:43<00:00, 22.20it/s, loss:0.094, val-loss:0.198, val-roc:0.7414]\n",
      "Epoch8: 100%|██████████| 972/972 [00:43<00:00, 22.59it/s, loss:0.082, val-loss:0.193, val-roc:0.8372]\n",
      "Epoch9: 100%|██████████| 972/972 [00:42<00:00, 23.04it/s, loss:0.063, val-loss:0.193, val-roc:0.8617]\n",
      "Epoch10: 100%|██████████| 972/972 [00:43<00:00, 22.49it/s, loss:0.060, val-loss:0.176, val-roc:0.8879]\n",
      "Epoch11: 100%|██████████| 972/972 [00:42<00:00, 22.74it/s, loss:0.052, val-loss:0.119, val-roc:0.9395]\n",
      "Epoch12: 100%|██████████| 972/972 [00:42<00:00, 22.78it/s, loss:0.050, val-loss:0.149, val-roc:0.9401]\n",
      "Epoch13: 100%|██████████| 972/972 [00:43<00:00, 22.38it/s, loss:0.041, val-loss:0.124, val-roc:0.9531]\n",
      "Epoch14: 100%|██████████| 972/972 [00:43<00:00, 22.45it/s, loss:0.038, val-loss:0.094, val-roc:0.9772]\n",
      "Epoch15: 100%|██████████| 972/972 [00:43<00:00, 22.60it/s, loss:0.038, val-loss:0.071, val-roc:0.9745]\n",
      "Epoch16: 100%|██████████| 972/972 [00:43<00:00, 22.10it/s, loss:0.033, val-loss:0.062, val-roc:0.9779]\n",
      "Epoch17: 100%|██████████| 972/972 [00:42<00:00, 22.92it/s, loss:0.022, val-loss:0.062, val-roc:0.9784]\n",
      "Epoch18: 100%|██████████| 972/972 [00:42<00:00, 23.12it/s, loss:0.030, val-loss:0.075, val-roc:0.9750]\n",
      "Epoch19: 100%|██████████| 972/972 [00:43<00:00, 22.46it/s, loss:0.018, val-loss:0.099, val-roc:0.9750]\n",
      "Epoch20: 100%|██████████| 972/972 [00:43<00:00, 22.42it/s, loss:0.018, val-loss:0.045, val-roc:0.9862]\n",
      "Epoch21: 100%|██████████| 972/972 [00:43<00:00, 22.41it/s, loss:0.019, val-loss:0.055, val-roc:0.9820]\n",
      "Epoch22: 100%|██████████| 972/972 [00:43<00:00, 22.50it/s, loss:0.024, val-loss:0.051, val-roc:0.9852]\n",
      "Epoch23: 100%|██████████| 972/972 [00:42<00:00, 22.74it/s, loss:0.023, val-loss:0.119, val-roc:0.9748]\n",
      "Epoch24: 100%|██████████| 972/972 [00:44<00:00, 21.87it/s, loss:0.012, val-loss:0.071, val-roc:0.9812]\n",
      "Epoch25: 100%|██████████| 972/972 [00:42<00:00, 22.82it/s, loss:0.014, val-loss:0.055, val-roc:0.9855]\n",
      "Epoch26: 100%|██████████| 972/972 [00:42<00:00, 22.94it/s, loss:0.014, val-loss:0.056, val-roc:0.9850]\n",
      "Epoch27: 100%|██████████| 972/972 [00:42<00:00, 22.93it/s, loss:0.013, val-loss:0.079, val-roc:0.9825]\n",
      "Epoch28: 100%|██████████| 972/972 [00:43<00:00, 22.33it/s, loss:0.017, val-loss:0.089, val-roc:0.9866]\n",
      "Epoch29: 100%|██████████| 972/972 [00:43<00:00, 22.26it/s, loss:0.012, val-loss:0.069, val-roc:0.9837]\n",
      "Epoch30: 100%|██████████| 972/972 [00:43<00:00, 22.46it/s, loss:0.011, val-loss:0.050, val-roc:0.9866]\n",
      "Epoch31: 100%|██████████| 972/972 [00:42<00:00, 22.95it/s, loss:0.013, val-loss:0.063, val-roc:0.9870]\n",
      "Epoch32: 100%|██████████| 972/972 [00:42<00:00, 23.00it/s, loss:0.008, val-loss:0.047, val-roc:0.9893]\n",
      "Epoch33: 100%|██████████| 972/972 [00:43<00:00, 22.10it/s, loss:0.009, val-loss:0.045, val-roc:0.9890]\n",
      "Epoch34: 100%|██████████| 972/972 [00:41<00:00, 23.51it/s, loss:0.011, val-loss:0.066, val-roc:0.9849]\n",
      "Epoch35: 100%|██████████| 972/972 [00:42<00:00, 22.69it/s, loss:0.011, val-loss:0.047, val-roc:0.9890]\n",
      "Epoch36: 100%|██████████| 972/972 [00:42<00:00, 23.04it/s, loss:0.009, val-loss:0.047, val-roc:0.9874]\n",
      "Epoch37: 100%|██████████| 972/972 [00:42<00:00, 22.62it/s, loss:0.008, val-loss:0.050, val-roc:0.9879]\n",
      "Epoch38: 100%|██████████| 972/972 [00:43<00:00, 22.55it/s, loss:0.009, val-loss:0.065, val-roc:0.9860]\n",
      "Epoch39: 100%|██████████| 972/972 [00:43<00:00, 22.34it/s, loss:0.008, val-loss:0.047, val-roc:0.9895]\n",
      "Epoch40: 100%|██████████| 972/972 [00:42<00:00, 22.79it/s, loss:0.009, val-loss:0.065, val-roc:0.9865]\n",
      "Epoch1:   0%|          | 0/973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 973/973 [00:42<00:00, 22.97it/s, loss:0.301, val-loss:0.649, val-roc:0.5174]\n",
      "Epoch2: 100%|██████████| 973/973 [00:42<00:00, 23.05it/s, loss:0.196, val-loss:0.233, val-roc:0.5078]\n",
      "Epoch3: 100%|██████████| 973/973 [00:43<00:00, 22.47it/s, loss:0.174, val-loss:0.246, val-roc:0.5169]\n",
      "Epoch4: 100%|██████████| 973/973 [00:41<00:00, 23.38it/s, loss:0.155, val-loss:0.199, val-roc:0.5525]\n",
      "Epoch5: 100%|██████████| 973/973 [00:44<00:00, 22.01it/s, loss:0.140, val-loss:0.195, val-roc:0.6245]\n",
      "Epoch6: 100%|██████████| 973/973 [00:42<00:00, 22.88it/s, loss:0.117, val-loss:0.182, val-roc:0.6922]\n",
      "Epoch7: 100%|██████████| 973/973 [00:42<00:00, 22.64it/s, loss:0.094, val-loss:0.178, val-roc:0.7683]\n",
      "Epoch8: 100%|██████████| 973/973 [00:42<00:00, 22.78it/s, loss:0.080, val-loss:0.230, val-roc:0.6818]\n",
      "Epoch9: 100%|██████████| 973/973 [00:42<00:00, 22.73it/s, loss:0.075, val-loss:0.177, val-roc:0.8715]\n",
      "Epoch10: 100%|██████████| 973/973 [00:43<00:00, 22.34it/s, loss:0.062, val-loss:0.139, val-roc:0.9056]\n",
      "Epoch11: 100%|██████████| 973/973 [00:42<00:00, 23.03it/s, loss:0.044, val-loss:0.100, val-roc:0.9410]\n",
      "Epoch12: 100%|██████████| 973/973 [00:42<00:00, 22.98it/s, loss:0.033, val-loss:0.091, val-roc:0.9602]\n",
      "Epoch13: 100%|██████████| 973/973 [00:42<00:00, 22.66it/s, loss:0.036, val-loss:0.121, val-roc:0.9444]\n",
      "Epoch14: 100%|██████████| 973/973 [00:42<00:00, 22.93it/s, loss:0.039, val-loss:0.102, val-roc:0.9569]\n",
      "Epoch15: 100%|██████████| 973/973 [00:41<00:00, 23.22it/s, loss:0.030, val-loss:0.098, val-roc:0.9505]\n",
      "Epoch16: 100%|██████████| 973/973 [00:42<00:00, 22.68it/s, loss:0.022, val-loss:0.100, val-roc:0.9637]\n",
      "Epoch17: 100%|██████████| 973/973 [00:42<00:00, 23.12it/s, loss:0.030, val-loss:0.082, val-roc:0.9638]\n",
      "Epoch18: 100%|██████████| 973/973 [00:42<00:00, 22.67it/s, loss:0.029, val-loss:0.128, val-roc:0.9556]\n",
      "Epoch19: 100%|██████████| 973/973 [00:42<00:00, 23.10it/s, loss:0.023, val-loss:0.086, val-roc:0.9706]\n",
      "Epoch20: 100%|██████████| 973/973 [00:42<00:00, 22.79it/s, loss:0.018, val-loss:0.096, val-roc:0.9688]\n",
      "Epoch21: 100%|██████████| 973/973 [00:42<00:00, 22.67it/s, loss:0.017, val-loss:0.121, val-roc:0.9738]\n",
      "Epoch22: 100%|██████████| 973/973 [00:41<00:00, 23.20it/s, loss:0.021, val-loss:0.102, val-roc:0.9647]\n",
      "Epoch23: 100%|██████████| 973/973 [00:42<00:00, 22.67it/s, loss:0.031, val-loss:0.085, val-roc:0.9761]\n",
      "Epoch24: 100%|██████████| 973/973 [00:43<00:00, 22.44it/s, loss:0.013, val-loss:0.091, val-roc:0.9707]\n",
      "Epoch25: 100%|██████████| 973/973 [00:43<00:00, 22.51it/s, loss:0.011, val-loss:0.074, val-roc:0.9720]\n",
      "Epoch26: 100%|██████████| 973/973 [00:44<00:00, 22.08it/s, loss:0.016, val-loss:0.077, val-roc:0.9822]\n",
      "Epoch27: 100%|██████████| 973/973 [00:42<00:00, 22.87it/s, loss:0.012, val-loss:0.070, val-roc:0.9762]\n",
      "Epoch28: 100%|██████████| 973/973 [00:42<00:00, 22.89it/s, loss:0.009, val-loss:0.094, val-roc:0.9714]\n",
      "Epoch29: 100%|██████████| 973/973 [00:42<00:00, 22.68it/s, loss:0.012, val-loss:0.069, val-roc:0.9767]\n",
      "Epoch30: 100%|██████████| 973/973 [00:42<00:00, 22.64it/s, loss:0.012, val-loss:0.065, val-roc:0.9764]\n",
      "Epoch31: 100%|██████████| 973/973 [00:43<00:00, 22.50it/s, loss:0.010, val-loss:0.084, val-roc:0.9737]\n",
      "Epoch32: 100%|██████████| 973/973 [00:43<00:00, 22.53it/s, loss:0.008, val-loss:0.097, val-roc:0.9765]\n",
      "Epoch33: 100%|██████████| 973/973 [00:42<00:00, 22.74it/s, loss:0.009, val-loss:0.083, val-roc:0.9772]\n",
      "Epoch34: 100%|██████████| 973/973 [00:43<00:00, 22.56it/s, loss:0.008, val-loss:0.100, val-roc:0.9743]\n",
      "Epoch35: 100%|██████████| 973/973 [00:42<00:00, 22.65it/s, loss:0.009, val-loss:0.095, val-roc:0.9763]\n",
      "Epoch36: 100%|██████████| 973/973 [00:42<00:00, 22.75it/s, loss:0.011, val-loss:0.084, val-roc:0.9779]\n",
      "Epoch37: 100%|██████████| 973/973 [00:42<00:00, 22.95it/s, loss:0.011, val-loss:0.114, val-roc:0.9745]\n",
      "Epoch38: 100%|██████████| 973/973 [00:43<00:00, 22.57it/s, loss:0.008, val-loss:0.098, val-roc:0.9768]\n",
      "Epoch39: 100%|██████████| 973/973 [00:43<00:00, 22.46it/s, loss:0.011, val-loss:0.091, val-roc:0.9778]\n",
      "Epoch40: 100%|██████████| 973/973 [00:43<00:00, 22.60it/s, loss:0.009, val-loss:0.095, val-roc:0.9787]\n",
      "Epoch1:   0%|          | 0/973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 973/973 [00:42<00:00, 22.68it/s, loss:0.262, val-loss:0.611, val-roc:0.5304]\n",
      "Epoch2: 100%|██████████| 973/973 [00:42<00:00, 22.64it/s, loss:0.194, val-loss:0.305, val-roc:0.5340]\n",
      "Epoch3: 100%|██████████| 973/973 [00:42<00:00, 22.84it/s, loss:0.170, val-loss:0.269, val-roc:0.5655]\n",
      "Epoch4: 100%|██████████| 973/973 [00:43<00:00, 22.34it/s, loss:0.159, val-loss:0.205, val-roc:0.6116]\n",
      "Epoch5: 100%|██████████| 973/973 [00:43<00:00, 22.58it/s, loss:0.140, val-loss:0.192, val-roc:0.6543]\n",
      "Epoch6: 100%|██████████| 973/973 [00:43<00:00, 22.44it/s, loss:0.114, val-loss:0.175, val-roc:0.7454]\n",
      "Epoch7: 100%|██████████| 973/973 [00:42<00:00, 22.83it/s, loss:0.101, val-loss:0.148, val-roc:0.8467]\n",
      "Epoch8: 100%|██████████| 973/973 [00:43<00:00, 22.56it/s, loss:0.079, val-loss:0.133, val-roc:0.8923]\n",
      "Epoch9: 100%|██████████| 973/973 [00:43<00:00, 22.30it/s, loss:0.067, val-loss:0.155, val-roc:0.9231]\n",
      "Epoch10: 100%|██████████| 973/973 [00:43<00:00, 22.52it/s, loss:0.060, val-loss:0.124, val-roc:0.9538]\n",
      "Epoch11: 100%|██████████| 973/973 [00:42<00:00, 22.66it/s, loss:0.057, val-loss:0.101, val-roc:0.9614]\n",
      "Epoch12: 100%|██████████| 973/973 [00:41<00:00, 23.20it/s, loss:0.043, val-loss:0.076, val-roc:0.9808]\n",
      "Epoch13: 100%|██████████| 973/973 [00:42<00:00, 23.09it/s, loss:0.043, val-loss:0.077, val-roc:0.9784]\n",
      "Epoch14: 100%|██████████| 973/973 [00:42<00:00, 23.16it/s, loss:0.044, val-loss:0.077, val-roc:0.9701]\n",
      "Epoch15: 100%|██████████| 973/973 [00:42<00:00, 23.12it/s, loss:0.033, val-loss:0.073, val-roc:0.9793]\n",
      "Epoch16: 100%|██████████| 973/973 [00:42<00:00, 22.96it/s, loss:0.031, val-loss:0.081, val-roc:0.9721]\n",
      "Epoch17: 100%|██████████| 973/973 [00:42<00:00, 22.90it/s, loss:0.027, val-loss:0.108, val-roc:0.9782]\n",
      "Epoch18: 100%|██████████| 973/973 [00:43<00:00, 22.49it/s, loss:0.030, val-loss:0.059, val-roc:0.9815]\n",
      "Epoch19: 100%|██████████| 973/973 [00:42<00:00, 22.68it/s, loss:0.022, val-loss:0.127, val-roc:0.9709]\n",
      "Epoch20: 100%|██████████| 973/973 [00:42<00:00, 22.70it/s, loss:0.016, val-loss:0.056, val-roc:0.9816]\n",
      "Epoch21: 100%|██████████| 973/973 [00:43<00:00, 22.50it/s, loss:0.024, val-loss:0.057, val-roc:0.9816]\n",
      "Epoch22: 100%|██████████| 973/973 [00:42<00:00, 22.67it/s, loss:0.019, val-loss:0.059, val-roc:0.9803]\n",
      "Epoch23: 100%|██████████| 973/973 [00:42<00:00, 22.70it/s, loss:0.018, val-loss:0.083, val-roc:0.9807]\n",
      "Epoch24: 100%|██████████| 973/973 [00:43<00:00, 22.61it/s, loss:0.017, val-loss:0.049, val-roc:0.9864]\n",
      "Epoch25: 100%|██████████| 973/973 [00:41<00:00, 23.26it/s, loss:0.017, val-loss:0.048, val-roc:0.9874]\n",
      "Epoch26: 100%|██████████| 973/973 [00:43<00:00, 22.55it/s, loss:0.017, val-loss:0.046, val-roc:0.9859]\n",
      "Epoch27: 100%|██████████| 973/973 [00:42<00:00, 22.77it/s, loss:0.012, val-loss:0.054, val-roc:0.9835]\n",
      "Epoch28: 100%|██████████| 973/973 [00:43<00:00, 22.55it/s, loss:0.011, val-loss:0.045, val-roc:0.9857]\n",
      "Epoch29: 100%|██████████| 973/973 [00:43<00:00, 22.61it/s, loss:0.014, val-loss:0.069, val-roc:0.9834]\n",
      "Epoch30: 100%|██████████| 973/973 [00:42<00:00, 23.05it/s, loss:0.011, val-loss:0.066, val-roc:0.9827]\n",
      "Epoch31: 100%|██████████| 973/973 [00:43<00:00, 22.62it/s, loss:0.012, val-loss:0.046, val-roc:0.9838]\n",
      "Epoch32: 100%|██████████| 973/973 [00:42<00:00, 22.97it/s, loss:0.006, val-loss:0.062, val-roc:0.9826]\n",
      "Epoch33: 100%|██████████| 973/973 [00:42<00:00, 22.95it/s, loss:0.010, val-loss:0.061, val-roc:0.9849]\n",
      "Epoch34: 100%|██████████| 973/973 [00:42<00:00, 22.93it/s, loss:0.010, val-loss:0.058, val-roc:0.9856]\n",
      "Epoch35: 100%|██████████| 973/973 [00:42<00:00, 22.66it/s, loss:0.009, val-loss:0.037, val-roc:0.9890]\n",
      "Epoch36: 100%|██████████| 973/973 [00:42<00:00, 22.97it/s, loss:0.011, val-loss:0.057, val-roc:0.9853]\n",
      "Epoch37: 100%|██████████| 973/973 [00:41<00:00, 23.25it/s, loss:0.010, val-loss:0.058, val-roc:0.9867]\n",
      "Epoch38: 100%|██████████| 973/973 [00:43<00:00, 22.42it/s, loss:0.010, val-loss:0.038, val-roc:0.9886]\n",
      "Epoch39: 100%|██████████| 973/973 [00:42<00:00, 23.15it/s, loss:0.009, val-loss:0.059, val-roc:0.9847]\n",
      "Epoch40: 100%|██████████| 973/973 [00:43<00:00, 22.55it/s, loss:0.008, val-loss:0.054, val-roc:0.9886]\n",
      "Epoch1:   0%|          | 0/973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 973/973 [00:43<00:00, 22.47it/s, loss:0.271, val-loss:0.654, val-roc:0.5008]\n",
      "Epoch2: 100%|██████████| 973/973 [00:43<00:00, 22.46it/s, loss:0.197, val-loss:0.293, val-roc:0.5066]\n",
      "Epoch3: 100%|██████████| 973/973 [00:43<00:00, 22.56it/s, loss:0.177, val-loss:0.242, val-roc:0.5297]\n",
      "Epoch4: 100%|██████████| 973/973 [00:42<00:00, 22.76it/s, loss:0.159, val-loss:0.202, val-roc:0.5946]\n",
      "Epoch5: 100%|██████████| 973/973 [00:42<00:00, 23.15it/s, loss:0.139, val-loss:0.189, val-roc:0.6519]\n",
      "Epoch6: 100%|██████████| 973/973 [00:42<00:00, 22.73it/s, loss:0.117, val-loss:0.174, val-roc:0.7512]\n",
      "Epoch7: 100%|██████████| 973/973 [00:42<00:00, 22.71it/s, loss:0.098, val-loss:0.176, val-roc:0.7944]\n",
      "Epoch8: 100%|██████████| 973/973 [00:42<00:00, 22.73it/s, loss:0.083, val-loss:0.235, val-roc:0.8383]\n",
      "Epoch9: 100%|██████████| 973/973 [00:41<00:00, 23.19it/s, loss:0.077, val-loss:0.175, val-roc:0.8889]\n",
      "Epoch10: 100%|██████████| 973/973 [00:42<00:00, 22.65it/s, loss:0.064, val-loss:0.147, val-roc:0.9245]\n",
      "Epoch11: 100%|██████████| 973/973 [00:42<00:00, 23.01it/s, loss:0.049, val-loss:0.105, val-roc:0.9491]\n",
      "Epoch12: 100%|██████████| 973/973 [00:42<00:00, 22.85it/s, loss:0.052, val-loss:0.111, val-roc:0.9454]\n",
      "Epoch13: 100%|██████████| 973/973 [00:43<00:00, 22.50it/s, loss:0.042, val-loss:0.097, val-roc:0.9605]\n",
      "Epoch14: 100%|██████████| 973/973 [00:42<00:00, 22.80it/s, loss:0.032, val-loss:0.084, val-roc:0.9666]\n",
      "Epoch15: 100%|██████████| 973/973 [00:42<00:00, 22.77it/s, loss:0.035, val-loss:0.115, val-roc:0.9667]\n",
      "Epoch16: 100%|██████████| 973/973 [00:43<00:00, 22.28it/s, loss:0.027, val-loss:0.104, val-roc:0.9711]\n",
      "Epoch17: 100%|██████████| 973/973 [00:42<00:00, 23.07it/s, loss:0.025, val-loss:0.140, val-roc:0.9687]\n",
      "Epoch18: 100%|██████████| 973/973 [00:41<00:00, 23.37it/s, loss:0.023, val-loss:0.078, val-roc:0.9756]\n",
      "Epoch19: 100%|██████████| 973/973 [00:41<00:00, 23.56it/s, loss:0.020, val-loss:0.081, val-roc:0.9716]\n",
      "Epoch20: 100%|██████████| 973/973 [00:41<00:00, 23.62it/s, loss:0.020, val-loss:0.117, val-roc:0.9660]\n",
      "Epoch21: 100%|██████████| 973/973 [00:41<00:00, 23.47it/s, loss:0.024, val-loss:0.107, val-roc:0.9697]\n",
      "Epoch22: 100%|██████████| 973/973 [00:41<00:00, 23.34it/s, loss:0.018, val-loss:0.093, val-roc:0.9751]\n",
      "Epoch23: 100%|██████████| 973/973 [00:41<00:00, 23.23it/s, loss:0.016, val-loss:0.085, val-roc:0.9730]\n",
      "Epoch24: 100%|██████████| 973/973 [00:42<00:00, 23.02it/s, loss:0.013, val-loss:0.136, val-roc:0.9743]\n",
      "Epoch25: 100%|██████████| 973/973 [00:42<00:00, 23.08it/s, loss:0.018, val-loss:0.110, val-roc:0.9742]\n",
      "Epoch26: 100%|██████████| 973/973 [00:41<00:00, 23.37it/s, loss:0.015, val-loss:0.089, val-roc:0.9770]\n",
      "Epoch27: 100%|██████████| 973/973 [00:40<00:00, 23.75it/s, loss:0.011, val-loss:0.080, val-roc:0.9777]\n",
      "Epoch28: 100%|██████████| 973/973 [00:41<00:00, 23.68it/s, loss:0.017, val-loss:0.085, val-roc:0.9758]\n",
      "Epoch29: 100%|██████████| 973/973 [00:41<00:00, 23.46it/s, loss:0.012, val-loss:0.115, val-roc:0.9752]\n",
      "Epoch30: 100%|██████████| 973/973 [00:41<00:00, 23.46it/s, loss:0.009, val-loss:0.084, val-roc:0.9767]\n",
      "Epoch31: 100%|██████████| 973/973 [00:41<00:00, 23.28it/s, loss:0.008, val-loss:0.141, val-roc:0.9768]\n",
      "Epoch32: 100%|██████████| 973/973 [00:41<00:00, 23.27it/s, loss:0.010, val-loss:0.107, val-roc:0.9779]\n",
      "Epoch33: 100%|██████████| 973/973 [00:41<00:00, 23.23it/s, loss:0.016, val-loss:0.081, val-roc:0.9787]\n",
      "Epoch34: 100%|██████████| 973/973 [00:41<00:00, 23.45it/s, loss:0.010, val-loss:0.120, val-roc:0.9789]\n",
      "Epoch35: 100%|██████████| 973/973 [00:40<00:00, 23.79it/s, loss:0.010, val-loss:0.128, val-roc:0.9760]\n",
      "Epoch36: 100%|██████████| 973/973 [00:41<00:00, 23.57it/s, loss:0.009, val-loss:0.124, val-roc:0.9763]\n",
      "Epoch37: 100%|██████████| 973/973 [00:40<00:00, 23.76it/s, loss:0.008, val-loss:0.093, val-roc:0.9788]\n",
      "Epoch38: 100%|██████████| 973/973 [00:41<00:00, 23.48it/s, loss:0.007, val-loss:0.091, val-roc:0.9800]\n",
      "Epoch39: 100%|██████████| 973/973 [00:42<00:00, 22.91it/s, loss:0.010, val-loss:0.124, val-roc:0.9770]\n",
      "Epoch40: 100%|██████████| 973/973 [00:43<00:00, 22.45it/s, loss:0.008, val-loss:0.105, val-roc:0.9787]\n",
      "Epoch1:   0%|          | 0/973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch1: 100%|██████████| 973/973 [00:40<00:00, 23.98it/s, loss:0.269, val-loss:0.524, val-roc:0.5119]\n",
      "Epoch2: 100%|██████████| 973/973 [00:41<00:00, 23.26it/s, loss:0.194, val-loss:0.226, val-roc:0.5057]\n",
      "Epoch3: 100%|██████████| 973/973 [00:41<00:00, 23.18it/s, loss:0.174, val-loss:0.216, val-roc:0.5498]\n",
      "Epoch4: 100%|██████████| 973/973 [00:42<00:00, 22.97it/s, loss:0.158, val-loss:0.180, val-roc:0.6163]\n",
      "Epoch5: 100%|██████████| 973/973 [00:41<00:00, 23.56it/s, loss:0.142, val-loss:0.192, val-roc:0.6220]\n",
      "Epoch6: 100%|██████████| 973/973 [00:40<00:00, 24.23it/s, loss:0.120, val-loss:0.178, val-roc:0.7023]\n",
      "Epoch7: 100%|██████████| 973/973 [00:39<00:00, 24.45it/s, loss:0.095, val-loss:0.194, val-roc:0.8139]\n",
      "Epoch8: 100%|██████████| 973/973 [00:39<00:00, 24.63it/s, loss:0.087, val-loss:0.197, val-roc:0.8381]\n",
      "Epoch9: 100%|██████████| 973/973 [00:40<00:00, 24.14it/s, loss:0.063, val-loss:0.204, val-roc:0.8665]\n",
      "Epoch10: 100%|██████████| 973/973 [00:40<00:00, 24.28it/s, loss:0.058, val-loss:0.132, val-roc:0.9161]\n",
      "Epoch11: 100%|██████████| 973/973 [00:39<00:00, 24.76it/s, loss:0.054, val-loss:0.113, val-roc:0.9500]\n",
      "Epoch12: 100%|██████████| 973/973 [00:39<00:00, 24.45it/s, loss:0.042, val-loss:0.085, val-roc:0.9648]\n",
      "Epoch13: 100%|██████████| 973/973 [00:39<00:00, 24.76it/s, loss:0.043, val-loss:0.084, val-roc:0.9657]\n",
      "Epoch14: 100%|██████████| 973/973 [00:39<00:00, 24.33it/s, loss:0.040, val-loss:0.087, val-roc:0.9621]\n",
      "Epoch15: 100%|██████████| 973/973 [00:39<00:00, 24.68it/s, loss:0.042, val-loss:0.101, val-roc:0.9544]\n",
      "Epoch16: 100%|██████████| 973/973 [00:39<00:00, 24.77it/s, loss:0.043, val-loss:0.098, val-roc:0.9648]\n",
      "Epoch17: 100%|██████████| 973/973 [00:38<00:00, 25.59it/s, loss:0.026, val-loss:0.066, val-roc:0.9630]\n",
      "Epoch18: 100%|██████████| 973/973 [00:39<00:00, 24.92it/s, loss:0.021, val-loss:0.090, val-roc:0.9683]\n",
      "Epoch19: 100%|██████████| 973/973 [00:39<00:00, 24.46it/s, loss:0.025, val-loss:0.097, val-roc:0.9605]\n",
      "Epoch20: 100%|██████████| 973/973 [00:39<00:00, 24.43it/s, loss:0.018, val-loss:0.113, val-roc:0.9671]\n",
      "Epoch21: 100%|██████████| 973/973 [00:40<00:00, 24.25it/s, loss:0.020, val-loss:0.088, val-roc:0.9709]\n",
      "Epoch22: 100%|██████████| 973/973 [00:40<00:00, 24.08it/s, loss:0.021, val-loss:0.080, val-roc:0.9676]\n",
      "Epoch23: 100%|██████████| 973/973 [00:40<00:00, 23.89it/s, loss:0.022, val-loss:0.091, val-roc:0.9688]\n",
      "Epoch24: 100%|██████████| 973/973 [00:39<00:00, 24.56it/s, loss:0.014, val-loss:0.061, val-roc:0.9738]\n",
      "Epoch25: 100%|██████████| 973/973 [00:40<00:00, 23.75it/s, loss:0.011, val-loss:0.074, val-roc:0.9784]\n",
      "Epoch26: 100%|██████████| 973/973 [00:40<00:00, 23.91it/s, loss:0.016, val-loss:0.062, val-roc:0.9778]\n",
      "Epoch27: 100%|██████████| 973/973 [00:40<00:00, 24.21it/s, loss:0.012, val-loss:0.070, val-roc:0.9795]\n",
      "Epoch28: 100%|██████████| 973/973 [00:40<00:00, 24.07it/s, loss:0.009, val-loss:0.063, val-roc:0.9812]\n",
      "Epoch29: 100%|██████████| 973/973 [00:40<00:00, 24.14it/s, loss:0.012, val-loss:0.088, val-roc:0.9706]\n",
      "Epoch30: 100%|██████████| 973/973 [00:40<00:00, 24.18it/s, loss:0.010, val-loss:0.084, val-roc:0.9750]\n",
      "Epoch31: 100%|██████████| 973/973 [00:40<00:00, 24.30it/s, loss:0.007, val-loss:0.074, val-roc:0.9758]\n",
      "Epoch32: 100%|██████████| 973/973 [00:39<00:00, 24.36it/s, loss:0.010, val-loss:0.082, val-roc:0.9719]\n",
      "Epoch33: 100%|██████████| 973/973 [00:40<00:00, 24.15it/s, loss:0.013, val-loss:0.061, val-roc:0.9789]\n",
      "Epoch34: 100%|██████████| 973/973 [00:41<00:00, 23.71it/s, loss:0.012, val-loss:0.079, val-roc:0.9780]\n",
      "Epoch35: 100%|██████████| 973/973 [00:40<00:00, 23.74it/s, loss:0.006, val-loss:0.061, val-roc:0.9791]\n",
      "Epoch36: 100%|██████████| 973/973 [00:40<00:00, 24.10it/s, loss:0.010, val-loss:0.066, val-roc:0.9763]\n",
      "Epoch37: 100%|██████████| 973/973 [00:39<00:00, 24.68it/s, loss:0.005, val-loss:0.061, val-roc:0.9788]\n",
      "Epoch38: 100%|██████████| 973/973 [00:39<00:00, 24.58it/s, loss:0.008, val-loss:0.061, val-roc:0.9779]\n",
      "Epoch39: 100%|██████████| 973/973 [00:39<00:00, 24.87it/s, loss:0.007, val-loss:0.060, val-roc:0.9788]\n",
      "Epoch40: 100%|██████████| 973/973 [00:39<00:00, 24.36it/s, loss:0.006, val-loss:0.065, val-roc:0.9758]\n"
     ]
    }
   ],
   "source": [
    "pos_weights = torch.ones(Config.num_class)\n",
    "counts = data_tp_df['species_id'].value_counts()\n",
    "for i in range(Config.num_class):\n",
    "    pos_weights[i] = (sum(counts)-counts[i])/counts[i]\n",
    "criterion = PANNsLoss().cuda()\n",
    "# loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weights).cuda()\n",
    "\n",
    "# def criterion(y_pred, y_target):\n",
    "#     loss = loss_function(y_pred, y_target.float())\n",
    "#     return loss\n",
    "\n",
    "model_name = 'SED_old_augment_RandomCrop_nomixup_attention_effb0'\n",
    "time_stamp = '{0:%m_%d_%H_%M}'.format(datetime.datetime.now())\n",
    "# time_stamp = '02_09_16_16'\n",
    "\n",
    "history = {\n",
    "    'config': Config,\n",
    "    'best_roc': [0]*len(data_folds),\n",
    "    'best_metrics': [0]*len(data_folds), \n",
    "    'best_model_path': [os.path.join(model_path, '{}_{}_fold_{}.pth'.format(model_name, time_stamp, i)) for i in range(len(data_folds))]\n",
    "}\n",
    "writer = SummaryWriter(log_dir=os.path.join(tensorboard_path, '{}_{}'.format(model_name, time_stamp)))\n",
    "for idx, (train_dataloader, val_dataloader) in enumerate(data_folds):\n",
    "    validate_points = list(np.linspace(0, len(train_dataloader)-1, 2).astype(int))[1:]\n",
    "    model = PANNsAtt().cuda()\n",
    "#     model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    epochs = 40\n",
    "    warmup_prob = 0.3\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, epochs=epochs, steps_per_epoch=len(train_dataloader), pct_start=warmup_prob, div_factor=25, anneal_strategy='cos', cycle_momentum=True)\n",
    "#     scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(warmup_prob*len(train_dataloader)*epochs), num_training_steps=len(train_dataloader)*epochs)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(model, train_dataloader, val_dataloader, criterion, optimizer, epoch, history, validate_points, scheduler,  writer, fold=idx, step=True)\n",
    "#         scheduler.step()\n",
    "        gc.collect()\n",
    "    torch.save(model.state_dict(), history['best_model_path'][idx])\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "with open(os.path.join(model_path, '{}_{}_history.pkl'.format(model_name, time_stamp)), 'wb') as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T09:48:23.143898Z",
     "start_time": "2021-02-03T09:48:23.132904Z"
    }
   },
   "source": [
    "## Predict Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T01:07:49.862974Z",
     "start_time": "2021-02-11T01:07:49.854942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SED_augment_RandomCrop_wavmixup_attention_effb4_02_10_14_20_history.pkl\n",
      "SED_old_augment_RandomCrop_specmixup_attention_effb4_02_10_14_26_history.pkl\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(model_path):\n",
    "    if file.endswith('.pkl'):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T04:48:50.146848Z",
     "start_time": "2021-02-11T04:48:48.830296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(model_path, 'SED_old_augment_RandomCrop_specmixup_attention_effb4_02_10_14_26_history.pkl'), 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "model = PANNsAtt().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:20:06.953283Z",
     "start_time": "2021-02-11T04:49:04.004518Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:34<00:00,  2.68s/it]\n",
      "100%|██████████| 125/125 [06:19<00:00,  3.04s/it]\n",
      "100%|██████████| 125/125 [06:23<00:00,  3.07s/it]\n",
      "100%|██████████| 125/125 [06:21<00:00,  3.05s/it]\n",
      "100%|██████████| 125/125 [06:23<00:00,  3.07s/it]\n"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "for path in history['best_model_path']:\n",
    "    model.load_state_dict(torch.load(path, map_location= torch.device('cpu')), strict=True)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            a, b, c, d, e = batch.size()\n",
    "            X = batch.view(a*b, c, d, e).cuda()\n",
    "            output = model(X, attn_mask=False)\n",
    "            pred = output['framewise_output'].view(a, b, -1, 24).max(dim=2)[0].max(dim=1)[0].cpu().detach().numpy()\n",
    "            preds.append(pred)\n",
    "    folds.append(np.concatenate(preds, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:20:06.984401Z",
     "start_time": "2021-02-11T05:20:06.955393Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(columns=['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'], dtype=np.float32)\n",
    "sub['recording_id'] = [file.split('.')[0] for file in test_files]\n",
    "sub.iloc[:, 1:] = sum(folds)/len(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:20:07.058028Z",
     "start_time": "2021-02-11T05:20:06.986509Z"
    }
   },
   "outputs": [],
   "source": [
    "time_stamp = '{0:%m_%d_%H_%M}'.format(datetime.datetime.now())\n",
    "sub.to_csv(os.path.join(res_path, 'submission_SED_old_augment_RandomCrop_nomixup_attention_effb0_{}.csv'.format(time_stamp)), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T04:47:56.635665Z",
     "start_time": "2021-02-11T04:47:56.626277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9816660798721708"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history['best_roc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T04:47:58.369981Z",
     "start_time": "2021-02-11T04:47:58.362042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908861891202932"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history['best_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T04:48:09.628596Z",
     "start_time": "2021-02-11T04:48:09.620267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': __main__.Config,\n",
       " 'best_roc': [0.9864938115119207,\n",
       "  0.9787321202163098,\n",
       "  0.9885835797106313,\n",
       "  0.978744022794933,\n",
       "  0.9757768651270599],\n",
       " 'best_metrics': [0.9281569809941521,\n",
       "  0.9017081054910002,\n",
       "  0.9224552562751576,\n",
       "  0.9021495016289289,\n",
       "  0.8898396116254209],\n",
       " 'best_model_path': ['/root/s/RFCX/model_save/SED_old_augment_RandomCrop_nomixup_attention_effb0_02_11_01_53_fold_0.pth',\n",
       "  '/root/s/RFCX/model_save/SED_old_augment_RandomCrop_nomixup_attention_effb0_02_11_01_53_fold_1.pth',\n",
       "  '/root/s/RFCX/model_save/SED_old_augment_RandomCrop_nomixup_attention_effb0_02_11_01_53_fold_2.pth',\n",
       "  '/root/s/RFCX/model_save/SED_old_augment_RandomCrop_nomixup_attention_effb0_02_11_01_53_fold_3.pth',\n",
       "  '/root/s/RFCX/model_save/SED_old_augment_RandomCrop_nomixup_attention_effb0_02_11_01_53_fold_4.pth']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
