{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 排序模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:38:31.820815Z",
     "start_time": "2021-01-14T14:38:31.806853Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc, os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取排序特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:38:32.358378Z",
     "start_time": "2021-01-14T14:38:32.347408Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = 'D:/Desktop/competition/news_article_rs/data/' # 天池平台路径\n",
    "save_path = 'D:/Desktop/competition/news_article_rs/res/'  # 天池平台路径\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:38:38.210732Z",
     "start_time": "2021-01-14T14:38:32.602725Z"
    }
   },
   "outputs": [],
   "source": [
    "# 重新读取数据的时候，发现click_article_id是一个浮点数，所以将其转换成int类型\n",
    "trn_user_item_feats_df = pd.read_csv(save_path + 'trn_user_item_feats_df.csv')\n",
    "trn_user_item_feats_df['click_article_id'] = trn_user_item_feats_df['click_article_id'].astype(int)\n",
    "val_user_item_feats_df = None\n",
    "    \n",
    "tst_user_item_feats_df = pd.read_csv(save_path + 'tst_user_item_feats_df.csv')\n",
    "tst_user_item_feats_df['click_article_id'] = tst_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "del tst_user_item_feats_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:38:38.225692Z",
     "start_time": "2021-01-14T14:38:38.211730Z"
    }
   },
   "outputs": [],
   "source": [
    "def submit(recall_df, topk=5, model_name=None):\n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 判断是不是每个用户都有5篇文章及以上\n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n",
    "    assert tmp.min() >= topk\n",
    "    \n",
    "    del recall_df['pred_score']\n",
    "    submit = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    \n",
    "    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n",
    "    # 按照提交格式定义列名\n",
    "    submit = submit.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', \n",
    "                                                  3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "    \n",
    "    save_name = save_path + model_name + '_' + datetime.today().strftime('%m-%d') + '.csv'\n",
    "    submit.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:38:38.241649Z",
     "start_time": "2021-01-14T14:38:38.226690Z"
    }
   },
   "outputs": [],
   "source": [
    "# 排序结果归一化\n",
    "def norm_sim(sim_df, weight=0.0):\n",
    "    # print(sim_df.head())\n",
    "    min_sim = sim_df.min()\n",
    "    max_sim = sim_df.max()\n",
    "    if max_sim == min_sim:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0)\n",
    "    else:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0 * (sim - min_sim) / (max_sim - min_sim))\n",
    "\n",
    "    sim_df = sim_df.apply(lambda sim: sim + weight)  # plus one\n",
    "    return sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB排序模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:38:38.318444Z",
     "start_time": "2021-01-14T14:38:38.242647Z"
    }
   },
   "outputs": [],
   "source": [
    "# 防止中间出错之后重新读取数据\n",
    "trn_user_item_feats_df_rank_model = trn_user_item_feats_df.copy()\n",
    "tst_user_item_feats_df_rank_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:38:38.334402Z",
     "start_time": "2021-01-14T14:38:38.320439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'click_article_id', 'sim0', 'time_diff0', 'word_diff0',\n",
       "       'sim_max', 'sim_min', 'sim_sum', 'sim_mean', 'score', 'rank', 'label',\n",
       "       'click_size', 'time_diff_mean_x', 'active_level', 'user_time_hob1',\n",
       "       'user_time_hob2', 'words_hbo', 'category_id', 'created_at_ts',\n",
       "       'words_count', 'user_num', 'time_diff_mean_y', 'hot_level',\n",
       "       'is_cat_hab'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df_rank_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:38:38.349361Z",
     "start_time": "2021-01-14T14:38:38.335399Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义特征列\n",
    "lgb_cols = ['sim0', 'time_diff0', 'word_diff0', 'sim_max', 'sim_min', 'sim_sum', 'sim_mean', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:38:38.486993Z",
     "start_time": "2021-01-14T14:38:38.350359Z"
    }
   },
   "outputs": [],
   "source": [
    "# 排序模型分组\n",
    "trn_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "g_train = trn_user_item_feats_df_rank_model.groupby(['user_id'], as_index=False).count()[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:38:59.163716Z",
     "start_time": "2021-01-14T14:38:38.487991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's ndcg@1: 0.99748\tvalid_0's ndcg@2: 0.99907\tvalid_0's ndcg@3: 0.99907\tvalid_0's ndcg@4: 0.99907\tvalid_0's ndcg@5: 0.99907\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.9979\tvalid_0's ndcg@2: 0.999225\tvalid_0's ndcg@3: 0.999225\tvalid_0's ndcg@4: 0.999225\tvalid_0's ndcg@5: 0.999225\n",
      "[3]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[4]\tvalid_0's ndcg@1: 0.999\tvalid_0's ndcg@2: 0.999631\tvalid_0's ndcg@3: 0.999631\tvalid_0's ndcg@4: 0.999631\tvalid_0's ndcg@5: 0.999631\n",
      "[5]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[6]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[7]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[8]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[9]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[10]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[11]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[12]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[13]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[14]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[15]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[16]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[17]\tvalid_0's ndcg@1: 0.99942\tvalid_0's ndcg@2: 0.999786\tvalid_0's ndcg@3: 0.999786\tvalid_0's ndcg@4: 0.999786\tvalid_0's ndcg@5: 0.999786\n",
      "[18]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[19]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[20]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[21]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[22]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[23]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[24]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[25]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[26]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[27]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[28]\tvalid_0's ndcg@1: 0.99932\tvalid_0's ndcg@2: 0.999749\tvalid_0's ndcg@3: 0.999749\tvalid_0's ndcg@4: 0.999749\tvalid_0's ndcg@5: 0.999749\n",
      "[29]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[30]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[31]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[32]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[33]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[34]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[35]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[36]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[37]\tvalid_0's ndcg@1: 0.99932\tvalid_0's ndcg@2: 0.999749\tvalid_0's ndcg@3: 0.999749\tvalid_0's ndcg@4: 0.999749\tvalid_0's ndcg@5: 0.999749\n",
      "[38]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[39]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[40]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[41]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[42]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[43]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[44]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[45]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[46]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[47]\tvalid_0's ndcg@1: 0.99932\tvalid_0's ndcg@2: 0.999749\tvalid_0's ndcg@3: 0.999749\tvalid_0's ndcg@4: 0.999749\tvalid_0's ndcg@5: 0.999749\n",
      "[48]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[49]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[50]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[51]\tvalid_0's ndcg@1: 0.99942\tvalid_0's ndcg@2: 0.999786\tvalid_0's ndcg@3: 0.999786\tvalid_0's ndcg@4: 0.999786\tvalid_0's ndcg@5: 0.999786\n",
      "[52]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[53]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[54]\tvalid_0's ndcg@1: 0.99942\tvalid_0's ndcg@2: 0.999786\tvalid_0's ndcg@3: 0.999786\tvalid_0's ndcg@4: 0.999786\tvalid_0's ndcg@5: 0.999786\n",
      "[55]\tvalid_0's ndcg@1: 0.99942\tvalid_0's ndcg@2: 0.999786\tvalid_0's ndcg@3: 0.999786\tvalid_0's ndcg@4: 0.999786\tvalid_0's ndcg@5: 0.999786\n",
      "[56]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[57]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[58]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[59]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[60]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[61]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[62]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[63]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[64]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[65]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[66]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[67]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[68]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[69]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[70]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[71]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[72]\tvalid_0's ndcg@1: 0.9994\tvalid_0's ndcg@2: 0.999779\tvalid_0's ndcg@3: 0.999779\tvalid_0's ndcg@4: 0.999779\tvalid_0's ndcg@5: 0.999779\n",
      "[73]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[74]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[75]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[76]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[77]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[78]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[79]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[80]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[81]\tvalid_0's ndcg@1: 0.99938\tvalid_0's ndcg@2: 0.999771\tvalid_0's ndcg@3: 0.999771\tvalid_0's ndcg@4: 0.999771\tvalid_0's ndcg@5: 0.999771\n",
      "[82]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[83]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[84]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[85]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[86]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[87]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[88]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[89]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[90]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[91]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[92]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[93]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[94]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[95]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[96]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[97]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[98]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[99]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[100]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[17]\tvalid_0's ndcg@1: 0.99942\tvalid_0's ndcg@2: 0.999786\tvalid_0's ndcg@3: 0.999786\tvalid_0's ndcg@4: 0.999786\tvalid_0's ndcg@5: 0.999786\n",
      "[1]\tvalid_0's ndcg@1: 0.9968\tvalid_0's ndcg@2: 0.998819\tvalid_0's ndcg@3: 0.998819\tvalid_0's ndcg@4: 0.998819\tvalid_0's ndcg@5: 0.998819\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.99712\tvalid_0's ndcg@2: 0.998937\tvalid_0's ndcg@3: 0.998937\tvalid_0's ndcg@4: 0.998937\tvalid_0's ndcg@5: 0.998937\n",
      "[3]\tvalid_0's ndcg@1: 0.99804\tvalid_0's ndcg@2: 0.999277\tvalid_0's ndcg@3: 0.999277\tvalid_0's ndcg@4: 0.999277\tvalid_0's ndcg@5: 0.999277\n",
      "[4]\tvalid_0's ndcg@1: 0.99826\tvalid_0's ndcg@2: 0.999358\tvalid_0's ndcg@3: 0.999358\tvalid_0's ndcg@4: 0.999358\tvalid_0's ndcg@5: 0.999358\n",
      "[5]\tvalid_0's ndcg@1: 0.99856\tvalid_0's ndcg@2: 0.999469\tvalid_0's ndcg@3: 0.999469\tvalid_0's ndcg@4: 0.999469\tvalid_0's ndcg@5: 0.999469\n",
      "[6]\tvalid_0's ndcg@1: 0.9986\tvalid_0's ndcg@2: 0.999483\tvalid_0's ndcg@3: 0.999483\tvalid_0's ndcg@4: 0.999483\tvalid_0's ndcg@5: 0.999483\n",
      "[7]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[8]\tvalid_0's ndcg@1: 0.9989\tvalid_0's ndcg@2: 0.999594\tvalid_0's ndcg@3: 0.999594\tvalid_0's ndcg@4: 0.999594\tvalid_0's ndcg@5: 0.999594\n",
      "[9]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[10]\tvalid_0's ndcg@1: 0.9989\tvalid_0's ndcg@2: 0.999594\tvalid_0's ndcg@3: 0.999594\tvalid_0's ndcg@4: 0.999594\tvalid_0's ndcg@5: 0.999594\n",
      "[11]\tvalid_0's ndcg@1: 0.99888\tvalid_0's ndcg@2: 0.999587\tvalid_0's ndcg@3: 0.999587\tvalid_0's ndcg@4: 0.999587\tvalid_0's ndcg@5: 0.999587\n",
      "[12]\tvalid_0's ndcg@1: 0.9988\tvalid_0's ndcg@2: 0.999557\tvalid_0's ndcg@3: 0.999557\tvalid_0's ndcg@4: 0.999557\tvalid_0's ndcg@5: 0.999557\n",
      "[13]\tvalid_0's ndcg@1: 0.9988\tvalid_0's ndcg@2: 0.999557\tvalid_0's ndcg@3: 0.999557\tvalid_0's ndcg@4: 0.999557\tvalid_0's ndcg@5: 0.999557\n",
      "[14]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[15]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\tvalid_0's ndcg@1: 0.99874\tvalid_0's ndcg@2: 0.999535\tvalid_0's ndcg@3: 0.999535\tvalid_0's ndcg@4: 0.999535\tvalid_0's ndcg@5: 0.999535\n",
      "[17]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[18]\tvalid_0's ndcg@1: 0.99876\tvalid_0's ndcg@2: 0.999542\tvalid_0's ndcg@3: 0.999542\tvalid_0's ndcg@4: 0.999542\tvalid_0's ndcg@5: 0.999542\n",
      "[19]\tvalid_0's ndcg@1: 0.9988\tvalid_0's ndcg@2: 0.999557\tvalid_0's ndcg@3: 0.999557\tvalid_0's ndcg@4: 0.999557\tvalid_0's ndcg@5: 0.999557\n",
      "[20]\tvalid_0's ndcg@1: 0.9988\tvalid_0's ndcg@2: 0.999557\tvalid_0's ndcg@3: 0.999557\tvalid_0's ndcg@4: 0.999557\tvalid_0's ndcg@5: 0.999557\n",
      "[21]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[22]\tvalid_0's ndcg@1: 0.99876\tvalid_0's ndcg@2: 0.999542\tvalid_0's ndcg@3: 0.999542\tvalid_0's ndcg@4: 0.999542\tvalid_0's ndcg@5: 0.999542\n",
      "[23]\tvalid_0's ndcg@1: 0.99874\tvalid_0's ndcg@2: 0.999535\tvalid_0's ndcg@3: 0.999535\tvalid_0's ndcg@4: 0.999535\tvalid_0's ndcg@5: 0.999535\n",
      "[24]\tvalid_0's ndcg@1: 0.99868\tvalid_0's ndcg@2: 0.999513\tvalid_0's ndcg@3: 0.999513\tvalid_0's ndcg@4: 0.999513\tvalid_0's ndcg@5: 0.999513\n",
      "[25]\tvalid_0's ndcg@1: 0.9987\tvalid_0's ndcg@2: 0.99952\tvalid_0's ndcg@3: 0.99952\tvalid_0's ndcg@4: 0.99952\tvalid_0's ndcg@5: 0.99952\n",
      "[26]\tvalid_0's ndcg@1: 0.9987\tvalid_0's ndcg@2: 0.99952\tvalid_0's ndcg@3: 0.99952\tvalid_0's ndcg@4: 0.99952\tvalid_0's ndcg@5: 0.99952\n",
      "[27]\tvalid_0's ndcg@1: 0.99864\tvalid_0's ndcg@2: 0.999498\tvalid_0's ndcg@3: 0.999498\tvalid_0's ndcg@4: 0.999498\tvalid_0's ndcg@5: 0.999498\n",
      "[28]\tvalid_0's ndcg@1: 0.99872\tvalid_0's ndcg@2: 0.999528\tvalid_0's ndcg@3: 0.999528\tvalid_0's ndcg@4: 0.999528\tvalid_0's ndcg@5: 0.999528\n",
      "[29]\tvalid_0's ndcg@1: 0.99874\tvalid_0's ndcg@2: 0.999535\tvalid_0's ndcg@3: 0.999535\tvalid_0's ndcg@4: 0.999535\tvalid_0's ndcg@5: 0.999535\n",
      "[30]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[31]\tvalid_0's ndcg@1: 0.99876\tvalid_0's ndcg@2: 0.999542\tvalid_0's ndcg@3: 0.999542\tvalid_0's ndcg@4: 0.999542\tvalid_0's ndcg@5: 0.999542\n",
      "[32]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[33]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[34]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[35]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[36]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[37]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[38]\tvalid_0's ndcg@1: 0.9988\tvalid_0's ndcg@2: 0.999557\tvalid_0's ndcg@3: 0.999557\tvalid_0's ndcg@4: 0.999557\tvalid_0's ndcg@5: 0.999557\n",
      "[39]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[40]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[41]\tvalid_0's ndcg@1: 0.9988\tvalid_0's ndcg@2: 0.999557\tvalid_0's ndcg@3: 0.999557\tvalid_0's ndcg@4: 0.999557\tvalid_0's ndcg@5: 0.999557\n",
      "[42]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[43]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[44]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[45]\tvalid_0's ndcg@1: 0.99876\tvalid_0's ndcg@2: 0.999542\tvalid_0's ndcg@3: 0.999542\tvalid_0's ndcg@4: 0.999542\tvalid_0's ndcg@5: 0.999542\n",
      "[46]\tvalid_0's ndcg@1: 0.99874\tvalid_0's ndcg@2: 0.999535\tvalid_0's ndcg@3: 0.999535\tvalid_0's ndcg@4: 0.999535\tvalid_0's ndcg@5: 0.999535\n",
      "[47]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[48]\tvalid_0's ndcg@1: 0.99876\tvalid_0's ndcg@2: 0.999542\tvalid_0's ndcg@3: 0.999542\tvalid_0's ndcg@4: 0.999542\tvalid_0's ndcg@5: 0.999542\n",
      "[49]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[50]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[51]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[52]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[53]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[54]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[55]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[56]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[57]\tvalid_0's ndcg@1: 0.99888\tvalid_0's ndcg@2: 0.999587\tvalid_0's ndcg@3: 0.999587\tvalid_0's ndcg@4: 0.999587\tvalid_0's ndcg@5: 0.999587\n",
      "[58]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[59]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[60]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[61]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[62]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[63]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[64]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[65]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[66]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[67]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[68]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[69]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[70]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[71]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[72]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[73]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[74]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[75]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[76]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[77]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[78]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[79]\tvalid_0's ndcg@1: 0.9988\tvalid_0's ndcg@2: 0.999557\tvalid_0's ndcg@3: 0.999557\tvalid_0's ndcg@4: 0.999557\tvalid_0's ndcg@5: 0.999557\n",
      "[80]\tvalid_0's ndcg@1: 0.9988\tvalid_0's ndcg@2: 0.999557\tvalid_0's ndcg@3: 0.999557\tvalid_0's ndcg@4: 0.999557\tvalid_0's ndcg@5: 0.999557\n",
      "[81]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[82]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[83]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[84]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[85]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[86]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[87]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[88]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[89]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[90]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[91]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[92]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[93]\tvalid_0's ndcg@1: 0.9989\tvalid_0's ndcg@2: 0.999594\tvalid_0's ndcg@3: 0.999594\tvalid_0's ndcg@4: 0.999594\tvalid_0's ndcg@5: 0.999594\n",
      "[94]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[95]\tvalid_0's ndcg@1: 0.99886\tvalid_0's ndcg@2: 0.999579\tvalid_0's ndcg@3: 0.999579\tvalid_0's ndcg@4: 0.999579\tvalid_0's ndcg@5: 0.999579\n",
      "[96]\tvalid_0's ndcg@1: 0.99888\tvalid_0's ndcg@2: 0.999587\tvalid_0's ndcg@3: 0.999587\tvalid_0's ndcg@4: 0.999587\tvalid_0's ndcg@5: 0.999587\n",
      "[97]\tvalid_0's ndcg@1: 0.9989\tvalid_0's ndcg@2: 0.999594\tvalid_0's ndcg@3: 0.999594\tvalid_0's ndcg@4: 0.999594\tvalid_0's ndcg@5: 0.999594\n",
      "[98]\tvalid_0's ndcg@1: 0.99888\tvalid_0's ndcg@2: 0.999587\tvalid_0's ndcg@3: 0.999587\tvalid_0's ndcg@4: 0.999587\tvalid_0's ndcg@5: 0.999587\n",
      "[99]\tvalid_0's ndcg@1: 0.99888\tvalid_0's ndcg@2: 0.999587\tvalid_0's ndcg@3: 0.999587\tvalid_0's ndcg@4: 0.999587\tvalid_0's ndcg@5: 0.999587\n",
      "[100]\tvalid_0's ndcg@1: 0.99888\tvalid_0's ndcg@2: 0.999587\tvalid_0's ndcg@3: 0.999587\tvalid_0's ndcg@4: 0.999587\tvalid_0's ndcg@5: 0.999587\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[8]\tvalid_0's ndcg@1: 0.9989\tvalid_0's ndcg@2: 0.999594\tvalid_0's ndcg@3: 0.999594\tvalid_0's ndcg@4: 0.999594\tvalid_0's ndcg@5: 0.999594\n",
      "[1]\tvalid_0's ndcg@1: 0.9975\tvalid_0's ndcg@2: 0.999077\tvalid_0's ndcg@3: 0.999077\tvalid_0's ndcg@4: 0.999077\tvalid_0's ndcg@5: 0.999077\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.99818\tvalid_0's ndcg@2: 0.999328\tvalid_0's ndcg@3: 0.999328\tvalid_0's ndcg@4: 0.999328\tvalid_0's ndcg@5: 0.999328\n",
      "[3]\tvalid_0's ndcg@1: 0.99864\tvalid_0's ndcg@2: 0.999498\tvalid_0's ndcg@3: 0.999498\tvalid_0's ndcg@4: 0.999498\tvalid_0's ndcg@5: 0.999498\n",
      "[4]\tvalid_0's ndcg@1: 0.99868\tvalid_0's ndcg@2: 0.999513\tvalid_0's ndcg@3: 0.999513\tvalid_0's ndcg@4: 0.999513\tvalid_0's ndcg@5: 0.999513\n",
      "[5]\tvalid_0's ndcg@1: 0.9989\tvalid_0's ndcg@2: 0.999594\tvalid_0's ndcg@3: 0.999594\tvalid_0's ndcg@4: 0.999594\tvalid_0's ndcg@5: 0.999594\n",
      "[6]\tvalid_0's ndcg@1: 0.99888\tvalid_0's ndcg@2: 0.999587\tvalid_0's ndcg@3: 0.999587\tvalid_0's ndcg@4: 0.999587\tvalid_0's ndcg@5: 0.999587\n",
      "[7]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[8]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[9]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[10]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[11]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[12]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[13]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[14]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[15]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[16]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[17]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[18]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[19]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[20]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[21]\tvalid_0's ndcg@1: 0.99918\tvalid_0's ndcg@2: 0.999697\tvalid_0's ndcg@3: 0.999697\tvalid_0's ndcg@4: 0.999697\tvalid_0's ndcg@5: 0.999697\n",
      "[22]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[23]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[24]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[25]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[26]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[27]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[28]\tvalid_0's ndcg@1: 0.99918\tvalid_0's ndcg@2: 0.999697\tvalid_0's ndcg@3: 0.999697\tvalid_0's ndcg@4: 0.999697\tvalid_0's ndcg@5: 0.999697\n",
      "[29]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[30]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[31]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32]\tvalid_0's ndcg@1: 0.99918\tvalid_0's ndcg@2: 0.999697\tvalid_0's ndcg@3: 0.999697\tvalid_0's ndcg@4: 0.999697\tvalid_0's ndcg@5: 0.999697\n",
      "[33]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[34]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[35]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[36]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[37]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[38]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[39]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[40]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[41]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[42]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[43]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[44]\tvalid_0's ndcg@1: 0.99918\tvalid_0's ndcg@2: 0.999697\tvalid_0's ndcg@3: 0.999697\tvalid_0's ndcg@4: 0.999697\tvalid_0's ndcg@5: 0.999697\n",
      "[45]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[46]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[47]\tvalid_0's ndcg@1: 0.99918\tvalid_0's ndcg@2: 0.999697\tvalid_0's ndcg@3: 0.999697\tvalid_0's ndcg@4: 0.999697\tvalid_0's ndcg@5: 0.999697\n",
      "[48]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[49]\tvalid_0's ndcg@1: 0.99918\tvalid_0's ndcg@2: 0.999697\tvalid_0's ndcg@3: 0.999697\tvalid_0's ndcg@4: 0.999697\tvalid_0's ndcg@5: 0.999697\n",
      "[50]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[51]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[52]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[53]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[54]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[55]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[56]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[57]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[58]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[59]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[60]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[61]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[62]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[63]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[64]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[65]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[66]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[67]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[68]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[69]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[70]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[71]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[72]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[73]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[74]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[75]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[76]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[77]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[78]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[79]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[80]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[81]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[82]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[83]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[84]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[85]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[86]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[87]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[88]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[89]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[90]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[91]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[92]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[93]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[94]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[95]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[96]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[97]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[98]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[99]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[100]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[64]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[1]\tvalid_0's ndcg@1: 0.99752\tvalid_0's ndcg@2: 0.999085\tvalid_0's ndcg@3: 0.999085\tvalid_0's ndcg@4: 0.999085\tvalid_0's ndcg@5: 0.999085\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.99806\tvalid_0's ndcg@2: 0.999284\tvalid_0's ndcg@3: 0.999284\tvalid_0's ndcg@4: 0.999284\tvalid_0's ndcg@5: 0.999284\n",
      "[3]\tvalid_0's ndcg@1: 0.99866\tvalid_0's ndcg@2: 0.999505\tvalid_0's ndcg@3: 0.999505\tvalid_0's ndcg@4: 0.999505\tvalid_0's ndcg@5: 0.999505\n",
      "[4]\tvalid_0's ndcg@1: 0.9987\tvalid_0's ndcg@2: 0.99952\tvalid_0's ndcg@3: 0.99952\tvalid_0's ndcg@4: 0.99952\tvalid_0's ndcg@5: 0.99952\n",
      "[5]\tvalid_0's ndcg@1: 0.99882\tvalid_0's ndcg@2: 0.999564\tvalid_0's ndcg@3: 0.999564\tvalid_0's ndcg@4: 0.999564\tvalid_0's ndcg@5: 0.999564\n",
      "[6]\tvalid_0's ndcg@1: 0.999\tvalid_0's ndcg@2: 0.999631\tvalid_0's ndcg@3: 0.999631\tvalid_0's ndcg@4: 0.999631\tvalid_0's ndcg@5: 0.999631\n",
      "[7]\tvalid_0's ndcg@1: 0.99898\tvalid_0's ndcg@2: 0.999624\tvalid_0's ndcg@3: 0.999624\tvalid_0's ndcg@4: 0.999624\tvalid_0's ndcg@5: 0.999624\n",
      "[8]\tvalid_0's ndcg@1: 0.99904\tvalid_0's ndcg@2: 0.999646\tvalid_0's ndcg@3: 0.999646\tvalid_0's ndcg@4: 0.999646\tvalid_0's ndcg@5: 0.999646\n",
      "[9]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[10]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[11]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[12]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[13]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[14]\tvalid_0's ndcg@1: 0.99918\tvalid_0's ndcg@2: 0.999697\tvalid_0's ndcg@3: 0.999697\tvalid_0's ndcg@4: 0.999697\tvalid_0's ndcg@5: 0.999697\n",
      "[15]\tvalid_0's ndcg@1: 0.99918\tvalid_0's ndcg@2: 0.999697\tvalid_0's ndcg@3: 0.999697\tvalid_0's ndcg@4: 0.999697\tvalid_0's ndcg@5: 0.999697\n",
      "[16]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[17]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[18]\tvalid_0's ndcg@1: 0.99918\tvalid_0's ndcg@2: 0.999697\tvalid_0's ndcg@3: 0.999697\tvalid_0's ndcg@4: 0.999697\tvalid_0's ndcg@5: 0.999697\n",
      "[19]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[20]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[21]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[22]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[23]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[24]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[25]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[26]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[27]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[28]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[29]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[30]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[31]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[32]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[33]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[34]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[35]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[36]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[37]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[38]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[39]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[40]\tvalid_0's ndcg@1: 0.99932\tvalid_0's ndcg@2: 0.999749\tvalid_0's ndcg@3: 0.999749\tvalid_0's ndcg@4: 0.999749\tvalid_0's ndcg@5: 0.999749\n",
      "[41]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[42]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[43]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[44]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[45]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[46]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[47]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[49]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[50]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[51]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[52]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[53]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[54]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[55]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[56]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[57]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[58]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[59]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[60]\tvalid_0's ndcg@1: 0.9992\tvalid_0's ndcg@2: 0.999705\tvalid_0's ndcg@3: 0.999705\tvalid_0's ndcg@4: 0.999705\tvalid_0's ndcg@5: 0.999705\n",
      "[61]\tvalid_0's ndcg@1: 0.99918\tvalid_0's ndcg@2: 0.999697\tvalid_0's ndcg@3: 0.999697\tvalid_0's ndcg@4: 0.999697\tvalid_0's ndcg@5: 0.999697\n",
      "[62]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[63]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[64]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[65]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[66]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[67]\tvalid_0's ndcg@1: 0.99922\tvalid_0's ndcg@2: 0.999712\tvalid_0's ndcg@3: 0.999712\tvalid_0's ndcg@4: 0.999712\tvalid_0's ndcg@5: 0.999712\n",
      "[68]\tvalid_0's ndcg@1: 0.99924\tvalid_0's ndcg@2: 0.99972\tvalid_0's ndcg@3: 0.99972\tvalid_0's ndcg@4: 0.99972\tvalid_0's ndcg@5: 0.99972\n",
      "[69]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[70]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[71]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[72]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[73]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[74]\tvalid_0's ndcg@1: 0.99926\tvalid_0's ndcg@2: 0.999727\tvalid_0's ndcg@3: 0.999727\tvalid_0's ndcg@4: 0.999727\tvalid_0's ndcg@5: 0.999727\n",
      "[75]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[76]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[77]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[78]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[79]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[80]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[81]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[82]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[83]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[84]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[85]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[86]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[87]\tvalid_0's ndcg@1: 0.99928\tvalid_0's ndcg@2: 0.999734\tvalid_0's ndcg@3: 0.999734\tvalid_0's ndcg@4: 0.999734\tvalid_0's ndcg@5: 0.999734\n",
      "[88]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "[89]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[90]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[91]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[92]\tvalid_0's ndcg@1: 0.99932\tvalid_0's ndcg@2: 0.999749\tvalid_0's ndcg@3: 0.999749\tvalid_0's ndcg@4: 0.999749\tvalid_0's ndcg@5: 0.999749\n",
      "[93]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[94]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[95]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[96]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[97]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[98]\tvalid_0's ndcg@1: 0.99934\tvalid_0's ndcg@2: 0.999756\tvalid_0's ndcg@3: 0.999756\tvalid_0's ndcg@4: 0.999756\tvalid_0's ndcg@5: 0.999756\n",
      "[99]\tvalid_0's ndcg@1: 0.99932\tvalid_0's ndcg@2: 0.999749\tvalid_0's ndcg@3: 0.999749\tvalid_0's ndcg@4: 0.999749\tvalid_0's ndcg@5: 0.999749\n",
      "[100]\tvalid_0's ndcg@1: 0.9993\tvalid_0's ndcg@2: 0.999742\tvalid_0's ndcg@3: 0.999742\tvalid_0's ndcg@4: 0.999742\tvalid_0's ndcg@5: 0.999742\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\tvalid_0's ndcg@1: 0.99936\tvalid_0's ndcg@2: 0.999764\tvalid_0's ndcg@3: 0.999764\tvalid_0's ndcg@4: 0.999764\tvalid_0's ndcg@5: 0.999764\n",
      "[1]\tvalid_0's ndcg@1: 0.99746\tvalid_0's ndcg@2: 0.99905\tvalid_0's ndcg@3: 0.99906\tvalid_0's ndcg@4: 0.99906\tvalid_0's ndcg@5: 0.99906\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.99796\tvalid_0's ndcg@2: 0.999234\tvalid_0's ndcg@3: 0.999244\tvalid_0's ndcg@4: 0.999244\tvalid_0's ndcg@5: 0.999244\n",
      "[3]\tvalid_0's ndcg@1: 0.99844\tvalid_0's ndcg@2: 0.999412\tvalid_0's ndcg@3: 0.999422\tvalid_0's ndcg@4: 0.999422\tvalid_0's ndcg@5: 0.999422\n",
      "[4]\tvalid_0's ndcg@1: 0.99858\tvalid_0's ndcg@2: 0.999476\tvalid_0's ndcg@3: 0.999476\tvalid_0's ndcg@4: 0.999476\tvalid_0's ndcg@5: 0.999476\n",
      "[5]\tvalid_0's ndcg@1: 0.99864\tvalid_0's ndcg@2: 0.999498\tvalid_0's ndcg@3: 0.999498\tvalid_0's ndcg@4: 0.999498\tvalid_0's ndcg@5: 0.999498\n",
      "[6]\tvalid_0's ndcg@1: 0.99858\tvalid_0's ndcg@2: 0.999476\tvalid_0's ndcg@3: 0.999476\tvalid_0's ndcg@4: 0.999476\tvalid_0's ndcg@5: 0.999476\n",
      "[7]\tvalid_0's ndcg@1: 0.99868\tvalid_0's ndcg@2: 0.999513\tvalid_0's ndcg@3: 0.999513\tvalid_0's ndcg@4: 0.999513\tvalid_0's ndcg@5: 0.999513\n",
      "[8]\tvalid_0's ndcg@1: 0.99878\tvalid_0's ndcg@2: 0.99955\tvalid_0's ndcg@3: 0.99955\tvalid_0's ndcg@4: 0.99955\tvalid_0's ndcg@5: 0.99955\n",
      "[9]\tvalid_0's ndcg@1: 0.9988\tvalid_0's ndcg@2: 0.999557\tvalid_0's ndcg@3: 0.999557\tvalid_0's ndcg@4: 0.999557\tvalid_0's ndcg@5: 0.999557\n",
      "[10]\tvalid_0's ndcg@1: 0.99884\tvalid_0's ndcg@2: 0.999572\tvalid_0's ndcg@3: 0.999572\tvalid_0's ndcg@4: 0.999572\tvalid_0's ndcg@5: 0.999572\n",
      "[11]\tvalid_0's ndcg@1: 0.9989\tvalid_0's ndcg@2: 0.999594\tvalid_0's ndcg@3: 0.999594\tvalid_0's ndcg@4: 0.999594\tvalid_0's ndcg@5: 0.999594\n",
      "[12]\tvalid_0's ndcg@1: 0.99892\tvalid_0's ndcg@2: 0.999601\tvalid_0's ndcg@3: 0.999601\tvalid_0's ndcg@4: 0.999601\tvalid_0's ndcg@5: 0.999601\n",
      "[13]\tvalid_0's ndcg@1: 0.99896\tvalid_0's ndcg@2: 0.999616\tvalid_0's ndcg@3: 0.999616\tvalid_0's ndcg@4: 0.999616\tvalid_0's ndcg@5: 0.999616\n",
      "[14]\tvalid_0's ndcg@1: 0.99902\tvalid_0's ndcg@2: 0.999638\tvalid_0's ndcg@3: 0.999638\tvalid_0's ndcg@4: 0.999638\tvalid_0's ndcg@5: 0.999638\n",
      "[15]\tvalid_0's ndcg@1: 0.99902\tvalid_0's ndcg@2: 0.999638\tvalid_0's ndcg@3: 0.999638\tvalid_0's ndcg@4: 0.999638\tvalid_0's ndcg@5: 0.999638\n",
      "[16]\tvalid_0's ndcg@1: 0.99898\tvalid_0's ndcg@2: 0.999624\tvalid_0's ndcg@3: 0.999624\tvalid_0's ndcg@4: 0.999624\tvalid_0's ndcg@5: 0.999624\n",
      "[17]\tvalid_0's ndcg@1: 0.99896\tvalid_0's ndcg@2: 0.999616\tvalid_0's ndcg@3: 0.999616\tvalid_0's ndcg@4: 0.999616\tvalid_0's ndcg@5: 0.999616\n",
      "[18]\tvalid_0's ndcg@1: 0.99898\tvalid_0's ndcg@2: 0.999624\tvalid_0's ndcg@3: 0.999624\tvalid_0's ndcg@4: 0.999624\tvalid_0's ndcg@5: 0.999624\n",
      "[19]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[20]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[21]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[22]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[23]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[24]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[25]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[26]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[27]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[28]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[29]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[30]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[31]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[32]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[33]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n",
      "[34]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[35]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[36]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[37]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[38]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n",
      "[39]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[40]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[41]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[42]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[43]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[44]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[45]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[46]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[47]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[48]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[49]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[50]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[51]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[52]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[53]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[54]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[55]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[56]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[57]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n",
      "[58]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[59]\tvalid_0's ndcg@1: 0.9991\tvalid_0's ndcg@2: 0.999668\tvalid_0's ndcg@3: 0.999668\tvalid_0's ndcg@4: 0.999668\tvalid_0's ndcg@5: 0.999668\n",
      "[60]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n",
      "[61]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[62]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n",
      "[63]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[65]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[66]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n",
      "[67]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[68]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n",
      "[69]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n",
      "[70]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[71]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[72]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n",
      "[73]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n",
      "[74]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[75]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[76]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[77]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[78]\tvalid_0's ndcg@1: 0.99904\tvalid_0's ndcg@2: 0.999646\tvalid_0's ndcg@3: 0.999646\tvalid_0's ndcg@4: 0.999646\tvalid_0's ndcg@5: 0.999646\n",
      "[79]\tvalid_0's ndcg@1: 0.99904\tvalid_0's ndcg@2: 0.999646\tvalid_0's ndcg@3: 0.999646\tvalid_0's ndcg@4: 0.999646\tvalid_0's ndcg@5: 0.999646\n",
      "[80]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n",
      "[81]\tvalid_0's ndcg@1: 0.99906\tvalid_0's ndcg@2: 0.999653\tvalid_0's ndcg@3: 0.999653\tvalid_0's ndcg@4: 0.999653\tvalid_0's ndcg@5: 0.999653\n",
      "[82]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[83]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[84]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[85]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[86]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[87]\tvalid_0's ndcg@1: 0.99908\tvalid_0's ndcg@2: 0.99966\tvalid_0's ndcg@3: 0.99966\tvalid_0's ndcg@4: 0.99966\tvalid_0's ndcg@5: 0.99966\n",
      "[88]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[89]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[90]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[91]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[92]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[93]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[94]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[95]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[96]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[97]\tvalid_0's ndcg@1: 0.99912\tvalid_0's ndcg@2: 0.999675\tvalid_0's ndcg@3: 0.999675\tvalid_0's ndcg@4: 0.999675\tvalid_0's ndcg@5: 0.999675\n",
      "[98]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[99]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "[100]\tvalid_0's ndcg@1: 0.99914\tvalid_0's ndcg@2: 0.999683\tvalid_0's ndcg@3: 0.999683\tvalid_0's ndcg@4: 0.999683\tvalid_0's ndcg@5: 0.999683\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[34]\tvalid_0's ndcg@1: 0.99916\tvalid_0's ndcg@2: 0.99969\tvalid_0's ndcg@3: 0.99969\tvalid_0's ndcg@4: 0.99969\tvalid_0's ndcg@5: 0.99969\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "offline = False\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id','label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 训练集与验证集的用户分组\n",
    "    train_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_train = train_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_val = valid_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    \n",
    "    # 定义模型\n",
    "    lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16)  \n",
    "    # 训练模型\n",
    "    lgb_ranker.fit(train_idx[lgb_cols], train_idx['label'], group=g_train,\n",
    "                   eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], eval_group= [g_val], \n",
    "                   eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=100, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_ranker.predict(valid_idx[lgb_cols], num_iteration=lgb_ranker.best_iteration_)\n",
    "    \n",
    "    # 对输出结果进行归一化\n",
    "    valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += lgb_ranker.predict(tst_user_item_feats_df_rank_model[lgb_cols], lgb_ranker.best_iteration_)\n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_ranker_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_ranker_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:39:02.572603Z",
     "start_time": "2021-01-14T14:38:59.164714Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "# 单模型生成提交结果\n",
    "rank_results = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_ranker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:39:26.023908Z",
     "start_time": "2021-01-14T14:39:02.573600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15305, number of negative: 226124\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.010450\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000018 seconds, init for row-wise cost 0.007106 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 4854\n",
      "[LightGBM] [Info] Number of data points in the train set: 241429, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.063393 -> initscore=-2.692904\n",
      "[LightGBM] [Info] Start training from score -2.692904\n",
      "[LightGBM] [Debug] Re-bagging, using 169126 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 10\n",
      "[1]\tvalid_0's auc: 0.993437\tvalid_0's binary_logloss: 0.227376\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 168785 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 12\n",
      "[2]\tvalid_0's auc: 0.992934\tvalid_0's binary_logloss: 0.221395\n",
      "[LightGBM] [Debug] Re-bagging, using 168698 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 12\n",
      "[3]\tvalid_0's auc: 0.994537\tvalid_0's binary_logloss: 0.216022\n",
      "[LightGBM] [Debug] Re-bagging, using 168804 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 10\n",
      "[4]\tvalid_0's auc: 0.994467\tvalid_0's binary_logloss: 0.210892\n",
      "[LightGBM] [Debug] Re-bagging, using 168819 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and max_depth = 9\n",
      "[5]\tvalid_0's auc: 0.994348\tvalid_0's binary_logloss: 0.206282\n",
      "[LightGBM] [Debug] Re-bagging, using 169508 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[6]\tvalid_0's auc: 0.994273\tvalid_0's binary_logloss: 0.202094\n",
      "[LightGBM] [Debug] Re-bagging, using 168859 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and max_depth = 12\n",
      "[7]\tvalid_0's auc: 0.99477\tvalid_0's binary_logloss: 0.197858\n",
      "[LightGBM] [Debug] Re-bagging, using 169252 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[8]\tvalid_0's auc: 0.995222\tvalid_0's binary_logloss: 0.19399\n",
      "[LightGBM] [Debug] Re-bagging, using 169157 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and max_depth = 9\n",
      "[9]\tvalid_0's auc: 0.99532\tvalid_0's binary_logloss: 0.190235\n",
      "[LightGBM] [Debug] Re-bagging, using 168992 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 8\n",
      "[10]\tvalid_0's auc: 0.995335\tvalid_0's binary_logloss: 0.186717\n",
      "[LightGBM] [Debug] Re-bagging, using 168796 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and max_depth = 9\n",
      "[11]\tvalid_0's auc: 0.995386\tvalid_0's binary_logloss: 0.183272\n",
      "[LightGBM] [Debug] Re-bagging, using 169182 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and max_depth = 8\n",
      "[12]\tvalid_0's auc: 0.995398\tvalid_0's binary_logloss: 0.180109\n",
      "[LightGBM] [Debug] Re-bagging, using 169257 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[13]\tvalid_0's auc: 0.995368\tvalid_0's binary_logloss: 0.177289\n",
      "[LightGBM] [Debug] Re-bagging, using 168980 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[14]\tvalid_0's auc: 0.995392\tvalid_0's binary_logloss: 0.174663\n",
      "[LightGBM] [Debug] Re-bagging, using 168770 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[15]\tvalid_0's auc: 0.995381\tvalid_0's binary_logloss: 0.172103\n",
      "[LightGBM] [Debug] Re-bagging, using 169335 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and max_depth = 9\n",
      "[16]\tvalid_0's auc: 0.995393\tvalid_0's binary_logloss: 0.169433\n",
      "[LightGBM] [Debug] Re-bagging, using 168997 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[17]\tvalid_0's auc: 0.995657\tvalid_0's binary_logloss: 0.166893\n",
      "[LightGBM] [Debug] Re-bagging, using 169189 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[18]\tvalid_0's auc: 0.995799\tvalid_0's binary_logloss: 0.16465\n",
      "[LightGBM] [Debug] Re-bagging, using 169026 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[19]\tvalid_0's auc: 0.995862\tvalid_0's binary_logloss: 0.162414\n",
      "[LightGBM] [Debug] Re-bagging, using 169103 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and max_depth = 8\n",
      "[20]\tvalid_0's auc: 0.995856\tvalid_0's binary_logloss: 0.160103\n",
      "[LightGBM] [Debug] Re-bagging, using 168646 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and max_depth = 10\n",
      "[21]\tvalid_0's auc: 0.995869\tvalid_0's binary_logloss: 0.157854\n",
      "[LightGBM] [Debug] Re-bagging, using 168847 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[22]\tvalid_0's auc: 0.99593\tvalid_0's binary_logloss: 0.155818\n",
      "[LightGBM] [Debug] Re-bagging, using 168800 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[23]\tvalid_0's auc: 0.995995\tvalid_0's binary_logloss: 0.153798\n",
      "[LightGBM] [Debug] Re-bagging, using 169625 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[24]\tvalid_0's auc: 0.996069\tvalid_0's binary_logloss: 0.151878\n",
      "[LightGBM] [Debug] Re-bagging, using 169077 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 9\n",
      "[25]\tvalid_0's auc: 0.996081\tvalid_0's binary_logloss: 0.149887\n",
      "[LightGBM] [Debug] Re-bagging, using 169388 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[26]\tvalid_0's auc: 0.996101\tvalid_0's binary_logloss: 0.147925\n",
      "[LightGBM] [Debug] Re-bagging, using 169097 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 9\n",
      "[27]\tvalid_0's auc: 0.996136\tvalid_0's binary_logloss: 0.146012\n",
      "[LightGBM] [Debug] Re-bagging, using 168605 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[28]\tvalid_0's auc: 0.996186\tvalid_0's binary_logloss: 0.144201\n",
      "[LightGBM] [Debug] Re-bagging, using 168760 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[29]\tvalid_0's auc: 0.996195\tvalid_0's binary_logloss: 0.14242\n",
      "[LightGBM] [Debug] Re-bagging, using 169122 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[30]\tvalid_0's auc: 0.996262\tvalid_0's binary_logloss: 0.140691\n",
      "[LightGBM] [Debug] Re-bagging, using 168931 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[31]\tvalid_0's auc: 0.996314\tvalid_0's binary_logloss: 0.139064\n",
      "[LightGBM] [Debug] Re-bagging, using 168814 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[32]\tvalid_0's auc: 0.996329\tvalid_0's binary_logloss: 0.13743\n",
      "[LightGBM] [Debug] Re-bagging, using 168992 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and max_depth = 9\n",
      "[33]\tvalid_0's auc: 0.996332\tvalid_0's binary_logloss: 0.135836\n",
      "[LightGBM] [Debug] Re-bagging, using 168782 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[34]\tvalid_0's auc: 0.996384\tvalid_0's binary_logloss: 0.134386\n",
      "[LightGBM] [Debug] Re-bagging, using 168878 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[35]\tvalid_0's auc: 0.996393\tvalid_0's binary_logloss: 0.132847\n",
      "[LightGBM] [Debug] Re-bagging, using 168937 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[36]\tvalid_0's auc: 0.996399\tvalid_0's binary_logloss: 0.131367\n",
      "[LightGBM] [Debug] Re-bagging, using 169091 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[37]\tvalid_0's auc: 0.996443\tvalid_0's binary_logloss: 0.129919\n",
      "[LightGBM] [Debug] Re-bagging, using 168802 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[38]\tvalid_0's auc: 0.996442\tvalid_0's binary_logloss: 0.12855\n",
      "[LightGBM] [Debug] Re-bagging, using 169013 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[39]\tvalid_0's auc: 0.996473\tvalid_0's binary_logloss: 0.127195\n",
      "[LightGBM] [Debug] Re-bagging, using 169023 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[40]\tvalid_0's auc: 0.996494\tvalid_0's binary_logloss: 0.125909\n",
      "[LightGBM] [Debug] Re-bagging, using 169502 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[41]\tvalid_0's auc: 0.996535\tvalid_0's binary_logloss: 0.124604\n",
      "[LightGBM] [Debug] Re-bagging, using 169029 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[42]\tvalid_0's auc: 0.996531\tvalid_0's binary_logloss: 0.123328\n",
      "[LightGBM] [Debug] Re-bagging, using 169012 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[43]\tvalid_0's auc: 0.996529\tvalid_0's binary_logloss: 0.122097\n",
      "[LightGBM] [Debug] Re-bagging, using 168974 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[44]\tvalid_0's auc: 0.996554\tvalid_0's binary_logloss: 0.120807\n",
      "[LightGBM] [Debug] Re-bagging, using 169253 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[45]\tvalid_0's auc: 0.996626\tvalid_0's binary_logloss: 0.119705\n",
      "[LightGBM] [Debug] Re-bagging, using 169025 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[46]\tvalid_0's auc: 0.996671\tvalid_0's binary_logloss: 0.118487\n",
      "[LightGBM] [Debug] Re-bagging, using 168870 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[47]\tvalid_0's auc: 0.996685\tvalid_0's binary_logloss: 0.117371\n",
      "[LightGBM] [Debug] Re-bagging, using 168525 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[48]\tvalid_0's auc: 0.996689\tvalid_0's binary_logloss: 0.116211\n",
      "[LightGBM] [Debug] Re-bagging, using 169043 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[49]\tvalid_0's auc: 0.996703\tvalid_0's binary_logloss: 0.115082\n",
      "[LightGBM] [Debug] Re-bagging, using 168956 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[50]\tvalid_0's auc: 0.996711\tvalid_0's binary_logloss: 0.114\n",
      "[LightGBM] [Debug] Re-bagging, using 168761 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[51]\tvalid_0's auc: 0.996711\tvalid_0's binary_logloss: 0.11295\n",
      "[LightGBM] [Debug] Re-bagging, using 168619 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[52]\tvalid_0's auc: 0.996713\tvalid_0's binary_logloss: 0.111905\n",
      "[LightGBM] [Debug] Re-bagging, using 169229 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[53]\tvalid_0's auc: 0.996723\tvalid_0's binary_logloss: 0.110834\n",
      "[LightGBM] [Debug] Re-bagging, using 168749 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[54]\tvalid_0's auc: 0.996732\tvalid_0's binary_logloss: 0.109781\n",
      "[LightGBM] [Debug] Re-bagging, using 169238 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[55]\tvalid_0's auc: 0.996746\tvalid_0's binary_logloss: 0.108737\n",
      "[LightGBM] [Debug] Re-bagging, using 168816 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[56]\tvalid_0's auc: 0.996748\tvalid_0's binary_logloss: 0.107752\n",
      "[LightGBM] [Debug] Re-bagging, using 169056 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[57]\tvalid_0's auc: 0.996753\tvalid_0's binary_logloss: 0.106783\n",
      "[LightGBM] [Debug] Re-bagging, using 169299 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[58]\tvalid_0's auc: 0.996767\tvalid_0's binary_logloss: 0.105827\n",
      "[LightGBM] [Debug] Re-bagging, using 168884 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[59]\tvalid_0's auc: 0.996785\tvalid_0's binary_logloss: 0.104917\n",
      "[LightGBM] [Debug] Re-bagging, using 169366 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[60]\tvalid_0's auc: 0.996791\tvalid_0's binary_logloss: 0.104003\n",
      "[LightGBM] [Debug] Re-bagging, using 168855 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[61]\tvalid_0's auc: 0.996802\tvalid_0's binary_logloss: 0.10315\n",
      "[LightGBM] [Debug] Re-bagging, using 169023 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[62]\tvalid_0's auc: 0.996812\tvalid_0's binary_logloss: 0.102219\n",
      "[LightGBM] [Debug] Re-bagging, using 169080 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[63]\tvalid_0's auc: 0.996848\tvalid_0's binary_logloss: 0.101355\n",
      "[LightGBM] [Debug] Re-bagging, using 169065 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[64]\tvalid_0's auc: 0.996856\tvalid_0's binary_logloss: 0.100477\n",
      "[LightGBM] [Debug] Re-bagging, using 168757 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[65]\tvalid_0's auc: 0.996872\tvalid_0's binary_logloss: 0.099561\n",
      "[LightGBM] [Debug] Re-bagging, using 168979 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[66]\tvalid_0's auc: 0.996879\tvalid_0's binary_logloss: 0.0987152\n",
      "[LightGBM] [Debug] Re-bagging, using 168878 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[67]\tvalid_0's auc: 0.996887\tvalid_0's binary_logloss: 0.0978636\n",
      "[LightGBM] [Debug] Re-bagging, using 169141 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[68]\tvalid_0's auc: 0.996882\tvalid_0's binary_logloss: 0.0970832\n",
      "[LightGBM] [Debug] Re-bagging, using 168703 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[69]\tvalid_0's auc: 0.996891\tvalid_0's binary_logloss: 0.0962707\n",
      "[LightGBM] [Debug] Re-bagging, using 168777 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[70]\tvalid_0's auc: 0.9969\tvalid_0's binary_logloss: 0.095513\n",
      "[LightGBM] [Debug] Re-bagging, using 168667 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[71]\tvalid_0's auc: 0.996906\tvalid_0's binary_logloss: 0.0947202\n",
      "[LightGBM] [Debug] Re-bagging, using 168890 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[72]\tvalid_0's auc: 0.99691\tvalid_0's binary_logloss: 0.0939671\n",
      "[LightGBM] [Debug] Re-bagging, using 168953 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[73]\tvalid_0's auc: 0.996922\tvalid_0's binary_logloss: 0.0932169\n",
      "[LightGBM] [Debug] Re-bagging, using 168827 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[74]\tvalid_0's auc: 0.996931\tvalid_0's binary_logloss: 0.0924494\n",
      "[LightGBM] [Debug] Re-bagging, using 168859 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[75]\tvalid_0's auc: 0.996924\tvalid_0's binary_logloss: 0.0917692\n",
      "[LightGBM] [Debug] Re-bagging, using 169024 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[76]\tvalid_0's auc: 0.996935\tvalid_0's binary_logloss: 0.0910232\n",
      "[LightGBM] [Debug] Re-bagging, using 168955 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[77]\tvalid_0's auc: 0.996944\tvalid_0's binary_logloss: 0.0903215\n",
      "[LightGBM] [Debug] Re-bagging, using 168953 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[78]\tvalid_0's auc: 0.996956\tvalid_0's binary_logloss: 0.0895853\n",
      "[LightGBM] [Debug] Re-bagging, using 168792 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[79]\tvalid_0's auc: 0.996959\tvalid_0's binary_logloss: 0.0889027\n",
      "[LightGBM] [Debug] Re-bagging, using 169009 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[80]\tvalid_0's auc: 0.996991\tvalid_0's binary_logloss: 0.0881885\n",
      "[LightGBM] [Debug] Re-bagging, using 169467 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[81]\tvalid_0's auc: 0.996996\tvalid_0's binary_logloss: 0.0875011\n",
      "[LightGBM] [Debug] Re-bagging, using 168854 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[82]\tvalid_0's auc: 0.997017\tvalid_0's binary_logloss: 0.086834\n",
      "[LightGBM] [Debug] Re-bagging, using 168990 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[83]\tvalid_0's auc: 0.997035\tvalid_0's binary_logloss: 0.0861315\n",
      "[LightGBM] [Debug] Re-bagging, using 168994 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[84]\tvalid_0's auc: 0.997032\tvalid_0's binary_logloss: 0.0855189\n",
      "[LightGBM] [Debug] Re-bagging, using 169070 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[85]\tvalid_0's auc: 0.997048\tvalid_0's binary_logloss: 0.0848786\n",
      "[LightGBM] [Debug] Re-bagging, using 168713 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[86]\tvalid_0's auc: 0.997053\tvalid_0's binary_logloss: 0.0842687\n",
      "[LightGBM] [Debug] Re-bagging, using 169185 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 19\n",
      "[87]\tvalid_0's auc: 0.997075\tvalid_0's binary_logloss: 0.0836125\n",
      "[LightGBM] [Debug] Re-bagging, using 168947 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 19\n",
      "[88]\tvalid_0's auc: 0.997095\tvalid_0's binary_logloss: 0.0829708\n",
      "[LightGBM] [Debug] Re-bagging, using 168352 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[89]\tvalid_0's auc: 0.997129\tvalid_0's binary_logloss: 0.0823108\n",
      "[LightGBM] [Debug] Re-bagging, using 169200 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 19\n",
      "[90]\tvalid_0's auc: 0.997139\tvalid_0's binary_logloss: 0.0817195\n",
      "[LightGBM] [Debug] Re-bagging, using 169242 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[91]\tvalid_0's auc: 0.997141\tvalid_0's binary_logloss: 0.0811165\n",
      "[LightGBM] [Debug] Re-bagging, using 169252 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[92]\tvalid_0's auc: 0.997157\tvalid_0's binary_logloss: 0.0805449\n",
      "[LightGBM] [Debug] Re-bagging, using 168925 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 19\n",
      "[93]\tvalid_0's auc: 0.997174\tvalid_0's binary_logloss: 0.0799488\n",
      "[LightGBM] [Debug] Re-bagging, using 169230 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[94]\tvalid_0's auc: 0.997183\tvalid_0's binary_logloss: 0.0793494\n",
      "[LightGBM] [Debug] Re-bagging, using 169015 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[95]\tvalid_0's auc: 0.997191\tvalid_0's binary_logloss: 0.0787538\n",
      "[LightGBM] [Debug] Re-bagging, using 169170 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[96]\tvalid_0's auc: 0.997194\tvalid_0's binary_logloss: 0.0781924\n",
      "[LightGBM] [Debug] Re-bagging, using 168982 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[97]\tvalid_0's auc: 0.997203\tvalid_0's binary_logloss: 0.0776237\n",
      "[LightGBM] [Debug] Re-bagging, using 168623 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[98]\tvalid_0's auc: 0.997225\tvalid_0's binary_logloss: 0.077095\n",
      "[LightGBM] [Debug] Re-bagging, using 168762 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 18\n",
      "[99]\tvalid_0's auc: 0.997234\tvalid_0's binary_logloss: 0.0765769\n",
      "[LightGBM] [Debug] Re-bagging, using 168675 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[100]\tvalid_0's auc: 0.997237\tvalid_0's binary_logloss: 0.0760453\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.997237\tvalid_0's binary_logloss: 0.0760453\n",
      "[LightGBM] [Info] Number of positive: 15241, number of negative: 226096\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.010467\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000016 seconds, init for row-wise cost 0.006883 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4850\n",
      "[LightGBM] [Info] Number of data points in the train set: 241337, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.063152 -> initscore=-2.696971\n",
      "[LightGBM] [Info] Start training from score -2.696971\n",
      "[LightGBM] [Debug] Re-bagging, using 169055 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 9\n",
      "[1]\tvalid_0's auc: 0.992961\tvalid_0's binary_logloss: 0.229866\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 168739 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 10\n",
      "[2]\tvalid_0's auc: 0.992504\tvalid_0's binary_logloss: 0.223805\n",
      "[LightGBM] [Debug] Re-bagging, using 168627 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and max_depth = 12\n",
      "[3]\tvalid_0's auc: 0.993972\tvalid_0's binary_logloss: 0.218621\n",
      "[LightGBM] [Debug] Re-bagging, using 168711 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 10\n",
      "[4]\tvalid_0's auc: 0.993882\tvalid_0's binary_logloss: 0.213364\n",
      "[LightGBM] [Debug] Re-bagging, using 168797 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and max_depth = 10\n",
      "[5]\tvalid_0's auc: 0.993777\tvalid_0's binary_logloss: 0.208704\n",
      "[LightGBM] [Debug] Re-bagging, using 169408 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and max_depth = 8\n",
      "[6]\tvalid_0's auc: 0.993649\tvalid_0's binary_logloss: 0.204475\n",
      "[LightGBM] [Debug] Re-bagging, using 168807 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and max_depth = 12\n",
      "[7]\tvalid_0's auc: 0.994281\tvalid_0's binary_logloss: 0.20027\n",
      "[LightGBM] [Debug] Re-bagging, using 169175 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[8]\tvalid_0's auc: 0.994504\tvalid_0's binary_logloss: 0.196593\n",
      "[LightGBM] [Debug] Re-bagging, using 169128 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 8\n",
      "[9]\tvalid_0's auc: 0.994594\tvalid_0's binary_logloss: 0.19278\n",
      "[LightGBM] [Debug] Re-bagging, using 168929 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and max_depth = 8\n",
      "[10]\tvalid_0's auc: 0.994621\tvalid_0's binary_logloss: 0.189196\n",
      "[LightGBM] [Debug] Re-bagging, using 168736 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and max_depth = 9\n",
      "[11]\tvalid_0's auc: 0.994697\tvalid_0's binary_logloss: 0.185721\n",
      "[LightGBM] [Debug] Re-bagging, using 169112 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and max_depth = 8\n",
      "[12]\tvalid_0's auc: 0.994703\tvalid_0's binary_logloss: 0.182484\n",
      "[LightGBM] [Debug] Re-bagging, using 169163 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[13]\tvalid_0's auc: 0.994709\tvalid_0's binary_logloss: 0.179605\n",
      "[LightGBM] [Debug] Re-bagging, using 168911 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[14]\tvalid_0's auc: 0.994714\tvalid_0's binary_logloss: 0.176981\n",
      "[LightGBM] [Debug] Re-bagging, using 168725 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[15]\tvalid_0's auc: 0.994678\tvalid_0's binary_logloss: 0.17438\n",
      "[LightGBM] [Debug] Re-bagging, using 169271 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and max_depth = 8\n",
      "[16]\tvalid_0's auc: 0.994692\tvalid_0's binary_logloss: 0.171721\n",
      "[LightGBM] [Debug] Re-bagging, using 168959 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[17]\tvalid_0's auc: 0.995029\tvalid_0's binary_logloss: 0.169156\n",
      "[LightGBM] [Debug] Re-bagging, using 169129 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[18]\tvalid_0's auc: 0.995221\tvalid_0's binary_logloss: 0.166858\n",
      "[LightGBM] [Debug] Re-bagging, using 168936 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[19]\tvalid_0's auc: 0.995283\tvalid_0's binary_logloss: 0.164638\n",
      "[LightGBM] [Debug] Re-bagging, using 169011 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and max_depth = 9\n",
      "[20]\tvalid_0's auc: 0.995279\tvalid_0's binary_logloss: 0.162331\n",
      "[LightGBM] [Debug] Re-bagging, using 168576 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and max_depth = 9\n",
      "[21]\tvalid_0's auc: 0.995316\tvalid_0's binary_logloss: 0.160016\n",
      "[LightGBM] [Debug] Re-bagging, using 168762 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[22]\tvalid_0's auc: 0.995454\tvalid_0's binary_logloss: 0.157977\n",
      "[LightGBM] [Debug] Re-bagging, using 168720 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[23]\tvalid_0's auc: 0.995492\tvalid_0's binary_logloss: 0.15604\n",
      "[LightGBM] [Debug] Re-bagging, using 169583 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[24]\tvalid_0's auc: 0.995555\tvalid_0's binary_logloss: 0.154083\n",
      "[LightGBM] [Debug] Re-bagging, using 169050 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 8\n",
      "[25]\tvalid_0's auc: 0.995592\tvalid_0's binary_logloss: 0.152036\n",
      "[LightGBM] [Debug] Re-bagging, using 169348 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and max_depth = 9\n",
      "[26]\tvalid_0's auc: 0.995596\tvalid_0's binary_logloss: 0.150091\n",
      "[LightGBM] [Debug] Re-bagging, using 169041 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and max_depth = 8\n",
      "[27]\tvalid_0's auc: 0.995596\tvalid_0's binary_logloss: 0.148229\n",
      "[LightGBM] [Debug] Re-bagging, using 168580 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[28]\tvalid_0's auc: 0.995667\tvalid_0's binary_logloss: 0.146392\n",
      "[LightGBM] [Debug] Re-bagging, using 168683 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[29]\tvalid_0's auc: 0.995679\tvalid_0's binary_logloss: 0.14458\n",
      "[LightGBM] [Debug] Re-bagging, using 169046 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[30]\tvalid_0's auc: 0.995735\tvalid_0's binary_logloss: 0.142864\n",
      "[LightGBM] [Debug] Re-bagging, using 168858 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[31]\tvalid_0's auc: 0.995772\tvalid_0's binary_logloss: 0.141253\n",
      "[LightGBM] [Debug] Re-bagging, using 168710 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[32]\tvalid_0's auc: 0.995783\tvalid_0's binary_logloss: 0.139601\n",
      "[LightGBM] [Debug] Re-bagging, using 168917 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[33]\tvalid_0's auc: 0.995785\tvalid_0's binary_logloss: 0.138004\n",
      "[LightGBM] [Debug] Re-bagging, using 168698 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[34]\tvalid_0's auc: 0.995825\tvalid_0's binary_logloss: 0.136555\n",
      "[LightGBM] [Debug] Re-bagging, using 168793 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[35]\tvalid_0's auc: 0.995831\tvalid_0's binary_logloss: 0.135021\n",
      "[LightGBM] [Debug] Re-bagging, using 168885 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[36]\tvalid_0's auc: 0.995867\tvalid_0's binary_logloss: 0.133461\n",
      "[LightGBM] [Debug] Re-bagging, using 169050 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[37]\tvalid_0's auc: 0.995904\tvalid_0's binary_logloss: 0.132008\n",
      "[LightGBM] [Debug] Re-bagging, using 168765 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[38]\tvalid_0's auc: 0.995906\tvalid_0's binary_logloss: 0.130633\n",
      "[LightGBM] [Debug] Re-bagging, using 168977 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[39]\tvalid_0's auc: 0.995925\tvalid_0's binary_logloss: 0.129285\n",
      "[LightGBM] [Debug] Re-bagging, using 168963 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[40]\tvalid_0's auc: 0.99595\tvalid_0's binary_logloss: 0.127965\n",
      "[LightGBM] [Debug] Re-bagging, using 169421 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[41]\tvalid_0's auc: 0.996002\tvalid_0's binary_logloss: 0.126653\n",
      "[LightGBM] [Debug] Re-bagging, using 168956 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[42]\tvalid_0's auc: 0.99599\tvalid_0's binary_logloss: 0.125412\n",
      "[LightGBM] [Debug] Re-bagging, using 168947 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[43]\tvalid_0's auc: 0.995992\tvalid_0's binary_logloss: 0.124168\n",
      "[LightGBM] [Debug] Re-bagging, using 168903 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[44]\tvalid_0's auc: 0.996015\tvalid_0's binary_logloss: 0.122869\n",
      "[LightGBM] [Debug] Re-bagging, using 169180 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[45]\tvalid_0's auc: 0.996085\tvalid_0's binary_logloss: 0.121753\n",
      "[LightGBM] [Debug] Re-bagging, using 168942 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[46]\tvalid_0's auc: 0.996126\tvalid_0's binary_logloss: 0.120568\n",
      "[LightGBM] [Debug] Re-bagging, using 168813 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[47]\tvalid_0's auc: 0.996134\tvalid_0's binary_logloss: 0.119463\n",
      "[LightGBM] [Debug] Re-bagging, using 168451 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[48]\tvalid_0's auc: 0.996138\tvalid_0's binary_logloss: 0.118308\n",
      "[LightGBM] [Debug] Re-bagging, using 168972 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[49]\tvalid_0's auc: 0.99616\tvalid_0's binary_logloss: 0.117164\n",
      "[LightGBM] [Debug] Re-bagging, using 168871 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[50]\tvalid_0's auc: 0.996175\tvalid_0's binary_logloss: 0.11605\n",
      "[LightGBM] [Debug] Re-bagging, using 168711 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[51]\tvalid_0's auc: 0.996199\tvalid_0's binary_logloss: 0.11493\n",
      "[LightGBM] [Debug] Re-bagging, using 168577 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[52]\tvalid_0's auc: 0.996201\tvalid_0's binary_logloss: 0.113886\n",
      "[LightGBM] [Debug] Re-bagging, using 169165 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[53]\tvalid_0's auc: 0.996213\tvalid_0's binary_logloss: 0.112798\n",
      "[LightGBM] [Debug] Re-bagging, using 168701 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[54]\tvalid_0's auc: 0.996231\tvalid_0's binary_logloss: 0.11175\n",
      "[LightGBM] [Debug] Re-bagging, using 169171 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[55]\tvalid_0's auc: 0.996255\tvalid_0's binary_logloss: 0.110684\n",
      "[LightGBM] [Debug] Re-bagging, using 168758 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[56]\tvalid_0's auc: 0.99626\tvalid_0's binary_logloss: 0.109692\n",
      "[LightGBM] [Debug] Re-bagging, using 168983 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[57]\tvalid_0's auc: 0.996285\tvalid_0's binary_logloss: 0.108669\n",
      "[LightGBM] [Debug] Re-bagging, using 169235 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[58]\tvalid_0's auc: 0.996294\tvalid_0's binary_logloss: 0.107713\n",
      "[LightGBM] [Debug] Re-bagging, using 168813 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[59]\tvalid_0's auc: 0.9963\tvalid_0's binary_logloss: 0.106808\n",
      "[LightGBM] [Debug] Re-bagging, using 169324 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[60]\tvalid_0's auc: 0.996304\tvalid_0's binary_logloss: 0.105877\n",
      "[LightGBM] [Debug] Re-bagging, using 168773 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[61]\tvalid_0's auc: 0.996307\tvalid_0's binary_logloss: 0.105023\n",
      "[LightGBM] [Debug] Re-bagging, using 168958 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[62]\tvalid_0's auc: 0.996325\tvalid_0's binary_logloss: 0.104085\n",
      "[LightGBM] [Debug] Re-bagging, using 169005 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[63]\tvalid_0's auc: 0.996354\tvalid_0's binary_logloss: 0.103217\n",
      "[LightGBM] [Debug] Re-bagging, using 168992 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[64]\tvalid_0's auc: 0.996363\tvalid_0's binary_logloss: 0.102334\n",
      "[LightGBM] [Debug] Re-bagging, using 168714 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[65]\tvalid_0's auc: 0.996377\tvalid_0's binary_logloss: 0.101452\n",
      "[LightGBM] [Debug] Re-bagging, using 168900 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[66]\tvalid_0's auc: 0.996388\tvalid_0's binary_logloss: 0.100599\n",
      "[LightGBM] [Debug] Re-bagging, using 168838 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[67]\tvalid_0's auc: 0.996399\tvalid_0's binary_logloss: 0.0997534\n",
      "[LightGBM] [Debug] Re-bagging, using 169073 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[68]\tvalid_0's auc: 0.996395\tvalid_0's binary_logloss: 0.0989654\n",
      "[LightGBM] [Debug] Re-bagging, using 168622 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[69]\tvalid_0's auc: 0.996413\tvalid_0's binary_logloss: 0.0981436\n",
      "[LightGBM] [Debug] Re-bagging, using 168698 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[70]\tvalid_0's auc: 0.996428\tvalid_0's binary_logloss: 0.0973724\n",
      "[LightGBM] [Debug] Re-bagging, using 168612 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[71]\tvalid_0's auc: 0.996443\tvalid_0's binary_logloss: 0.0965594\n",
      "[LightGBM] [Debug] Re-bagging, using 168820 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[72]\tvalid_0's auc: 0.996453\tvalid_0's binary_logloss: 0.0957914\n",
      "[LightGBM] [Debug] Re-bagging, using 168867 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[73]\tvalid_0's auc: 0.996465\tvalid_0's binary_logloss: 0.0950647\n",
      "[LightGBM] [Debug] Re-bagging, using 168766 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[74]\tvalid_0's auc: 0.996483\tvalid_0's binary_logloss: 0.0942668\n",
      "[LightGBM] [Debug] Re-bagging, using 168798 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[75]\tvalid_0's auc: 0.996486\tvalid_0's binary_logloss: 0.0935663\n",
      "[LightGBM] [Debug] Re-bagging, using 168947 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[76]\tvalid_0's auc: 0.996493\tvalid_0's binary_logloss: 0.0928363\n",
      "[LightGBM] [Debug] Re-bagging, using 168903 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[77]\tvalid_0's auc: 0.996503\tvalid_0's binary_logloss: 0.0921378\n",
      "[LightGBM] [Debug] Re-bagging, using 168876 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[78]\tvalid_0's auc: 0.996516\tvalid_0's binary_logloss: 0.0914157\n",
      "[LightGBM] [Debug] Re-bagging, using 168740 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[79]\tvalid_0's auc: 0.996518\tvalid_0's binary_logloss: 0.0907343\n",
      "[LightGBM] [Debug] Re-bagging, using 168944 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[80]\tvalid_0's auc: 0.996532\tvalid_0's binary_logloss: 0.0900324\n",
      "[LightGBM] [Debug] Re-bagging, using 169395 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[81]\tvalid_0's auc: 0.996539\tvalid_0's binary_logloss: 0.0893457\n",
      "[LightGBM] [Debug] Re-bagging, using 168806 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[82]\tvalid_0's auc: 0.996563\tvalid_0's binary_logloss: 0.0886504\n",
      "[LightGBM] [Debug] Re-bagging, using 168906 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[83]\tvalid_0's auc: 0.996577\tvalid_0's binary_logloss: 0.0879645\n",
      "[LightGBM] [Debug] Re-bagging, using 168935 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[84]\tvalid_0's auc: 0.996573\tvalid_0's binary_logloss: 0.0873554\n",
      "[LightGBM] [Debug] Re-bagging, using 168977 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[85]\tvalid_0's auc: 0.996591\tvalid_0's binary_logloss: 0.0867145\n",
      "[LightGBM] [Debug] Re-bagging, using 168633 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[86]\tvalid_0's auc: 0.996593\tvalid_0's binary_logloss: 0.0860975\n",
      "[LightGBM] [Debug] Re-bagging, using 169110 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 18\n",
      "[87]\tvalid_0's auc: 0.996614\tvalid_0's binary_logloss: 0.0854475\n",
      "[LightGBM] [Debug] Re-bagging, using 168873 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 18\n",
      "[88]\tvalid_0's auc: 0.99664\tvalid_0's binary_logloss: 0.084801\n",
      "[LightGBM] [Debug] Re-bagging, using 168324 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[89]\tvalid_0's auc: 0.99666\tvalid_0's binary_logloss: 0.0841683\n",
      "[LightGBM] [Debug] Re-bagging, using 169159 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[90]\tvalid_0's auc: 0.996668\tvalid_0's binary_logloss: 0.0835787\n",
      "[LightGBM] [Debug] Re-bagging, using 169181 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[91]\tvalid_0's auc: 0.996679\tvalid_0's binary_logloss: 0.0829782\n",
      "[LightGBM] [Debug] Re-bagging, using 169163 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 18\n",
      "[92]\tvalid_0's auc: 0.996706\tvalid_0's binary_logloss: 0.0823815\n",
      "[LightGBM] [Debug] Re-bagging, using 168870 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 19\n",
      "[93]\tvalid_0's auc: 0.996732\tvalid_0's binary_logloss: 0.0817702\n",
      "[LightGBM] [Debug] Re-bagging, using 169176 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[94]\tvalid_0's auc: 0.996746\tvalid_0's binary_logloss: 0.0811766\n",
      "[LightGBM] [Debug] Re-bagging, using 168964 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[95]\tvalid_0's auc: 0.99676\tvalid_0's binary_logloss: 0.0805874\n",
      "[LightGBM] [Debug] Re-bagging, using 169116 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[96]\tvalid_0's auc: 0.996773\tvalid_0's binary_logloss: 0.0800146\n",
      "[LightGBM] [Debug] Re-bagging, using 168933 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[97]\tvalid_0's auc: 0.99678\tvalid_0's binary_logloss: 0.0794673\n",
      "[LightGBM] [Debug] Re-bagging, using 168561 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[98]\tvalid_0's auc: 0.996801\tvalid_0's binary_logloss: 0.0789506\n",
      "[LightGBM] [Debug] Re-bagging, using 168718 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 18\n",
      "[99]\tvalid_0's auc: 0.996813\tvalid_0's binary_logloss: 0.0784175\n",
      "[LightGBM] [Debug] Re-bagging, using 168591 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[100]\tvalid_0's auc: 0.996823\tvalid_0's binary_logloss: 0.0778933\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.996823\tvalid_0's binary_logloss: 0.0778933\n",
      "[LightGBM] [Info] Number of positive: 15247, number of negative: 226118\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.010438\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000011 seconds, init for row-wise cost 0.007042 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 4854\n",
      "[LightGBM] [Info] Number of data points in the train set: 241365, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.063170 -> initscore=-2.696674\n",
      "[LightGBM] [Info] Start training from score -2.696674\n",
      "[LightGBM] [Debug] Re-bagging, using 169077 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 10\n",
      "[1]\tvalid_0's auc: 0.992918\tvalid_0's binary_logloss: 0.229652\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 168758 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and max_depth = 11\n",
      "[2]\tvalid_0's auc: 0.992819\tvalid_0's binary_logloss: 0.223495\n",
      "[LightGBM] [Debug] Re-bagging, using 168641 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 13\n",
      "[3]\tvalid_0's auc: 0.994185\tvalid_0's binary_logloss: 0.218021\n",
      "[LightGBM] [Debug] Re-bagging, using 168743 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 10\n",
      "[4]\tvalid_0's auc: 0.994054\tvalid_0's binary_logloss: 0.212768\n",
      "[LightGBM] [Debug] Re-bagging, using 168809 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[5]\tvalid_0's auc: 0.993971\tvalid_0's binary_logloss: 0.208065\n",
      "[LightGBM] [Debug] Re-bagging, using 169431 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[6]\tvalid_0's auc: 0.993853\tvalid_0's binary_logloss: 0.203783\n",
      "[LightGBM] [Debug] Re-bagging, using 168828 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[7]\tvalid_0's auc: 0.994448\tvalid_0's binary_logloss: 0.199619\n",
      "[LightGBM] [Debug] Re-bagging, using 169201 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[8]\tvalid_0's auc: 0.994756\tvalid_0's binary_logloss: 0.195749\n",
      "[LightGBM] [Debug] Re-bagging, using 169134 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 9\n",
      "[9]\tvalid_0's auc: 0.994881\tvalid_0's binary_logloss: 0.191891\n",
      "[LightGBM] [Debug] Re-bagging, using 168944 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 19 and max_depth = 8\n",
      "[10]\tvalid_0's auc: 0.99491\tvalid_0's binary_logloss: 0.18828\n",
      "[LightGBM] [Debug] Re-bagging, using 168760 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 20 and max_depth = 8\n",
      "[11]\tvalid_0's auc: 0.994888\tvalid_0's binary_logloss: 0.184919\n",
      "[LightGBM] [Debug] Re-bagging, using 169118 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and max_depth = 8\n",
      "[12]\tvalid_0's auc: 0.994956\tvalid_0's binary_logloss: 0.181581\n",
      "[LightGBM] [Debug] Re-bagging, using 169190 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[13]\tvalid_0's auc: 0.994912\tvalid_0's binary_logloss: 0.178688\n",
      "[LightGBM] [Debug] Re-bagging, using 168953 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[14]\tvalid_0's auc: 0.994867\tvalid_0's binary_logloss: 0.176098\n",
      "[LightGBM] [Debug] Re-bagging, using 168714 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[15]\tvalid_0's auc: 0.99485\tvalid_0's binary_logloss: 0.173494\n",
      "[LightGBM] [Debug] Re-bagging, using 169310 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and max_depth = 8\n",
      "[16]\tvalid_0's auc: 0.994857\tvalid_0's binary_logloss: 0.170797\n",
      "[LightGBM] [Debug] Re-bagging, using 168965 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[17]\tvalid_0's auc: 0.99519\tvalid_0's binary_logloss: 0.16823\n",
      "[LightGBM] [Debug] Re-bagging, using 169152 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[18]\tvalid_0's auc: 0.995361\tvalid_0's binary_logloss: 0.166\n",
      "[LightGBM] [Debug] Re-bagging, using 168951 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[19]\tvalid_0's auc: 0.995482\tvalid_0's binary_logloss: 0.1637\n",
      "[LightGBM] [Debug] Re-bagging, using 169047 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 8\n",
      "[20]\tvalid_0's auc: 0.995485\tvalid_0's binary_logloss: 0.161384\n",
      "[LightGBM] [Debug] Re-bagging, using 168602 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and max_depth = 10\n",
      "[21]\tvalid_0's auc: 0.995504\tvalid_0's binary_logloss: 0.159077\n",
      "[LightGBM] [Debug] Re-bagging, using 168772 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[22]\tvalid_0's auc: 0.995623\tvalid_0's binary_logloss: 0.15698\n",
      "[LightGBM] [Debug] Re-bagging, using 168762 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[23]\tvalid_0's auc: 0.99564\tvalid_0's binary_logloss: 0.155044\n",
      "[LightGBM] [Debug] Re-bagging, using 169608 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[24]\tvalid_0's auc: 0.995707\tvalid_0's binary_logloss: 0.153063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 169043 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and max_depth = 10\n",
      "[25]\tvalid_0's auc: 0.995734\tvalid_0's binary_logloss: 0.151022\n",
      "[LightGBM] [Debug] Re-bagging, using 169368 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[26]\tvalid_0's auc: 0.995754\tvalid_0's binary_logloss: 0.149054\n",
      "[LightGBM] [Debug] Re-bagging, using 169056 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[27]\tvalid_0's auc: 0.995765\tvalid_0's binary_logloss: 0.147195\n",
      "[LightGBM] [Debug] Re-bagging, using 168586 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[28]\tvalid_0's auc: 0.995831\tvalid_0's binary_logloss: 0.145372\n",
      "[LightGBM] [Debug] Re-bagging, using 168712 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[29]\tvalid_0's auc: 0.995872\tvalid_0's binary_logloss: 0.143523\n",
      "[LightGBM] [Debug] Re-bagging, using 169039 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[30]\tvalid_0's auc: 0.995943\tvalid_0's binary_logloss: 0.141783\n",
      "[LightGBM] [Debug] Re-bagging, using 168886 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[31]\tvalid_0's auc: 0.995976\tvalid_0's binary_logloss: 0.140167\n",
      "[LightGBM] [Debug] Re-bagging, using 168745 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[32]\tvalid_0's auc: 0.995972\tvalid_0's binary_logloss: 0.138542\n",
      "[LightGBM] [Debug] Re-bagging, using 168935 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[33]\tvalid_0's auc: 0.995987\tvalid_0's binary_logloss: 0.136923\n",
      "[LightGBM] [Debug] Re-bagging, using 168712 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[34]\tvalid_0's auc: 0.99603\tvalid_0's binary_logloss: 0.135487\n",
      "[LightGBM] [Debug] Re-bagging, using 168850 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[35]\tvalid_0's auc: 0.996052\tvalid_0's binary_logloss: 0.13393\n",
      "[LightGBM] [Debug] Re-bagging, using 168905 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[36]\tvalid_0's auc: 0.996067\tvalid_0's binary_logloss: 0.132409\n",
      "[LightGBM] [Debug] Re-bagging, using 169065 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[37]\tvalid_0's auc: 0.996098\tvalid_0's binary_logloss: 0.13097\n",
      "[LightGBM] [Debug] Re-bagging, using 168781 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[38]\tvalid_0's auc: 0.996112\tvalid_0's binary_logloss: 0.129555\n",
      "[LightGBM] [Debug] Re-bagging, using 168976 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[39]\tvalid_0's auc: 0.996163\tvalid_0's binary_logloss: 0.128169\n",
      "[LightGBM] [Debug] Re-bagging, using 168967 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[40]\tvalid_0's auc: 0.996178\tvalid_0's binary_logloss: 0.126872\n",
      "[LightGBM] [Debug] Re-bagging, using 169447 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[41]\tvalid_0's auc: 0.996238\tvalid_0's binary_logloss: 0.125579\n",
      "[LightGBM] [Debug] Re-bagging, using 168957 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[42]\tvalid_0's auc: 0.996232\tvalid_0's binary_logloss: 0.124323\n",
      "[LightGBM] [Debug] Re-bagging, using 168982 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[43]\tvalid_0's auc: 0.996243\tvalid_0's binary_logloss: 0.123069\n",
      "[LightGBM] [Debug] Re-bagging, using 168942 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[44]\tvalid_0's auc: 0.996276\tvalid_0's binary_logloss: 0.121738\n",
      "[LightGBM] [Debug] Re-bagging, using 169207 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[45]\tvalid_0's auc: 0.996353\tvalid_0's binary_logloss: 0.120608\n",
      "[LightGBM] [Debug] Re-bagging, using 168959 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[46]\tvalid_0's auc: 0.996411\tvalid_0's binary_logloss: 0.119426\n",
      "[LightGBM] [Debug] Re-bagging, using 168813 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[47]\tvalid_0's auc: 0.996435\tvalid_0's binary_logloss: 0.11828\n",
      "[LightGBM] [Debug] Re-bagging, using 168472 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[48]\tvalid_0's auc: 0.996463\tvalid_0's binary_logloss: 0.117075\n",
      "[LightGBM] [Debug] Re-bagging, using 169008 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[49]\tvalid_0's auc: 0.996482\tvalid_0's binary_logloss: 0.115931\n",
      "[LightGBM] [Debug] Re-bagging, using 168916 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[50]\tvalid_0's auc: 0.996482\tvalid_0's binary_logloss: 0.114865\n",
      "[LightGBM] [Debug] Re-bagging, using 168721 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[51]\tvalid_0's auc: 0.996496\tvalid_0's binary_logloss: 0.113767\n",
      "[LightGBM] [Debug] Re-bagging, using 168579 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[52]\tvalid_0's auc: 0.996497\tvalid_0's binary_logloss: 0.112726\n",
      "[LightGBM] [Debug] Re-bagging, using 169187 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[53]\tvalid_0's auc: 0.996503\tvalid_0's binary_logloss: 0.111651\n",
      "[LightGBM] [Debug] Re-bagging, using 168725 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[54]\tvalid_0's auc: 0.996509\tvalid_0's binary_logloss: 0.110605\n",
      "[LightGBM] [Debug] Re-bagging, using 169173 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[55]\tvalid_0's auc: 0.996517\tvalid_0's binary_logloss: 0.109585\n",
      "[LightGBM] [Debug] Re-bagging, using 168785 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[56]\tvalid_0's auc: 0.996515\tvalid_0's binary_logloss: 0.108612\n",
      "[LightGBM] [Debug] Re-bagging, using 169007 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[57]\tvalid_0's auc: 0.996522\tvalid_0's binary_logloss: 0.107623\n",
      "[LightGBM] [Debug] Re-bagging, using 169243 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[58]\tvalid_0's auc: 0.996538\tvalid_0's binary_logloss: 0.106671\n",
      "[LightGBM] [Debug] Re-bagging, using 168821 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[59]\tvalid_0's auc: 0.996559\tvalid_0's binary_logloss: 0.105752\n",
      "[LightGBM] [Debug] Re-bagging, using 169356 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[60]\tvalid_0's auc: 0.996566\tvalid_0's binary_logloss: 0.104835\n",
      "[LightGBM] [Debug] Re-bagging, using 168806 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[61]\tvalid_0's auc: 0.99657\tvalid_0's binary_logloss: 0.103994\n",
      "[LightGBM] [Debug] Re-bagging, using 168969 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[62]\tvalid_0's auc: 0.996586\tvalid_0's binary_logloss: 0.103079\n",
      "[LightGBM] [Debug] Re-bagging, using 169043 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[63]\tvalid_0's auc: 0.996629\tvalid_0's binary_logloss: 0.102194\n",
      "[LightGBM] [Debug] Re-bagging, using 169006 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[64]\tvalid_0's auc: 0.996643\tvalid_0's binary_logloss: 0.101292\n",
      "[LightGBM] [Debug] Re-bagging, using 168701 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[65]\tvalid_0's auc: 0.996656\tvalid_0's binary_logloss: 0.100395\n",
      "[LightGBM] [Debug] Re-bagging, using 168928 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[66]\tvalid_0's auc: 0.996663\tvalid_0's binary_logloss: 0.0995329\n",
      "[LightGBM] [Debug] Re-bagging, using 168867 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[67]\tvalid_0's auc: 0.996672\tvalid_0's binary_logloss: 0.0986958\n",
      "[LightGBM] [Debug] Re-bagging, using 169117 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[68]\tvalid_0's auc: 0.996676\tvalid_0's binary_logloss: 0.0979139\n",
      "[LightGBM] [Debug] Re-bagging, using 168641 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[69]\tvalid_0's auc: 0.996681\tvalid_0's binary_logloss: 0.0970884\n",
      "[LightGBM] [Debug] Re-bagging, using 168706 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[70]\tvalid_0's auc: 0.996696\tvalid_0's binary_logloss: 0.0963188\n",
      "[LightGBM] [Debug] Re-bagging, using 168627 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[71]\tvalid_0's auc: 0.996705\tvalid_0's binary_logloss: 0.0955208\n",
      "[LightGBM] [Debug] Re-bagging, using 168838 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[72]\tvalid_0's auc: 0.996707\tvalid_0's binary_logloss: 0.0947704\n",
      "[LightGBM] [Debug] Re-bagging, using 168868 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[73]\tvalid_0's auc: 0.996718\tvalid_0's binary_logloss: 0.0940701\n",
      "[LightGBM] [Debug] Re-bagging, using 168773 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[74]\tvalid_0's auc: 0.996751\tvalid_0's binary_logloss: 0.0932388\n",
      "[LightGBM] [Debug] Re-bagging, using 168831 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[75]\tvalid_0's auc: 0.996752\tvalid_0's binary_logloss: 0.0925358\n",
      "[LightGBM] [Debug] Re-bagging, using 169004 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[76]\tvalid_0's auc: 0.996765\tvalid_0's binary_logloss: 0.0917879\n",
      "[LightGBM] [Debug] Re-bagging, using 168940 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[77]\tvalid_0's auc: 0.996771\tvalid_0's binary_logloss: 0.0910979\n",
      "[LightGBM] [Debug] Re-bagging, using 168902 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[78]\tvalid_0's auc: 0.996784\tvalid_0's binary_logloss: 0.0903752\n",
      "[LightGBM] [Debug] Re-bagging, using 168744 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[79]\tvalid_0's auc: 0.996794\tvalid_0's binary_logloss: 0.0896793\n",
      "[LightGBM] [Debug] Re-bagging, using 168954 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[80]\tvalid_0's auc: 0.996802\tvalid_0's binary_logloss: 0.0890306\n",
      "[LightGBM] [Debug] Re-bagging, using 169411 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[81]\tvalid_0's auc: 0.996809\tvalid_0's binary_logloss: 0.0883541\n",
      "[LightGBM] [Debug] Re-bagging, using 168793 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[82]\tvalid_0's auc: 0.996831\tvalid_0's binary_logloss: 0.0876829\n",
      "[LightGBM] [Debug] Re-bagging, using 168926 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[83]\tvalid_0's auc: 0.996842\tvalid_0's binary_logloss: 0.087011\n",
      "[LightGBM] [Debug] Re-bagging, using 168946 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[84]\tvalid_0's auc: 0.996842\tvalid_0's binary_logloss: 0.0864046\n",
      "[LightGBM] [Debug] Re-bagging, using 169020 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[85]\tvalid_0's auc: 0.996844\tvalid_0's binary_logloss: 0.085814\n",
      "[LightGBM] [Debug] Re-bagging, using 168671 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[86]\tvalid_0's auc: 0.996847\tvalid_0's binary_logloss: 0.0852024\n",
      "[LightGBM] [Debug] Re-bagging, using 169154 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[87]\tvalid_0's auc: 0.996873\tvalid_0's binary_logloss: 0.0845599\n",
      "[LightGBM] [Debug] Re-bagging, using 168889 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[88]\tvalid_0's auc: 0.996895\tvalid_0's binary_logloss: 0.0839\n",
      "[LightGBM] [Debug] Re-bagging, using 168328 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 18\n",
      "[89]\tvalid_0's auc: 0.996915\tvalid_0's binary_logloss: 0.0832653\n",
      "[LightGBM] [Debug] Re-bagging, using 169180 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[90]\tvalid_0's auc: 0.996928\tvalid_0's binary_logloss: 0.0826864\n",
      "[LightGBM] [Debug] Re-bagging, using 169210 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[91]\tvalid_0's auc: 0.996938\tvalid_0's binary_logloss: 0.0820782\n",
      "[LightGBM] [Debug] Re-bagging, using 169187 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[92]\tvalid_0's auc: 0.996953\tvalid_0's binary_logloss: 0.0814816\n",
      "[LightGBM] [Debug] Re-bagging, using 168894 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[93]\tvalid_0's auc: 0.996963\tvalid_0's binary_logloss: 0.0809134\n",
      "[LightGBM] [Debug] Re-bagging, using 169186 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[94]\tvalid_0's auc: 0.996971\tvalid_0's binary_logloss: 0.0803273\n",
      "[LightGBM] [Debug] Re-bagging, using 168992 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[95]\tvalid_0's auc: 0.996982\tvalid_0's binary_logloss: 0.0797454\n",
      "[LightGBM] [Debug] Re-bagging, using 169118 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[96]\tvalid_0's auc: 0.996991\tvalid_0's binary_logloss: 0.0791766\n",
      "[LightGBM] [Debug] Re-bagging, using 168917 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[97]\tvalid_0's auc: 0.997002\tvalid_0's binary_logloss: 0.078611\n",
      "[LightGBM] [Debug] Re-bagging, using 168577 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[98]\tvalid_0's auc: 0.997026\tvalid_0's binary_logloss: 0.0780917\n",
      "[LightGBM] [Debug] Re-bagging, using 168722 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[99]\tvalid_0's auc: 0.997034\tvalid_0's binary_logloss: 0.077552\n",
      "[LightGBM] [Debug] Re-bagging, using 168650 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[100]\tvalid_0's auc: 0.997041\tvalid_0's binary_logloss: 0.0770109\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.997041\tvalid_0's binary_logloss: 0.0770109\n",
      "[LightGBM] [Info] Number of positive: 15324, number of negative: 226065\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.010476\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000014 seconds, init for row-wise cost 0.007294 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4850\n",
      "[LightGBM] [Info] Number of data points in the train set: 241389, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.063483 -> initscore=-2.691402\n",
      "[LightGBM] [Info] Start training from score -2.691402\n",
      "[LightGBM] [Debug] Re-bagging, using 169095 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and max_depth = 10\n",
      "[1]\tvalid_0's auc: 0.993275\tvalid_0's binary_logloss: 0.226448\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 168769 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and max_depth = 12\n",
      "[2]\tvalid_0's auc: 0.992913\tvalid_0's binary_logloss: 0.220474\n",
      "[LightGBM] [Debug] Re-bagging, using 168661 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 13\n",
      "[3]\tvalid_0's auc: 0.994518\tvalid_0's binary_logloss: 0.215019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 168765 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 9\n",
      "[4]\tvalid_0's auc: 0.994495\tvalid_0's binary_logloss: 0.209835\n",
      "[LightGBM] [Debug] Re-bagging, using 168819 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[5]\tvalid_0's auc: 0.994449\tvalid_0's binary_logloss: 0.205194\n",
      "[LightGBM] [Debug] Re-bagging, using 169450 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[6]\tvalid_0's auc: 0.994355\tvalid_0's binary_logloss: 0.201004\n",
      "[LightGBM] [Debug] Re-bagging, using 168850 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and max_depth = 12\n",
      "[7]\tvalid_0's auc: 0.994817\tvalid_0's binary_logloss: 0.196786\n",
      "[LightGBM] [Debug] Re-bagging, using 169208 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[8]\tvalid_0's auc: 0.99516\tvalid_0's binary_logloss: 0.193045\n",
      "[LightGBM] [Debug] Re-bagging, using 169152 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and max_depth = 9\n",
      "[9]\tvalid_0's auc: 0.995234\tvalid_0's binary_logloss: 0.189298\n",
      "[LightGBM] [Debug] Re-bagging, using 168957 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 18 and max_depth = 7\n",
      "[10]\tvalid_0's auc: 0.995264\tvalid_0's binary_logloss: 0.185815\n",
      "[LightGBM] [Debug] Re-bagging, using 168770 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and max_depth = 9\n",
      "[11]\tvalid_0's auc: 0.995288\tvalid_0's binary_logloss: 0.182493\n",
      "[LightGBM] [Debug] Re-bagging, using 169152 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and max_depth = 8\n",
      "[12]\tvalid_0's auc: 0.995306\tvalid_0's binary_logloss: 0.179311\n",
      "[LightGBM] [Debug] Re-bagging, using 169205 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[13]\tvalid_0's auc: 0.995316\tvalid_0's binary_logloss: 0.176452\n",
      "[LightGBM] [Debug] Re-bagging, using 168980 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[14]\tvalid_0's auc: 0.995341\tvalid_0's binary_logloss: 0.173809\n",
      "[LightGBM] [Debug] Re-bagging, using 168732 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[15]\tvalid_0's auc: 0.995358\tvalid_0's binary_logloss: 0.171231\n",
      "[LightGBM] [Debug] Re-bagging, using 169320 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and max_depth = 10\n",
      "[16]\tvalid_0's auc: 0.995364\tvalid_0's binary_logloss: 0.168599\n",
      "[LightGBM] [Debug] Re-bagging, using 168975 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[17]\tvalid_0's auc: 0.995579\tvalid_0's binary_logloss: 0.166056\n",
      "[LightGBM] [Debug] Re-bagging, using 169153 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[18]\tvalid_0's auc: 0.995689\tvalid_0's binary_logloss: 0.163857\n",
      "[LightGBM] [Debug] Re-bagging, using 168974 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[19]\tvalid_0's auc: 0.995777\tvalid_0's binary_logloss: 0.161601\n",
      "[LightGBM] [Debug] Re-bagging, using 169078 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 9\n",
      "[20]\tvalid_0's auc: 0.995763\tvalid_0's binary_logloss: 0.1593\n",
      "[LightGBM] [Debug] Re-bagging, using 168622 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 9\n",
      "[21]\tvalid_0's auc: 0.99577\tvalid_0's binary_logloss: 0.157066\n",
      "[LightGBM] [Debug] Re-bagging, using 168794 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[22]\tvalid_0's auc: 0.995903\tvalid_0's binary_logloss: 0.155009\n",
      "[LightGBM] [Debug] Re-bagging, using 168788 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[23]\tvalid_0's auc: 0.995955\tvalid_0's binary_logloss: 0.15307\n",
      "[LightGBM] [Debug] Re-bagging, using 169608 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[24]\tvalid_0's auc: 0.996029\tvalid_0's binary_logloss: 0.15115\n",
      "[LightGBM] [Debug] Re-bagging, using 169066 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and max_depth = 8\n",
      "[25]\tvalid_0's auc: 0.996055\tvalid_0's binary_logloss: 0.149149\n",
      "[LightGBM] [Debug] Re-bagging, using 169374 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[26]\tvalid_0's auc: 0.996071\tvalid_0's binary_logloss: 0.147223\n",
      "[LightGBM] [Debug] Re-bagging, using 169056 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[27]\tvalid_0's auc: 0.996078\tvalid_0's binary_logloss: 0.145378\n",
      "[LightGBM] [Debug] Re-bagging, using 168609 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[28]\tvalid_0's auc: 0.996166\tvalid_0's binary_logloss: 0.143564\n",
      "[LightGBM] [Debug] Re-bagging, using 168709 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and max_depth = 9\n",
      "[29]\tvalid_0's auc: 0.996177\tvalid_0's binary_logloss: 0.141777\n",
      "[LightGBM] [Debug] Re-bagging, using 169071 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[30]\tvalid_0's auc: 0.996225\tvalid_0's binary_logloss: 0.140081\n",
      "[LightGBM] [Debug] Re-bagging, using 168909 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[31]\tvalid_0's auc: 0.99628\tvalid_0's binary_logloss: 0.138429\n",
      "[LightGBM] [Debug] Re-bagging, using 168773 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[32]\tvalid_0's auc: 0.996283\tvalid_0's binary_logloss: 0.136817\n",
      "[LightGBM] [Debug] Re-bagging, using 168946 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[33]\tvalid_0's auc: 0.996322\tvalid_0's binary_logloss: 0.135164\n",
      "[LightGBM] [Debug] Re-bagging, using 168752 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[34]\tvalid_0's auc: 0.996363\tvalid_0's binary_logloss: 0.133732\n",
      "[LightGBM] [Debug] Re-bagging, using 168850 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[35]\tvalid_0's auc: 0.996374\tvalid_0's binary_logloss: 0.132197\n",
      "[LightGBM] [Debug] Re-bagging, using 168944 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[36]\tvalid_0's auc: 0.996403\tvalid_0's binary_logloss: 0.130701\n",
      "[LightGBM] [Debug] Re-bagging, using 169058 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[37]\tvalid_0's auc: 0.99644\tvalid_0's binary_logloss: 0.129249\n",
      "[LightGBM] [Debug] Re-bagging, using 168792 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[38]\tvalid_0's auc: 0.996436\tvalid_0's binary_logloss: 0.127891\n",
      "[LightGBM] [Debug] Re-bagging, using 168995 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[39]\tvalid_0's auc: 0.996468\tvalid_0's binary_logloss: 0.126538\n",
      "[LightGBM] [Debug] Re-bagging, using 168979 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[40]\tvalid_0's auc: 0.996477\tvalid_0's binary_logloss: 0.125287\n",
      "[LightGBM] [Debug] Re-bagging, using 169453 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[41]\tvalid_0's auc: 0.996528\tvalid_0's binary_logloss: 0.123961\n",
      "[LightGBM] [Debug] Re-bagging, using 168995 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[42]\tvalid_0's auc: 0.996521\tvalid_0's binary_logloss: 0.122717\n",
      "[LightGBM] [Debug] Re-bagging, using 169000 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[43]\tvalid_0's auc: 0.996536\tvalid_0's binary_logloss: 0.121452\n",
      "[LightGBM] [Debug] Re-bagging, using 168961 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[44]\tvalid_0's auc: 0.996554\tvalid_0's binary_logloss: 0.120177\n",
      "[LightGBM] [Debug] Re-bagging, using 169204 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[45]\tvalid_0's auc: 0.996611\tvalid_0's binary_logloss: 0.11909\n",
      "[LightGBM] [Debug] Re-bagging, using 168976 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[46]\tvalid_0's auc: 0.996654\tvalid_0's binary_logloss: 0.117915\n",
      "[LightGBM] [Debug] Re-bagging, using 168835 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[47]\tvalid_0's auc: 0.996679\tvalid_0's binary_logloss: 0.11679\n",
      "[LightGBM] [Debug] Re-bagging, using 168516 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[48]\tvalid_0's auc: 0.996692\tvalid_0's binary_logloss: 0.115619\n",
      "[LightGBM] [Debug] Re-bagging, using 169030 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[49]\tvalid_0's auc: 0.996714\tvalid_0's binary_logloss: 0.114466\n",
      "[LightGBM] [Debug] Re-bagging, using 168915 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[50]\tvalid_0's auc: 0.99672\tvalid_0's binary_logloss: 0.113393\n",
      "[LightGBM] [Debug] Re-bagging, using 168730 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[51]\tvalid_0's auc: 0.996738\tvalid_0's binary_logloss: 0.112307\n",
      "[LightGBM] [Debug] Re-bagging, using 168605 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[52]\tvalid_0's auc: 0.996738\tvalid_0's binary_logloss: 0.111261\n",
      "[LightGBM] [Debug] Re-bagging, using 169194 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[53]\tvalid_0's auc: 0.996741\tvalid_0's binary_logloss: 0.110214\n",
      "[LightGBM] [Debug] Re-bagging, using 168750 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[54]\tvalid_0's auc: 0.996744\tvalid_0's binary_logloss: 0.109206\n",
      "[LightGBM] [Debug] Re-bagging, using 169194 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[55]\tvalid_0's auc: 0.996759\tvalid_0's binary_logloss: 0.108168\n",
      "[LightGBM] [Debug] Re-bagging, using 168795 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[56]\tvalid_0's auc: 0.996764\tvalid_0's binary_logloss: 0.107202\n",
      "[LightGBM] [Debug] Re-bagging, using 169000 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[57]\tvalid_0's auc: 0.996777\tvalid_0's binary_logloss: 0.106199\n",
      "[LightGBM] [Debug] Re-bagging, using 169275 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[58]\tvalid_0's auc: 0.996784\tvalid_0's binary_logloss: 0.105258\n",
      "[LightGBM] [Debug] Re-bagging, using 168852 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[59]\tvalid_0's auc: 0.996794\tvalid_0's binary_logloss: 0.104342\n",
      "[LightGBM] [Debug] Re-bagging, using 169361 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[60]\tvalid_0's auc: 0.996805\tvalid_0's binary_logloss: 0.103409\n",
      "[LightGBM] [Debug] Re-bagging, using 168839 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[61]\tvalid_0's auc: 0.996814\tvalid_0's binary_logloss: 0.102564\n",
      "[LightGBM] [Debug] Re-bagging, using 168981 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[62]\tvalid_0's auc: 0.996823\tvalid_0's binary_logloss: 0.101668\n",
      "[LightGBM] [Debug] Re-bagging, using 169029 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[63]\tvalid_0's auc: 0.996842\tvalid_0's binary_logloss: 0.100836\n",
      "[LightGBM] [Debug] Re-bagging, using 169026 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[64]\tvalid_0's auc: 0.996866\tvalid_0's binary_logloss: 0.0999334\n",
      "[LightGBM] [Debug] Re-bagging, using 168741 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[65]\tvalid_0's auc: 0.996893\tvalid_0's binary_logloss: 0.0990147\n",
      "[LightGBM] [Debug] Re-bagging, using 168962 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[66]\tvalid_0's auc: 0.996903\tvalid_0's binary_logloss: 0.0981629\n",
      "[LightGBM] [Debug] Re-bagging, using 168869 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[67]\tvalid_0's auc: 0.996916\tvalid_0's binary_logloss: 0.0973087\n",
      "[LightGBM] [Debug] Re-bagging, using 169126 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[68]\tvalid_0's auc: 0.996914\tvalid_0's binary_logloss: 0.0965297\n",
      "[LightGBM] [Debug] Re-bagging, using 168657 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[69]\tvalid_0's auc: 0.99693\tvalid_0's binary_logloss: 0.0957046\n",
      "[LightGBM] [Debug] Re-bagging, using 168728 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[70]\tvalid_0's auc: 0.996956\tvalid_0's binary_logloss: 0.0949163\n",
      "[LightGBM] [Debug] Re-bagging, using 168614 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[71]\tvalid_0's auc: 0.99697\tvalid_0's binary_logloss: 0.0941138\n",
      "[LightGBM] [Debug] Re-bagging, using 168861 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[72]\tvalid_0's auc: 0.996984\tvalid_0's binary_logloss: 0.0933397\n",
      "[LightGBM] [Debug] Re-bagging, using 168921 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 19\n",
      "[73]\tvalid_0's auc: 0.997002\tvalid_0's binary_logloss: 0.0926072\n",
      "[LightGBM] [Debug] Re-bagging, using 168807 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[74]\tvalid_0's auc: 0.997013\tvalid_0's binary_logloss: 0.0918337\n",
      "[LightGBM] [Debug] Re-bagging, using 168850 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[75]\tvalid_0's auc: 0.997008\tvalid_0's binary_logloss: 0.0911457\n",
      "[LightGBM] [Debug] Re-bagging, using 169003 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[76]\tvalid_0's auc: 0.997017\tvalid_0's binary_logloss: 0.0904326\n",
      "[LightGBM] [Debug] Re-bagging, using 168968 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[77]\tvalid_0's auc: 0.997022\tvalid_0's binary_logloss: 0.089746\n",
      "[LightGBM] [Debug] Re-bagging, using 168905 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[78]\tvalid_0's auc: 0.997036\tvalid_0's binary_logloss: 0.0890172\n",
      "[LightGBM] [Debug] Re-bagging, using 168739 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[79]\tvalid_0's auc: 0.997035\tvalid_0's binary_logloss: 0.0883415\n",
      "[LightGBM] [Debug] Re-bagging, using 168965 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[80]\tvalid_0's auc: 0.997068\tvalid_0's binary_logloss: 0.0876542\n",
      "[LightGBM] [Debug] Re-bagging, using 169417 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[81]\tvalid_0's auc: 0.99707\tvalid_0's binary_logloss: 0.0869796\n",
      "[LightGBM] [Debug] Re-bagging, using 168837 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[82]\tvalid_0's auc: 0.997103\tvalid_0's binary_logloss: 0.0862833\n",
      "[LightGBM] [Debug] Re-bagging, using 168961 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[83]\tvalid_0's auc: 0.997111\tvalid_0's binary_logloss: 0.0856182\n",
      "[LightGBM] [Debug] Re-bagging, using 168972 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84]\tvalid_0's auc: 0.997115\tvalid_0's binary_logloss: 0.0850059\n",
      "[LightGBM] [Debug] Re-bagging, using 169032 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[85]\tvalid_0's auc: 0.997144\tvalid_0's binary_logloss: 0.0843376\n",
      "[LightGBM] [Debug] Re-bagging, using 168680 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[86]\tvalid_0's auc: 0.997146\tvalid_0's binary_logloss: 0.083736\n",
      "[LightGBM] [Debug] Re-bagging, using 169170 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 19\n",
      "[87]\tvalid_0's auc: 0.997169\tvalid_0's binary_logloss: 0.0830731\n",
      "[LightGBM] [Debug] Re-bagging, using 168914 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 20\n",
      "[88]\tvalid_0's auc: 0.997189\tvalid_0's binary_logloss: 0.0824237\n",
      "[LightGBM] [Debug] Re-bagging, using 168351 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[89]\tvalid_0's auc: 0.9972\tvalid_0's binary_logloss: 0.0818427\n",
      "[LightGBM] [Debug] Re-bagging, using 169192 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 18\n",
      "[90]\tvalid_0's auc: 0.997211\tvalid_0's binary_logloss: 0.0812459\n",
      "[LightGBM] [Debug] Re-bagging, using 169221 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[91]\tvalid_0's auc: 0.997215\tvalid_0's binary_logloss: 0.0806496\n",
      "[LightGBM] [Debug] Re-bagging, using 169218 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 18\n",
      "[92]\tvalid_0's auc: 0.997231\tvalid_0's binary_logloss: 0.0800622\n",
      "[LightGBM] [Debug] Re-bagging, using 168888 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[93]\tvalid_0's auc: 0.997259\tvalid_0's binary_logloss: 0.0794424\n",
      "[LightGBM] [Debug] Re-bagging, using 169171 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[94]\tvalid_0's auc: 0.997265\tvalid_0's binary_logloss: 0.0788651\n",
      "[LightGBM] [Debug] Re-bagging, using 169005 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[95]\tvalid_0's auc: 0.997278\tvalid_0's binary_logloss: 0.0782783\n",
      "[LightGBM] [Debug] Re-bagging, using 169134 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[96]\tvalid_0's auc: 0.997287\tvalid_0's binary_logloss: 0.0777178\n",
      "[LightGBM] [Debug] Re-bagging, using 168979 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[97]\tvalid_0's auc: 0.997294\tvalid_0's binary_logloss: 0.0771632\n",
      "[LightGBM] [Debug] Re-bagging, using 168595 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[98]\tvalid_0's auc: 0.997308\tvalid_0's binary_logloss: 0.0766586\n",
      "[LightGBM] [Debug] Re-bagging, using 168739 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[99]\tvalid_0's auc: 0.997319\tvalid_0's binary_logloss: 0.0761133\n",
      "[LightGBM] [Debug] Re-bagging, using 168641 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[100]\tvalid_0's auc: 0.997324\tvalid_0's binary_logloss: 0.0755759\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.997324\tvalid_0's binary_logloss: 0.0755759\n",
      "[LightGBM] [Info] Number of positive: 15255, number of negative: 226173\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.010463\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000014 seconds, init for row-wise cost 0.006842 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4853\n",
      "[LightGBM] [Info] Number of data points in the train set: 241428, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.063187 -> initscore=-2.696393\n",
      "[LightGBM] [Info] Start training from score -2.696393\n",
      "[LightGBM] [Debug] Re-bagging, using 169125 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 10\n",
      "[1]\tvalid_0's auc: 0.993026\tvalid_0's binary_logloss: 0.229561\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 168785 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 11\n",
      "[2]\tvalid_0's auc: 0.992654\tvalid_0's binary_logloss: 0.223485\n",
      "[LightGBM] [Debug] Re-bagging, using 168696 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and max_depth = 13\n",
      "[3]\tvalid_0's auc: 0.993905\tvalid_0's binary_logloss: 0.218027\n",
      "[LightGBM] [Debug] Re-bagging, using 168803 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and max_depth = 10\n",
      "[4]\tvalid_0's auc: 0.993995\tvalid_0's binary_logloss: 0.21281\n",
      "[LightGBM] [Debug] Re-bagging, using 168820 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[5]\tvalid_0's auc: 0.993915\tvalid_0's binary_logloss: 0.208163\n",
      "[LightGBM] [Debug] Re-bagging, using 169508 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[6]\tvalid_0's auc: 0.993833\tvalid_0's binary_logloss: 0.203934\n",
      "[LightGBM] [Debug] Re-bagging, using 168857 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and max_depth = 13\n",
      "[7]\tvalid_0's auc: 0.994322\tvalid_0's binary_logloss: 0.199668\n",
      "[LightGBM] [Debug] Re-bagging, using 169251 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[8]\tvalid_0's auc: 0.994648\tvalid_0's binary_logloss: 0.195817\n",
      "[LightGBM] [Debug] Re-bagging, using 169157 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and max_depth = 8\n",
      "[9]\tvalid_0's auc: 0.994805\tvalid_0's binary_logloss: 0.192098\n",
      "[LightGBM] [Debug] Re-bagging, using 168992 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 20 and max_depth = 8\n",
      "[10]\tvalid_0's auc: 0.994875\tvalid_0's binary_logloss: 0.188538\n",
      "[LightGBM] [Debug] Re-bagging, using 168794 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 20 and max_depth = 8\n",
      "[11]\tvalid_0's auc: 0.994908\tvalid_0's binary_logloss: 0.185214\n",
      "[LightGBM] [Debug] Re-bagging, using 169184 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and max_depth = 8\n",
      "[12]\tvalid_0's auc: 0.994944\tvalid_0's binary_logloss: 0.182036\n",
      "[LightGBM] [Debug] Re-bagging, using 169252 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[13]\tvalid_0's auc: 0.994914\tvalid_0's binary_logloss: 0.179148\n",
      "[LightGBM] [Debug] Re-bagging, using 168979 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[14]\tvalid_0's auc: 0.994947\tvalid_0's binary_logloss: 0.176472\n",
      "[LightGBM] [Debug] Re-bagging, using 168770 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[15]\tvalid_0's auc: 0.994916\tvalid_0's binary_logloss: 0.173883\n",
      "[LightGBM] [Debug] Re-bagging, using 169337 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 19 and max_depth = 8\n",
      "[16]\tvalid_0's auc: 0.994923\tvalid_0's binary_logloss: 0.171219\n",
      "[LightGBM] [Debug] Re-bagging, using 168996 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[17]\tvalid_0's auc: 0.995242\tvalid_0's binary_logloss: 0.168592\n",
      "[LightGBM] [Debug] Re-bagging, using 169189 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[18]\tvalid_0's auc: 0.995406\tvalid_0's binary_logloss: 0.166337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 169021 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[19]\tvalid_0's auc: 0.995467\tvalid_0's binary_logloss: 0.164074\n",
      "[LightGBM] [Debug] Re-bagging, using 169107 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and max_depth = 9\n",
      "[20]\tvalid_0's auc: 0.995475\tvalid_0's binary_logloss: 0.161755\n",
      "[LightGBM] [Debug] Re-bagging, using 168642 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and max_depth = 10\n",
      "[21]\tvalid_0's auc: 0.995469\tvalid_0's binary_logloss: 0.159535\n",
      "[LightGBM] [Debug] Re-bagging, using 168845 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[22]\tvalid_0's auc: 0.995592\tvalid_0's binary_logloss: 0.157445\n",
      "[LightGBM] [Debug] Re-bagging, using 168800 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[23]\tvalid_0's auc: 0.995623\tvalid_0's binary_logloss: 0.155473\n",
      "[LightGBM] [Debug] Re-bagging, using 169627 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[24]\tvalid_0's auc: 0.995674\tvalid_0's binary_logloss: 0.153547\n",
      "[LightGBM] [Debug] Re-bagging, using 169075 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and max_depth = 10\n",
      "[25]\tvalid_0's auc: 0.99569\tvalid_0's binary_logloss: 0.151553\n",
      "[LightGBM] [Debug] Re-bagging, using 169386 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and max_depth = 10\n",
      "[26]\tvalid_0's auc: 0.995705\tvalid_0's binary_logloss: 0.149621\n",
      "[LightGBM] [Debug] Re-bagging, using 169096 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and max_depth = 10\n",
      "[27]\tvalid_0's auc: 0.995724\tvalid_0's binary_logloss: 0.147727\n",
      "[LightGBM] [Debug] Re-bagging, using 168610 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[28]\tvalid_0's auc: 0.995803\tvalid_0's binary_logloss: 0.145894\n",
      "[LightGBM] [Debug] Re-bagging, using 168754 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and max_depth = 11\n",
      "[29]\tvalid_0's auc: 0.995827\tvalid_0's binary_logloss: 0.144073\n",
      "[LightGBM] [Debug] Re-bagging, using 169121 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[30]\tvalid_0's auc: 0.9959\tvalid_0's binary_logloss: 0.142315\n",
      "[LightGBM] [Debug] Re-bagging, using 168933 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[31]\tvalid_0's auc: 0.995934\tvalid_0's binary_logloss: 0.140705\n",
      "[LightGBM] [Debug] Re-bagging, using 168810 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[32]\tvalid_0's auc: 0.995952\tvalid_0's binary_logloss: 0.139069\n",
      "[LightGBM] [Debug] Re-bagging, using 168997 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[33]\tvalid_0's auc: 0.995969\tvalid_0's binary_logloss: 0.137467\n",
      "[LightGBM] [Debug] Re-bagging, using 168776 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[34]\tvalid_0's auc: 0.996012\tvalid_0's binary_logloss: 0.136011\n",
      "[LightGBM] [Debug] Re-bagging, using 168881 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[35]\tvalid_0's auc: 0.996024\tvalid_0's binary_logloss: 0.134477\n",
      "[LightGBM] [Debug] Re-bagging, using 168937 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[36]\tvalid_0's auc: 0.996041\tvalid_0's binary_logloss: 0.132981\n",
      "[LightGBM] [Debug] Re-bagging, using 169083 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[37]\tvalid_0's auc: 0.996096\tvalid_0's binary_logloss: 0.131485\n",
      "[LightGBM] [Debug] Re-bagging, using 168807 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[38]\tvalid_0's auc: 0.996094\tvalid_0's binary_logloss: 0.130117\n",
      "[LightGBM] [Debug] Re-bagging, using 169007 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[39]\tvalid_0's auc: 0.996142\tvalid_0's binary_logloss: 0.128718\n",
      "[LightGBM] [Debug] Re-bagging, using 169028 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[40]\tvalid_0's auc: 0.996146\tvalid_0's binary_logloss: 0.127454\n",
      "[LightGBM] [Debug] Re-bagging, using 169497 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[41]\tvalid_0's auc: 0.996213\tvalid_0's binary_logloss: 0.126131\n",
      "[LightGBM] [Debug] Re-bagging, using 169026 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[42]\tvalid_0's auc: 0.996201\tvalid_0's binary_logloss: 0.124885\n",
      "[LightGBM] [Debug] Re-bagging, using 169018 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[43]\tvalid_0's auc: 0.996204\tvalid_0's binary_logloss: 0.123643\n",
      "[LightGBM] [Debug] Re-bagging, using 168973 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[44]\tvalid_0's auc: 0.996211\tvalid_0's binary_logloss: 0.122394\n",
      "[LightGBM] [Debug] Re-bagging, using 169246 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[45]\tvalid_0's auc: 0.99629\tvalid_0's binary_logloss: 0.121293\n",
      "[LightGBM] [Debug] Re-bagging, using 169028 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[46]\tvalid_0's auc: 0.996328\tvalid_0's binary_logloss: 0.12014\n",
      "[LightGBM] [Debug] Re-bagging, using 168874 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[47]\tvalid_0's auc: 0.996361\tvalid_0's binary_logloss: 0.118939\n",
      "[LightGBM] [Debug] Re-bagging, using 168520 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[48]\tvalid_0's auc: 0.996382\tvalid_0's binary_logloss: 0.117744\n",
      "[LightGBM] [Debug] Re-bagging, using 169045 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[49]\tvalid_0's auc: 0.996403\tvalid_0's binary_logloss: 0.116607\n",
      "[LightGBM] [Debug] Re-bagging, using 168954 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[50]\tvalid_0's auc: 0.996396\tvalid_0's binary_logloss: 0.11555\n",
      "[LightGBM] [Debug] Re-bagging, using 168756 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[51]\tvalid_0's auc: 0.996396\tvalid_0's binary_logloss: 0.114485\n",
      "[LightGBM] [Debug] Re-bagging, using 168617 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[52]\tvalid_0's auc: 0.996408\tvalid_0's binary_logloss: 0.11341\n",
      "[LightGBM] [Debug] Re-bagging, using 169231 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[53]\tvalid_0's auc: 0.996412\tvalid_0's binary_logloss: 0.112367\n",
      "[LightGBM] [Debug] Re-bagging, using 168750 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[54]\tvalid_0's auc: 0.996426\tvalid_0's binary_logloss: 0.111315\n",
      "[LightGBM] [Debug] Re-bagging, using 169243 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[55]\tvalid_0's auc: 0.996438\tvalid_0's binary_logloss: 0.110272\n",
      "[LightGBM] [Debug] Re-bagging, using 168815 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[56]\tvalid_0's auc: 0.996438\tvalid_0's binary_logloss: 0.109298\n",
      "[LightGBM] [Debug] Re-bagging, using 169048 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[57]\tvalid_0's auc: 0.996444\tvalid_0's binary_logloss: 0.108311\n",
      "[LightGBM] [Debug] Re-bagging, using 169306 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[58]\tvalid_0's auc: 0.996447\tvalid_0's binary_logloss: 0.107369\n",
      "[LightGBM] [Debug] Re-bagging, using 168880 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[59]\tvalid_0's auc: 0.996483\tvalid_0's binary_logloss: 0.106371\n",
      "[LightGBM] [Debug] Re-bagging, using 169364 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[60]\tvalid_0's auc: 0.996494\tvalid_0's binary_logloss: 0.105438\n",
      "[LightGBM] [Debug] Re-bagging, using 168850 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[61]\tvalid_0's auc: 0.996503\tvalid_0's binary_logloss: 0.104572\n",
      "[LightGBM] [Debug] Re-bagging, using 169025 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[62]\tvalid_0's auc: 0.996519\tvalid_0's binary_logloss: 0.103628\n",
      "[LightGBM] [Debug] Re-bagging, using 169081 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[63]\tvalid_0's auc: 0.996558\tvalid_0's binary_logloss: 0.102743\n",
      "[LightGBM] [Debug] Re-bagging, using 169060 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[64]\tvalid_0's auc: 0.996565\tvalid_0's binary_logloss: 0.10188\n",
      "[LightGBM] [Debug] Re-bagging, using 168756 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[65]\tvalid_0's auc: 0.996567\tvalid_0's binary_logloss: 0.101022\n",
      "[LightGBM] [Debug] Re-bagging, using 168981 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[66]\tvalid_0's auc: 0.99657\tvalid_0's binary_logloss: 0.100169\n",
      "[LightGBM] [Debug] Re-bagging, using 168880 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[67]\tvalid_0's auc: 0.996582\tvalid_0's binary_logloss: 0.0992982\n",
      "[LightGBM] [Debug] Re-bagging, using 169139 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[68]\tvalid_0's auc: 0.996582\tvalid_0's binary_logloss: 0.0984896\n",
      "[LightGBM] [Debug] Re-bagging, using 168694 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[69]\tvalid_0's auc: 0.996584\tvalid_0's binary_logloss: 0.0976924\n",
      "[LightGBM] [Debug] Re-bagging, using 168776 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[70]\tvalid_0's auc: 0.996613\tvalid_0's binary_logloss: 0.0968589\n",
      "[LightGBM] [Debug] Re-bagging, using 168680 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[71]\tvalid_0's auc: 0.996621\tvalid_0's binary_logloss: 0.0960515\n",
      "[LightGBM] [Debug] Re-bagging, using 168889 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[72]\tvalid_0's auc: 0.996626\tvalid_0's binary_logloss: 0.0952861\n",
      "[LightGBM] [Debug] Re-bagging, using 168951 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[73]\tvalid_0's auc: 0.996638\tvalid_0's binary_logloss: 0.0945717\n",
      "[LightGBM] [Debug] Re-bagging, using 168825 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[74]\tvalid_0's auc: 0.996656\tvalid_0's binary_logloss: 0.0937778\n",
      "[LightGBM] [Debug] Re-bagging, using 168850 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[75]\tvalid_0's auc: 0.996655\tvalid_0's binary_logloss: 0.0930958\n",
      "[LightGBM] [Debug] Re-bagging, using 169028 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[76]\tvalid_0's auc: 0.99667\tvalid_0's binary_logloss: 0.0923308\n",
      "[LightGBM] [Debug] Re-bagging, using 168958 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[77]\tvalid_0's auc: 0.996672\tvalid_0's binary_logloss: 0.0916359\n",
      "[LightGBM] [Debug] Re-bagging, using 168945 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[78]\tvalid_0's auc: 0.996694\tvalid_0's binary_logloss: 0.0908847\n",
      "[LightGBM] [Debug] Re-bagging, using 168800 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[79]\tvalid_0's auc: 0.996699\tvalid_0's binary_logloss: 0.0902009\n",
      "[LightGBM] [Debug] Re-bagging, using 169006 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[80]\tvalid_0's auc: 0.996713\tvalid_0's binary_logloss: 0.0895208\n",
      "[LightGBM] [Debug] Re-bagging, using 169462 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[81]\tvalid_0's auc: 0.996721\tvalid_0's binary_logloss: 0.0888273\n",
      "[LightGBM] [Debug] Re-bagging, using 168854 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 20\n",
      "[82]\tvalid_0's auc: 0.996753\tvalid_0's binary_logloss: 0.088108\n",
      "[LightGBM] [Debug] Re-bagging, using 168988 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[83]\tvalid_0's auc: 0.996762\tvalid_0's binary_logloss: 0.0874383\n",
      "[LightGBM] [Debug] Re-bagging, using 169005 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[84]\tvalid_0's auc: 0.996766\tvalid_0's binary_logloss: 0.0868174\n",
      "[LightGBM] [Debug] Re-bagging, using 169064 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[85]\tvalid_0's auc: 0.996787\tvalid_0's binary_logloss: 0.0861979\n",
      "[LightGBM] [Debug] Re-bagging, using 168711 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[86]\tvalid_0's auc: 0.996788\tvalid_0's binary_logloss: 0.0856074\n",
      "[LightGBM] [Debug] Re-bagging, using 169178 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[87]\tvalid_0's auc: 0.996808\tvalid_0's binary_logloss: 0.0849594\n",
      "[LightGBM] [Debug] Re-bagging, using 168954 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[88]\tvalid_0's auc: 0.996835\tvalid_0's binary_logloss: 0.0843198\n",
      "[LightGBM] [Debug] Re-bagging, using 168359 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[89]\tvalid_0's auc: 0.996871\tvalid_0's binary_logloss: 0.0836454\n",
      "[LightGBM] [Debug] Re-bagging, using 169183 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[90]\tvalid_0's auc: 0.996882\tvalid_0's binary_logloss: 0.0830356\n",
      "[LightGBM] [Debug] Re-bagging, using 169258 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[91]\tvalid_0's auc: 0.996896\tvalid_0's binary_logloss: 0.0824117\n",
      "[LightGBM] [Debug] Re-bagging, using 169242 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[92]\tvalid_0's auc: 0.996912\tvalid_0's binary_logloss: 0.0818128\n",
      "[LightGBM] [Debug] Re-bagging, using 168912 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[93]\tvalid_0's auc: 0.996928\tvalid_0's binary_logloss: 0.0812075\n",
      "[LightGBM] [Debug] Re-bagging, using 169241 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[94]\tvalid_0's auc: 0.996938\tvalid_0's binary_logloss: 0.0806149\n",
      "[LightGBM] [Debug] Re-bagging, using 169014 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[95]\tvalid_0's auc: 0.996947\tvalid_0's binary_logloss: 0.0800217\n",
      "[LightGBM] [Debug] Re-bagging, using 169177 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[96]\tvalid_0's auc: 0.996957\tvalid_0's binary_logloss: 0.0794501\n",
      "[LightGBM] [Debug] Re-bagging, using 168974 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[97]\tvalid_0's auc: 0.996968\tvalid_0's binary_logloss: 0.0788825\n",
      "[LightGBM] [Debug] Re-bagging, using 168623 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[98]\tvalid_0's auc: 0.996986\tvalid_0's binary_logloss: 0.0783678\n",
      "[LightGBM] [Debug] Re-bagging, using 168759 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[99]\tvalid_0's auc: 0.996997\tvalid_0's binary_logloss: 0.0778298\n",
      "[LightGBM] [Debug] Re-bagging, using 168675 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[100]\tvalid_0's auc: 0.997012\tvalid_0's binary_logloss: 0.0772722\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.997012\tvalid_0's binary_logloss: 0.0772722\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id', 'label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 模型及参数的定义\n",
    "    lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16, verbose=10)  \n",
    "    # 训练模型\n",
    "    lgb_Classfication.fit(train_idx[lgb_cols], train_idx['label'],eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], \n",
    "                          eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_Classfication.predict_proba(valid_idx[lgb_cols], \n",
    "                                                              num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "    # 对输出结果进行归一化 分类模型输出的值本身就是一个概率值不需要进行归一化\n",
    "    # valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += lgb_Classfication.predict_proba(tst_user_item_feats_df_rank_model[lgb_cols], \n",
    "                                                     num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_cls_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_cls_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:39:29.281200Z",
     "start_time": "2021-01-14T14:39:26.024905Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:39:30.217697Z",
     "start_time": "2021-01-14T14:39:29.282197Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取多个模型的排序结果文件\n",
    "lgb_ranker = pd.read_csv(save_path + 'tst_lgb_ranker_feats.csv')\n",
    "lgb_cls = pd.read_csv(save_path + 'tst_lgb_cls_feats.csv')\n",
    "# din_ranker = pd.read_csv(save_path + 'din_rank_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:39:30.232656Z",
     "start_time": "2021-01-14T14:39:30.218694Z"
    }
   },
   "outputs": [],
   "source": [
    "rank_model = {'lgb_ranker': lgb_ranker, \n",
    "              'lgb_cls': lgb_cls}\n",
    "#               'din_ranker': din_ranker}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:41:36.763387Z",
     "start_time": "2021-01-14T14:41:36.753414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>pred_score</th>\n",
       "      <th>pred_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>250000</td>\n",
       "      <td>160417</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>250003</td>\n",
       "      <td>160417</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>250004</td>\n",
       "      <td>160417</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>250009</td>\n",
       "      <td>160417</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>250010</td>\n",
       "      <td>160417</td>\n",
       "      <td>0.085297</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999995</td>\n",
       "      <td>299943</td>\n",
       "      <td>75295</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999996</td>\n",
       "      <td>299943</td>\n",
       "      <td>272640</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999997</td>\n",
       "      <td>299944</td>\n",
       "      <td>106009</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999998</td>\n",
       "      <td>299959</td>\n",
       "      <td>139</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999999</td>\n",
       "      <td>299959</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  pred_score  pred_rank\n",
       "0         250000            160417    0.006458        5.0\n",
       "1         250003            160417    0.001824        8.0\n",
       "2         250004            160417    0.001229        4.0\n",
       "3         250009            160417    0.001938        5.0\n",
       "4         250010            160417    0.085297        7.0\n",
       "...          ...               ...         ...        ...\n",
       "1999995   299943             75295    0.000016       39.0\n",
       "1999996   299943            272640    0.000016       40.0\n",
       "1999997   299944            106009    0.000394       20.0\n",
       "1999998   299959               139    0.000084       17.0\n",
       "1999999   299959               145    0.000084       18.0\n",
       "\n",
       "[2000000 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:39:30.264571Z",
     "start_time": "2021-01-14T14:39:30.249611Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ensumble_predict_topk(rank_model, topk=5):\n",
    "#     final_recall = rank_model['lgb_cls'].append(rank_model['din_ranker'])\n",
    "#     rank_model['lgb_ranker']['pred_score'] = rank_model['lgb_ranker']['pred_score'].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    final_recall = rank_model['lgb_cls'].append(rank_model['lgb_ranker'])\n",
    "    final_recall = final_recall.groupby(['user_id', 'click_article_id'])['pred_score'].sum().reset_index()\n",
    "    \n",
    "    submit(final_recall, topk=topk, model_name='ensemble_fuse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T14:39:34.313746Z",
     "start_time": "2021-01-14T14:39:30.265569Z"
    }
   },
   "outputs": [],
   "source": [
    "get_ensumble_predict_topk(rank_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
